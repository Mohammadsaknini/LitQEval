{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from litQeval.eval_utils import *\n",
    "import plotly.express as px\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mSearching config file credentials for default 'live' instance..\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mDimcli - Dimensions API Client (v1.3)\u001b[0m\n",
      "\u001b[2mConnected to: <https://app.dimensions.ai/api/dsl> - DSL v2.10\u001b[0m\n",
      "\u001b[2mMethod: dsl.ini file\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-1000 / 3795 (2.15s)\u001b[0m\n",
      "1000-2000 / 3795 (3.67s)\u001b[0m\n",
      "2000-3000 / 3795 (1.97s)\u001b[0m\n",
      "3000-3795 / 3795 (25.52s)\u001b[0m\n",
      "===\n",
      "Records extracted: 3795\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 3795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mSearching config file credentials for default 'live' instance..\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results after filtering: 3563\n",
      "\u001b[2mDimcli - Dimensions API Client (v1.3)\u001b[0m\n",
      "\u001b[2mConnected to: <https://app.dimensions.ai/api/dsl> - DSL v2.10\u001b[0m\n",
      "\u001b[2mMethod: dsl.ini file\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-1000 / 14679 (9.59s)\u001b[0m\n",
      "1000-2000 / 14679 (6.20s)\u001b[0m\n",
      "2000-3000 / 14679 (3.49s)\u001b[0m\n",
      "3000-4000 / 14679 (2.97s)\u001b[0m\n",
      "4000-5000 / 14679 (2.83s)\u001b[0m\n",
      "5000-6000 / 14679 (2.95s)\u001b[0m\n",
      "6000-7000 / 14679 (2.76s)\u001b[0m\n",
      "7000-8000 / 14679 (26.38s)\u001b[0m\n",
      "8000-9000 / 14679 (3.35s)\u001b[0m\n",
      "9000-10000 / 14679 (5.52s)\u001b[0m\n",
      "10000-11000 / 14679 (5.94s)\u001b[0m\n",
      "11000-12000 / 14679 (2.69s)\u001b[0m\n",
      "12000-13000 / 14679 (6.18s)\u001b[0m\n",
      "13000-14000 / 14679 (3.22s)\u001b[0m\n",
      "14000-14679 / 14679 (2.92s)\u001b[0m\n",
      "===\n",
      "Records extracted: 14679\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 14679\n",
      "Total results after filtering: 14651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:32<00:00, 32.41s/it]\n",
      "100%|██████████| 3/3 [02:24<00:00, 48.26s/it]\n",
      "c:\\Users\\saknini\\Desktop\\Master Project\\LitQEval\\.venv\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\saknini\\Desktop\\Master Project\\LitQEval\\.venv\\lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m         predicted \u001b[38;5;241m=\u001b[39m i[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredicted\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m core_pubs \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcore_pubs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      8\u001b[0m core_mean_embedding \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcore_mean_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\saknini\\Desktop\\Master Project\\LitQEval\\litQeval\\eval_utils.py:272\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(base_query, predicted_query, full_data)\u001b[0m\n\u001b[0;32m    268\u001b[0m core_vs \u001b[38;5;241m=\u001b[39m Chroma(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcore_publications\u001b[39m\u001b[38;5;124m\"\u001b[39m, EMBEDDING_MODEL,\n\u001b[0;32m    269\u001b[0m                  persist_directory\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/vs/core_publications\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    271\u001b[0m core_mean_embedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(core_embeddings, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 272\u001b[0m cos_threshold \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcore_mean_embedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcore_embeddings\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mflatten()\u001b[38;5;241m.\u001b[39mmin()\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbaseline_pubs\u001b[39m\u001b[38;5;124m\"\u001b[39m: baseline_pubs,\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredicted_pubs\u001b[39m\u001b[38;5;124m\"\u001b[39m: predicted_pubs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcore_threshold\u001b[39m\u001b[38;5;124m\"\u001b[39m: cos_threshold, \n\u001b[0;32m    284\u001b[0m }\n",
      "File \u001b[1;32mc:\\Users\\saknini\\Desktop\\Master Project\\LitQEval\\.venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\saknini\\Desktop\\Master Project\\LitQEval\\.venv\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1679\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1635\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[0;32m   1636\u001b[0m \n\u001b[0;32m   1637\u001b[0m \u001b[38;5;124;03mCosine similarity, or the cosine kernel, computes similarity as the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1675\u001b[0m \u001b[38;5;124;03m       [0.57..., 0.81...]])\u001b[39;00m\n\u001b[0;32m   1676\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;66;03m# to avoid recursive import\u001b[39;00m\n\u001b[1;32m-> 1679\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_pairwise_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1681\u001b[0m X_normalized \u001b[38;5;241m=\u001b[39m normalize(X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m Y:\n",
      "File \u001b[1;32mc:\\Users\\saknini\\Desktop\\Master Project\\LitQEval\\.venv\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:185\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[1;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, ensure_2d, copy)\u001b[0m\n\u001b[0;32m    175\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m    176\u001b[0m         X,\n\u001b[0;32m    177\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m         ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m    183\u001b[0m     )\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 185\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    194\u001b[0m     Y \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m    195\u001b[0m         Y,\n\u001b[0;32m    196\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    201\u001b[0m         ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m    202\u001b[0m     )\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m precomputed:\n",
      "File \u001b[1;32mc:\\Users\\saknini\\Desktop\\Master Project\\LitQEval\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1064\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1061\u001b[0m     )\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m-> 1064\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1065\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1066\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1067\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1068\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m   1072\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m   1073\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\saknini\\Desktop\\Master Project\\LitQEval\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:123\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\saknini\\Desktop\\Master Project\\LitQEval\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:172\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    171\u001b[0m     )\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "for i in json.load(open('data/queries.json')):\n",
    "    if i[\"baseline\"] == \"Software Defect Prediction\":\n",
    "        baseline = i[\"baseline\"]\n",
    "        predicted = i[\"predicted\"]\n",
    "        break\n",
    "data = get_data(baseline, predicted)\n",
    "core_pubs = data[\"core_pubs\"]\n",
    "core_mean_embedding = data[\"core_mean_embedding\"]\n",
    "baseline_pubs = data[\"baseline_pubs\"]\n",
    "predicted_pubs = data[\"predicted_pubs\"]\n",
    "baseline_vs = data[\"baseline_vs\"]\n",
    "predicted_vs = data[\"predicted_vs\"]\n",
    "core_vs = data[\"core_vs\"]\n",
    "core_embeddigs = data[\"core_embeddings\"]\n",
    "core_threshold = data[\"core_threshold\"]\n",
    "core_embeddings = data[\"core_embeddings\"]\n",
    "predicted_embeddings = np.array([embedding for embedding in predicted_vs.get(include=[\"embeddings\"])[\"embeddings\"]])\n",
    "baseline_embeddings = np.array([embedding for embedding in baseline_vs.get(include=[\"embeddings\"])[\"embeddings\"]])\n",
    "core_mean_embedding.shape, predicted_embeddings.shape, baseline_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim = cosine_similarity(core_mean_embedding, baseline_embeddings).flatten()\n",
    "baseline_pubs[\"similarity\"] = cosine_sim\n",
    "\n",
    "core_pubs_in_baseline = baseline_pubs[baseline_pubs[\"id\"].isin(core_pubs)]\n",
    "relevent_baseline_pubs = baseline_pubs[baseline_pubs[\"similarity\"] >= core_threshold].copy()\n",
    "print(f\"Number of core publications in the baseline: {core_pubs_in_baseline.shape[0]}\")\n",
    "print(f\"Number of relevant publications in the baseline: {relevent_baseline_pubs.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted\n",
    "cosine_sim = cosine_similarity(core_mean_embedding, predicted_embeddings).flatten()\n",
    "predicted_pubs[\"similarity\"] = cosine_sim\n",
    "\n",
    "core_pubs_in_predicted = predicted_pubs[predicted_pubs[\"id\"].isin(core_pubs)]\n",
    "relevant_predicted_pubs = predicted_pubs[predicted_pubs[\"similarity\"] >= core_threshold].copy()\n",
    "print(f\"Number of core publications in the predicted: {core_pubs_in_predicted.shape[0]}\")\n",
    "print(f\"Number of relevant publications in the predicted: {relevant_predicted_pubs.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = evaluate_recall(core_pubs, baseline_pubs, predicted_pubs)\n",
    "# semnatic precision: every element that is more similar than the least similar core publication is considered relevant\n",
    "# relevant_predicted_pubs: publications that are more similar than the least similar core publication.\n",
    "pred_precision = relevant_predicted_pubs.shape[0] / predicted_pubs.shape[0] # total number of found publications\n",
    "baseline_precision = (relevent_baseline_pubs.shape[0] / baseline_pubs.shape[0]) if baseline_pubs.shape[0] > 0 else 0\n",
    "pred_f2 = fscore(pred_precision, recall[\"predicted_recall\"], 2)\n",
    "baseline_f2 = fscore(baseline_precision, recall[\"baseline_recall\"], 2)\n",
    "df = pd.DataFrame({\n",
    "    \"Semantic Precision\": [pred_precision, baseline_precision],\n",
    "    \"Recall\": [recall[\"predicted_recall\"], recall[\"baseline_recall\"]],\n",
    "    \"Semantic F2\": [pred_f2, baseline_f2]\n",
    "}, index=[\"Predicted\", \"Baseline\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimum Volume Enclosing Ellipsoid MMVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, c = mvee(core_embeddings)\n",
    "base_is_inside = is_inside_ellipse(A, c, baseline_embeddings)\n",
    "predicted_is_inside = is_inside_ellipse(A, c, predicted_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvve_prec_baseline = base_is_inside.sum() / len(base_is_inside)\n",
    "mvve_prec_predicted = predicted_is_inside.sum() / len(predicted_is_inside)\n",
    "\n",
    "mvve_df = pd.DataFrame({\n",
    "    \"MVVE Precision\": [mvve_prec_predicted, mvve_prec_baseline],\n",
    "    \"Recall\": [recall[\"predicted_recall\"], recall[\"baseline_recall\"]],\n",
    "    \"MVVE F2\": [fscore(mvve_prec_predicted, recall[\"predicted_recall\"], 2), fscore(mvve_prec_baseline, recall[\"baseline_recall\"], 2)]\n",
    "}, index=[\"Predicted\", \"Baseline\"])\n",
    "print(f\"Baseline - Inside: {base_is_inside.sum()}\")\n",
    "print(f\"Predicted - Inside: {predicted_is_inside.sum()}\")\n",
    "mvve_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    \"Query\": [predicted] + [baseline],\n",
    "    \"Recall\": [recall[\"predicted_recall\"], recall[\"baseline_recall\"]],\n",
    "    \"Semantic Precision\": [pred_precision, baseline_precision],\n",
    "    \"Semantic F2\": [pred_f2, baseline_f2],\n",
    "    \"MVVE Precision\": [mvve_prec_predicted, mvve_prec_baseline],\n",
    "    \"MVVE F2\": [fscore(mvve_prec_predicted, recall[\"predicted_recall\"], 2), fscore(mvve_prec_baseline, recall[\"baseline_recall\"], 2)]\n",
    "}, index=[\"Predicted\", \"Baseline\"])\n",
    "\n",
    "try:\n",
    "    old_results = pd.read_excel(\"results.xlsx\", index_col=0)\n",
    "    results = pd.concat([old_results, results]).drop_duplicates(subset=[\"Query\"]).round(3)\n",
    "    results.to_excel(\"results.xlsx\")\n",
    "except FileNotFoundError:\n",
    "    results.to_excel(\"results.xlsx\")\n",
    "\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"Topic\"] = results[\"Query\"].copy()\n",
    "results[\"Topic\"][0::2] = np.nan\n",
    "plt_df = results.bfill()\n",
    "plt_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(plt_df, x=\"Topic\", y=[\"Recall\", \"Semantic Precision\", \"MVVE Precision\", \"Semantic F2\", \"MVVE F2\"], title=\"Metrics for Predicted and Baseline Queries\", barmode=\"group\",\n",
    "                   facet_row=\"index\", facet_row_spacing=0.1)\n",
    "\n",
    "# Sort by value\n",
    "fig.for_each_trace(lambda t: t.update(x=t.x[::-1], y=t.y[::-1]))\n",
    "fig.for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[-1]))\n",
    "fig.update_layout(yaxis1_title=\"\", yaxis2_title=\"\", yaxis1_dtick=0.2, yaxis2_dtick=0.2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference in metrics between predicted and baseline (Recall\tSemantic Precision\tSemantic F2\tMVVE Precision\tMVVE F2\t)\n",
    "diff_df = results.loc[\"Predicted\"][[\"Recall\",\"Semantic Precision\" ,\"Semantic F2\" ,\"MVVE Precision\", \"MVVE F2\"]].values\\\n",
    "      - results.loc[\"Baseline\"][[\"Recall\",\"Semantic Precision\" ,\"Semantic F2\" ,\"MVVE Precision\", \"MVVE F2\"]].values\n",
    "\n",
    "diff_df = pd.DataFrame(diff_df.round(3), columns=[\"Recall\",\"Semantic Precision\" ,\"Semantic F2\" ,\"MVVE Precision\", \"MVVE F2\"], index=results.loc[\"Baseline\"][\"Query\"])\n",
    "diff_df = diff_df.style.map(lambda x: 'background-color: #6b0801' if x < -0.5 else 'background-color: #a82b22' if x < 0 else '')\n",
    "diff_df.format(\"{:.3f}\").set_caption(\"Difference in metrics between predicted and baseline (Red indicates a decrease in the metric in comparison to the baseline\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "litqeval-nY2J0JWW-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
