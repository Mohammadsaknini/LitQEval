{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from litQeval.eval_utils import *\n",
    "import plotly.express as px\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mSearching config file credentials for default 'live' instance..\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mDimcli - Dimensions API Client (v1.3)\u001b[0m\n",
      "\u001b[2mConnected to: <https://app.dimensions.ai/api/dsl> - DSL v2.10\u001b[0m\n",
      "\u001b[2mMethod: dsl.ini file\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-1000 / 32683 (8.37s)\u001b[0m\n",
      "1000-2000 / 32683 (3.09s)\u001b[0m\n",
      "2000-3000 / 32683 (6.30s)\u001b[0m\n",
      "3000-4000 / 32683 (3.33s)\u001b[0m\n",
      "4000-5000 / 32683 (5.26s)\u001b[0m\n",
      "5000-6000 / 32683 (2.90s)\u001b[0m\n",
      "6000-7000 / 32683 (2.68s)\u001b[0m\n",
      "7000-8000 / 32683 (6.10s)\u001b[0m\n",
      "8000-9000 / 32683 (2.73s)\u001b[0m\n",
      "9000-10000 / 32683 (5.93s)\u001b[0m\n",
      "10000-11000 / 32683 (2.83s)\u001b[0m\n",
      "11000-12000 / 32683 (3.12s)\u001b[0m\n",
      "12000-13000 / 32683 (6.15s)\u001b[0m\n",
      "13000-14000 / 32683 (2.91s)\u001b[0m\n",
      "14000-15000 / 32683 (2.61s)\u001b[0m\n",
      "15000-16000 / 32683 (6.29s)\u001b[0m\n",
      "16000-17000 / 32683 (5.99s)\u001b[0m\n",
      "17000-18000 / 32683 (3.18s)\u001b[0m\n",
      "18000-19000 / 32683 (3.07s)\u001b[0m\n",
      "19000-20000 / 32683 (3.30s)\u001b[0m\n",
      "20000-21000 / 32683 (2.50s)\u001b[0m\n",
      "21000-22000 / 32683 (5.87s)\u001b[0m\n",
      "22000-23000 / 32683 (2.60s)\u001b[0m\n",
      "23000-24000 / 32683 (2.69s)\u001b[0m\n",
      "24000-25000 / 32683 (3.42s)\u001b[0m\n",
      "25000-26000 / 32683 (2.66s)\u001b[0m\n",
      "26000-27000 / 32683 (3.27s)\u001b[0m\n",
      "27000-28000 / 32683 (2.97s)\u001b[0m\n",
      "28000-29000 / 32683 (3.57s)\u001b[0m\n",
      "29000-30000 / 32683 (3.37s)\u001b[0m\n",
      "30000-31000 / 32683 (3.57s)\u001b[0m\n",
      "31000-32000 / 32683 (3.38s)\u001b[0m\n",
      "32000-32683 / 32683 (12.21s)\u001b[0m\n",
      "===\n",
      "Records extracted: 32683\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 32683\n",
      "Total results after filtering: 30538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mSearching config file credentials for default 'live' instance..\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mDimcli - Dimensions API Client (v1.3)\u001b[0m\n",
      "\u001b[2mConnected to: <https://app.dimensions.ai/api/dsl> - DSL v2.10\u001b[0m\n",
      "\u001b[2mMethod: dsl.ini file\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-1000 / 37485 (15.14s)\u001b[0m\n",
      "1000-2000 / 37485 (4.88s)\u001b[0m\n",
      "2000-3000 / 37485 (5.07s)\u001b[0m\n",
      "3000-4000 / 37485 (6.12s)\u001b[0m\n",
      "4000-5000 / 37485 (5.21s)\u001b[0m\n",
      "5000-6000 / 37485 (5.10s)\u001b[0m\n",
      "6000-7000 / 37485 (4.31s)\u001b[0m\n",
      "7000-8000 / 37485 (4.28s)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "baseline = 'Synthetic Biology'\n",
    "predicted = \"\"\"\n",
    "(synthetic biology) OR \"genome editing\" OR \"microbial engineering\" OR \"synthetic organisms\" OR \"rna engineering\" OR \"environmental biotechnology\" OR \"bioprinting\" OR \"biomolecular engineering\" OR \"synthetic ecology\" OR \"synthetic genomics\" OR \"biomanufacturing\" OR \"biocontainment\" OR \"biodesign\" OR \"designer organisms\" OR \"chassis organisms\" OR \n",
    "((\"gene synthesis\" OR \"dna synthesis\" OR \"molecular biology\" OR \"systems biology\" OR \"bioinformatics\" OR \"cell-free systems\" OR \"protein engineering\" OR \"biotechnology\" OR \"directed evolution\" OR \"gene drives\" OR \"genetic engineering\" OR \"crispr\" OR \"synthetic pathways\" OR \"pathway engineering\" OR \"metabolic engineering\") AND (Synthetic))\n",
    "\"\"\"\n",
    "\n",
    "data = get_data(baseline, predicted)\n",
    "core_pubs = data[\"core_pubs\"]\n",
    "core_mean_embedding = data[\"core_mean_embedding\"]\n",
    "baseline_pubs = data[\"baseline_pubs\"]\n",
    "predicted_pubs = data[\"predicted_pubs\"]\n",
    "baseline_vs = data[\"baseline_vs\"]\n",
    "predicted_vs = data[\"predicted_vs\"]\n",
    "core_vs = data[\"core_vs\"]\n",
    "predicted_embeddings = np.array([embedding for embedding in predicted_vs.get(include=[\"embeddings\"])[\"embeddings\"]])\n",
    "baseline_embeddings = np.array([embedding for embedding in baseline_vs.get(include=[\"embeddings\"])[\"embeddings\"]])\n",
    "core_embeddings = np.squeeze([core_vs.get(i,include=[\"embeddings\"])[\"embeddings\"] for i in core_pubs])\n",
    "core_mean_embedding.reshape(1, -1).shape, predicted_embeddings.shape, baseline_embeddings.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline\n",
    "cosine_sim = cosine_similarity(core_mean_embedding, baseline_embeddings).flatten()\n",
    "baseline_pubs[\"similarity\"] = cosine_sim\n",
    "\n",
    "core_pubs_in_baseline = baseline_pubs[baseline_pubs[\"id\"].isin(core_pubs)]\n",
    "threshold = core_pubs_in_baseline[\"similarity\"].min()\n",
    "relevent_baseline_pubs = baseline_pubs[baseline_pubs[\"similarity\"] >= threshold].copy()\n",
    "print(f\"Number of core publications in the baseline: {core_pubs_in_baseline.shape[0]}\")\n",
    "print(f\"Number of relevant publications in the baseline: {relevent_baseline_pubs.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted\n",
    "cosine_sim = cosine_similarity(core_mean_embedding, predicted_embeddings).flatten()\n",
    "predicted_pubs[\"similarity\"] = cosine_sim\n",
    "\n",
    "core_pubs_in_predicted = predicted_pubs[predicted_pubs[\"id\"].isin(core_pubs)]\n",
    "threshold = core_pubs_in_predicted[\"similarity\"].min()\n",
    "relevant_predicted_pubs = predicted_pubs[predicted_pubs[\"similarity\"] >= threshold].copy()\n",
    "print(f\"Number of core publications in the predicted: {core_pubs_in_predicted.shape[0]}\")\n",
    "print(f\"Number of relevant publications in the predicted: {relevant_predicted_pubs.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = evaluate_recall(core_pubs, baseline_pubs, predicted_pubs)\n",
    "# semnatic precision: every element that is more similar than the least similar core publication is considered relevant\n",
    "# relevant_predicted_pubs: publications that are more similar than the least similar core publication.\n",
    "pred_precision = relevant_predicted_pubs.shape[0] / predicted_pubs.shape[0] # total number of found publications\n",
    "baseline_precision = (relevent_baseline_pubs.shape[0] / baseline_pubs.shape[0]) if baseline_pubs.shape[0] > 0 else 0\n",
    "pred_f2 = fscore(pred_precision, recall[\"predicted_recall\"], 2)\n",
    "baseline_f2 = fscore(baseline_precision, recall[\"baseline_recall\"], 2)\n",
    "df = pd.DataFrame({\n",
    "    \"Semantic Precision\": [pred_precision, baseline_precision],\n",
    "    \"Recall\": [recall[\"predicted_recall\"], recall[\"baseline_recall\"]],\n",
    "    \"Semantic F2\": [pred_f2, baseline_f2]\n",
    "}, index=[\"Predicted\", \"Baseline\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimum Volume Enclosing Ellipsoid MMVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.linalg as la\n",
    "\n",
    "def mvee(points, tol=0.0001):\n",
    "    \"\"\"\n",
    "    Finds the ellipse equation in \"center form\"\n",
    "    (x-c).T * A * (x-c) = 1\n",
    "    \"\"\"\n",
    "    N, d = points.shape\n",
    "    Q = np.column_stack((points, np.ones(N))).T\n",
    "    err = tol+1.0\n",
    "    u = np.ones(N)/N\n",
    "    while err > tol:\n",
    "        # assert u.sum() == 1 # invariant\n",
    "        X = np.dot(np.dot(Q, np.diag(u)), Q.T)\n",
    "        M = np.diag(np.dot(np.dot(Q.T, la.inv(X)), Q))\n",
    "        jdx = np.argmax(M)\n",
    "        step_size = (M[jdx]-d-1.0)/((d+1)*(M[jdx]-1.0))\n",
    "        new_u = (1-step_size)*u\n",
    "        new_u[jdx] += step_size\n",
    "        err = la.norm(new_u-u)\n",
    "        u = new_u\n",
    "    c = np.dot(u, points)\n",
    "    A = la.inv(np.dot(np.dot(points.T, np.diag(u)), points)\n",
    "               - np.multiply.outer(c, c))/d\n",
    "    return A, c\n",
    "\n",
    "A, c = mvee(core_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_is_inside = is_inside_ellipse(A, c, baseline_embeddings)\n",
    "predicted_is_inside = is_inside_ellipse(A, c, predicted_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvve_prec_baseline = base_is_inside.sum() / len(base_is_inside)\n",
    "mvve_prec_predicted = predicted_is_inside.sum() / len(predicted_is_inside)\n",
    "\n",
    "mvve_df = pd.DataFrame({\n",
    "    \"MVVE Precision\": [mvve_prec_predicted, mvve_prec_baseline],\n",
    "    \"Recall\": [recall[\"predicted_recall\"], recall[\"baseline_recall\"]],\n",
    "    \"MVVE F2\": [fscore(mvve_prec_predicted, recall[\"predicted_recall\"], 2), fscore(mvve_prec_baseline, recall[\"baseline_recall\"], 2)]\n",
    "}, index=[\"Predicted\", \"Baseline\"])\n",
    "print(f\"Baseline - Inside: {base_is_inside.sum()}\")\n",
    "print(f\"Predicted - Inside: {predicted_is_inside.sum()}\")\n",
    "mvve_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    \"Query\": [predicted] + [baseline],\n",
    "    \"Recall\": [recall[\"predicted_recall\"], recall[\"baseline_recall\"]],\n",
    "    \"Semantic Precision\": [pred_precision, baseline_precision],\n",
    "    \"Semantic F2\": [pred_f2, baseline_f2],\n",
    "    \"MVVE Precision\": [mvve_prec_predicted, mvve_prec_baseline],\n",
    "    \"MVVE F2\": [fscore(mvve_prec_predicted, recall[\"predicted_recall\"], 2), fscore(mvve_prec_baseline, recall[\"baseline_recall\"], 2)]\n",
    "}, index=[\"Predicted\", \"Baseline\"])\n",
    "\n",
    "try:\n",
    "    old_results = pd.read_excel(\"results.xlsx\", index_col=0)\n",
    "    results = pd.concat([old_results, results]).drop_duplicates(subset=[\"Query\"]).round(3)\n",
    "    results.to_excel(\"results.xlsx\")\n",
    "except FileNotFoundError:\n",
    "    results.to_excel(\"results.xlsx\")\n",
    "\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"Topic\"] = results[\"Query\"].copy()\n",
    "results[\"Topic\"][0::2] = np.nan\n",
    "plt_df = results.bfill()\n",
    "plt_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(plt_df, x=\"Topic\", y=[\"Recall\", \"Semantic Precision\", \"MVVE Precision\", \"Semantic F2\", \"MVVE F2\"], title=\"Metrics for Predicted and Baseline Queries\", barmode=\"group\",\n",
    "                   facet_row=\"index\", facet_row_spacing=0.1)\n",
    "\n",
    "# Sort by value\n",
    "fig.for_each_trace(lambda t: t.update(x=t.x[::-1], y=t.y[::-1]))\n",
    "fig.for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[-1]))\n",
    "fig.update_layout(yaxis1_title=\"\", yaxis2_title=\"\", yaxis1_dtick=0.2, yaxis2_dtick=0.2)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "litqeval-nY2J0JWW-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
