{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The goal of this notebook is to do an ablation study with differnet semantic preicision metrics, to see how they perform and correlate with one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from plotly.subplots import make_subplots\n",
    "from litQeval.eval_utils import *\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import plotly.io as pio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "pio.templates.default = \"seaborn\"\n",
    "COLORS = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd',\n",
    "          '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "PLOT_CONFIGS = dict(\n",
    "    title_x=0.5, title_font_size=30, title_font_family=\"Modern Computer\", font_family=\"Modern Computer\",\n",
    "    xaxis_title=\"\", yaxis_title=\"\", showlegend=True, legend_title=\"\",\n",
    "    xaxis_tickfont_size=15, yaxis_tickfont_size=15, legend_font_size=20, legend_itemsizing=\"constant\",\n",
    "    legend_orientation=\"h\", legend_yanchor=\"bottom\", legend_y=-0.3, legend_xanchor=\"center\", legend_x=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [i[\"baseline\"] for i in json.load(open('data/queries.json'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scatters():\n",
    "    plot = make_subplots(rows=len(topics)//2, cols=2, subplot_titles=topics)\n",
    "    for idx, topic in tqdm(enumerate(topics), total=len(topics)):\n",
    "        data = get_evaluation_data(topic)\n",
    "        umap_core_embeddings = data[\"umap_core_embeddings\"]\n",
    "        df = data[\"df\"]\n",
    "\n",
    "        plot.add_traces([\n",
    "            go.Scattergl(\n",
    "                x=df[df[\"Source\"] == \"Predicted\"][\"UMAP1\"],\n",
    "                y=df[df[\"Source\"] == \"Predicted\"][\"UMAP2\"],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(color=COLORS[0], size=5),\n",
    "                name=\"Predicted\",\n",
    "                opacity=0.5,\n",
    "                showlegend=False,\n",
    "            ),\n",
    "            go.Scattergl(\n",
    "                x=df[df[\"Source\"] == \"Baseline\"][\"UMAP1\"],\n",
    "                y=df[df[\"Source\"] == \"Baseline\"][\"UMAP2\"],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(color=COLORS[1], size=5),\n",
    "                name=\"Baseline\",\n",
    "                opacity=0.5,\n",
    "                showlegend=False,\n",
    "            ),\n",
    "            go.Scattergl(\n",
    "                x=umap_core_embeddings[:, 0],\n",
    "                y=umap_core_embeddings[:, 1],\n",
    "                mode=\"markers\",\n",
    "                opacity=0.5,\n",
    "                marker=dict(color=\"red\", size=5),\n",
    "                showlegend=False,\n",
    "            ),\n",
    "        ],\n",
    "            rows=idx//2+1, cols=idx % 2+1)\n",
    "\n",
    "    plot.update_layout(height=2000, showlegend=False)\n",
    "    plot.show()\n",
    "# create_scatters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metric investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = topics[7]\n",
    "data = get_evaluation_data(topic)\n",
    "baseline_pubs = data[\"baseline_pubs\"]\n",
    "predicted_pubs = data[\"predicted_pubs\"]\n",
    "core_pubs = data[\"core_pubs\"]\n",
    "\n",
    "baseline_vs = data[\"baseline_vs\"]\n",
    "predicted_vs = data[\"predicted_vs\"]\n",
    "core_vs = data[\"core_vs\"]\n",
    "threshold = data[\"core_threshold\"]\n",
    "\n",
    "umap_embeddings = data[\"umap_embeddings\"]\n",
    "umap_core_embeddings = data[\"umap_core_embeddings\"]\n",
    "core_mean_embedding = data[\"core_mean_embedding\"]\n",
    "\n",
    "embeddings = data[\"embeddings\"]\n",
    "baseline_embeddings = data[\"baseline_embeddings\"]\n",
    "predicted_embeddings = data[\"predicted_embeddings\"]\n",
    "core_embeddings = data[\"core_embeddings\"]\n",
    "\n",
    "baseline_umap_embeddings = data[\"baseline_umap_embeddings\"]\n",
    "predicted_umap_embeddings = data[\"predicted_umap_embeddings\"]\n",
    "baseline_core_umap_embeddings = data[\"baseline_core_umap_embeddings\"]\n",
    "predicted_core_umap_embeddings = data[\"predicted_core_umap_embeddings\"]\n",
    "\n",
    "df = data[\"df\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_traces([\n",
    "    go.Scattergl(\n",
    "        x=df[df[\"Source\"] == \"Predicted\"][\"UMAP1\"],\n",
    "        y=df[df[\"Source\"] == \"Predicted\"][\"UMAP2\"],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(color=COLORS[0], size=5),\n",
    "        name=\"Predicted\",\n",
    "        opacity=0.5,\n",
    "    ),\n",
    "    go.Scattergl(\n",
    "        x=df[df[\"Source\"] == \"Baseline\"][\"UMAP1\"],\n",
    "        y=df[df[\"Source\"] == \"Baseline\"][\"UMAP2\"],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(color=COLORS[1], size=5),\n",
    "        name=\"Baseline\",\n",
    "        opacity=0.5,\n",
    "    ),\n",
    "    go.Scattergl(\n",
    "        x=umap_core_embeddings[:, 0],\n",
    "        y=umap_core_embeddings[:, 1],\n",
    "        mode=\"markers\",\n",
    "        opacity=0.8,\n",
    "        marker=dict(color=\"red\", size=5),\n",
    "        name=\"Core\",\n",
    "    ),\n",
    "])\n",
    "fig.update_traces(marker=dict(size=4))\n",
    "fig.update_layout(**PLOT_CONFIGS,title=topic)\n",
    "baseline_recall = recall(core_pubs[\"id\"], baseline_pubs[\"id\"])\n",
    "predicted_recall = recall(core_pubs[\"id\"], predicted_pubs[\"id\"])\n",
    "baseline_cp = set(baseline_pubs[\"id\"]).intersection(core_pubs[\"id\"])\n",
    "predicted_cp = set(predicted_pubs[\"id\"]).intersection(core_pubs[\"id\"])\n",
    "print(f\"Baseline recall: {round(baseline_recall,3)} - ({len(baseline_cp)}/{len(core_pubs)} were found)\")\n",
    "print(f\"Predicted recall: {round(predicted_recall,3)} - ({len(predicted_cp)}/{len(core_pubs)} were found)\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 100\n",
    "hists = []\n",
    "frequenceies = []\n",
    "for i in tqdm(embeddings):\n",
    "    frequency, hist = np.histogram(i, bins=n_bins)\n",
    "    hists.append(hist)\n",
    "    frequenceies.append(frequency)\n",
    "x_ticks = np.array(hists).mean(axis=0)\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.imshow(frequenceies, cmap=\"inferno\", aspect=\"auto\")\n",
    "plt.colorbar()\n",
    "plt.xticks(np.arange(0, n_bins, int(n_bins*0.1)+1),\n",
    "           labels=np.round(x_ticks[np.arange(0, n_bins, int(n_bins*0.1)+1)], 2))\n",
    "plt.ylabel(\"Embeddings\")\n",
    "plt.title(\"Histograms of the embeddings\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_baseline_relevant, cos_baseline_cores = eval_cosine(\n",
    "    df, \"Baseline\", core_mean_embedding, baseline_core_umap_embeddings, baseline_embeddings, core_pubs, topic, True)\n",
    "cos_predicted_relevant, cos_predicted_cores = eval_cosine(\n",
    "    df, \"Predicted\", core_mean_embedding, predicted_core_umap_embeddings, predicted_embeddings, core_pubs, topic, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.linspace(0.4, 1, 100)\n",
    "baseline_items = []\n",
    "predicted_items = []\n",
    "threshold_df = df.copy()\n",
    "threshold_df[\"similarity\"] = cosine_similarity(core_mean_embedding, embeddings).flatten()\n",
    "for threshold in thresholds:\n",
    "    n_pubs_baseline = threshold_df[(threshold_df[\"similarity\"] >= threshold) & (\n",
    "        threshold_df[\"Source\"] == \"Baseline\")].shape[0]\n",
    "    n_pubs_predicted = threshold_df[(threshold_df[\"similarity\"] >= threshold) & (\n",
    "        threshold_df[\"Source\"] == \"Predicted\")].shape[0]\n",
    "\n",
    "    n_core_pubs_baseline = len(set(threshold_df[(threshold_df[\"similarity\"] >= threshold) & (\n",
    "        threshold_df[\"Source\"] == \"Baseline\")][\"id\"]).intersection(core_pubs[\"id\"]))\n",
    "    n_core_pubs_predicted = len(set(threshold_df[(threshold_df[\"similarity\"] >= threshold) & (\n",
    "        threshold_df[\"Source\"] == \"Predicted\")][\"id\"]).intersection(core_pubs[\"id\"]))\n",
    "    baseline_items.append(\n",
    "        {\"threshold\": threshold, \"n_pubs\": n_pubs_baseline, \"n_core_pubs\": n_core_pubs_baseline})\n",
    "    predicted_items.append(\n",
    "        {\"threshold\": threshold, \"n_pubs\": n_pubs_predicted, \"n_core_pubs\": n_core_pubs_predicted})\n",
    "\n",
    "baseline_df = pd.DataFrame(baseline_items)\n",
    "predicted_df = pd.DataFrame(predicted_items)\n",
    "fig = go.Figure()\n",
    "fig.add_traces([\n",
    "    go.Scatter(x=baseline_df[\"threshold\"], y=baseline_df[\"n_core_pubs\"],\n",
    "               customdata=baseline_df[\"n_pubs\"],\n",
    "               name=\"Baseline\", mode=\"lines\", marker_color=COLORS[1],\n",
    "               hovertemplate=\"N Pubs: %{y} <br> N Core Pubs: %{customdata}\"),\n",
    "\n",
    "    go.Scatter(x=predicted_df[\"threshold\"], y=predicted_df[\"n_core_pubs\"],\n",
    "               name=\"Predicted\", mode=\"lines\", marker=dict(color=COLORS[0]),\n",
    "                customdata=predicted_df[\"n_pubs\"],\n",
    "                hovertemplate=\"N Pubs: %{y} <br> N Core Pubs: %{customdata}\")\n",
    "])\n",
    "fig.update_layout(\n",
    "    **PLOT_CONFIGS, title=\"Number of Core Publications vs Threshold\", hovermode=\"x\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_baseline_k, cluster_baseline_relevant, cluster_baseline_core = eval_clustering(\n",
    "    df, \"Baseline\", baseline_embeddings, baseline_cp, topic, True)\n",
    "cluster_predicted_k, cluster_predicted_relevant, cluster_predicted_core = eval_clustering(\n",
    "    df, \"Predicted\", predicted_embeddings, predicted_cp, topic, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if baseline_core_umap_embeddings.size != 0 and baseline_core_umap_embeddings.shape[0] >= 3:\n",
    "    mvee_baseline_relevant = eval_mvee(df, \"Baseline\", baseline_core_umap_embeddings, baseline_umap_embeddings, topic, True)\n",
    "else:\n",
    "    mvee_baseline_relevant = pd.DataFrame({\"id\": []})\n",
    "if predicted_core_umap_embeddings.size != 0 and predicted_core_umap_embeddings.shape[0] >= 3:\n",
    "    mvee_predicted_relevant = eval_mvee(df, \"Predicted\", predicted_core_umap_embeddings, predicted_umap_embeddings, topic, True)\n",
    "else:\n",
    "    mvee_predicted_relevant = pd.DataFrame({\"id\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if baseline_core_umap_embeddings.size != 0 and baseline_core_umap_embeddings.shape[0] >= 3:\n",
    "    hull_baseline_relevant = eval_hull(df, \"Baseline\", baseline_core_umap_embeddings, baseline_umap_embeddings, topic, True)\n",
    "else:\n",
    "    hull_baseline_relevant = pd.DataFrame({\"id\": []})\n",
    "if predicted_core_umap_embeddings.size != 0 and predicted_core_umap_embeddings.shape[0] >= 3:\n",
    "    hull_predicted_relevant = eval_hull(df, \"Predicted\", predicted_core_umap_embeddings, predicted_umap_embeddings, topic, True)\n",
    "else:\n",
    "    hull_predicted_relevant = pd.DataFrame({\"id\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# To take the number of the publications into account\n",
    "def decay_function(t, p=2, q=3):\n",
    "    return (1 - t**p)**q\n",
    "\n",
    "v = 50000  # Threshold value\n",
    "temp = np.linspace(0, 50000, 100)\n",
    "custom = decay_function(temp / v) \n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_traces([\n",
    "    go.Scatter(x=temp, y=custom, mode='lines', name=\"Custom Decay\"),\n",
    "])\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Comparison of Decay Functions\",\n",
    "    xaxis_title=\"Number of Publications\",\n",
    "    yaxis_title=\"Decay Factor\",\n",
    "    legend_title=\"Decay Type\",\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 2\n",
    "\n",
    "cos_baseline_precision = cos_baseline_relevant.shape[0] / len(baseline_pubs)\n",
    "cos_baseline_recall = len(cos_baseline_cores) / len(core_pubs)\n",
    "cos_baseline_f2 = fscore(cos_baseline_precision, cos_baseline_recall, cos_baseline_relevant.shape[0], beta)\n",
    "cos_predicted_precision = cos_predicted_relevant.shape[0] / len(predicted_pubs)\n",
    "cos_predicted_recall = len(cos_predicted_cores) / len(core_pubs)\n",
    "cos_predicted_f2 = fscore(cos_predicted_precision, cos_predicted_recall, cos_predicted_relevant.shape[0], beta)\n",
    "\n",
    "\n",
    "cluster_baseline_precision = cluster_baseline_relevant.shape[0] / len(baseline_pubs)\n",
    "cluster_baseline_recall = cluster_baseline_core / len(core_pubs)\n",
    "cluster_baseline_f2 = fscore(cluster_baseline_precision, cluster_baseline_recall, cluster_baseline_relevant.shape[0], beta)\n",
    "cluster_predicted_precision = cluster_predicted_relevant.shape[0] / len(predicted_pubs)\n",
    "cluster_predicted_recall = cluster_predicted_core / len(core_pubs)\n",
    "cluster_predicted_f2 = fscore(cluster_predicted_precision, cluster_predicted_recall, cluster_predicted_relevant.shape[0], beta)\n",
    "\n",
    "mvee_baseline_precision = mvee_baseline_relevant.shape[0] / len(baseline_pubs)\n",
    "mvee_baseline_recall = 1\n",
    "mvee_baseline_f2 = fscore(mvee_baseline_precision, mvee_baseline_recall, mvee_baseline_relevant.shape[0], beta)\n",
    "mvee_predicted_precision = mvee_predicted_relevant.shape[0] / len(predicted_pubs)\n",
    "mvee_predicted_recall = 1\n",
    "mvee_predicted_f2 = fscore(mvee_predicted_precision, mvee_predicted_recall, mvee_predicted_relevant.shape[0], beta)\n",
    "\n",
    "hull_baseline_precision = hull_baseline_relevant.shape[0] / len(baseline_pubs)\n",
    "hull_baseline_recall = 1\n",
    "hull_baseline_f2 = fscore(hull_baseline_precision, hull_baseline_recall, hull_baseline_relevant.shape[0], beta)\n",
    "hull_predicted_precision = hull_predicted_relevant.shape[0] / len(predicted_pubs)\n",
    "hull_predicted_recall = 1\n",
    "hull_predicted_f2 = fscore(hull_predicted_precision, hull_predicted_recall, hull_predicted_relevant.shape[0], beta)\n",
    "\n",
    "intersecting_baseline_relevant = set(cos_baseline_relevant[\"id\"]).intersection(\n",
    "                                set(cluster_baseline_relevant[\"id\"]))\\\n",
    "                                .intersection(set(mvee_baseline_relevant[\"id\"]))\\\n",
    "                                .intersection(set(hull_baseline_relevant[\"id\"]))\n",
    "intersecting_predicted_relevant = set(cos_predicted_relevant[\"id\"]).intersection(\n",
    "                                set(cluster_predicted_relevant[\"id\"]))\\\n",
    "                                .intersection(set(mvee_predicted_relevant[\"id\"]))\\\n",
    "                                .intersection(set(hull_predicted_relevant[\"id\"]))\n",
    "\n",
    "intersecting_baseline_core = intersecting_baseline_relevant.intersection(baseline_cp)\n",
    "intersecting_predicted_core = intersecting_predicted_relevant.intersection(predicted_cp)\n",
    "\n",
    "intersecting_baseline_precision = len(intersecting_baseline_relevant) / len(baseline_pubs)\n",
    "intersecting_baseline_recall = len(intersecting_baseline_core) / len(core_pubs)\n",
    "intersecting_baseline_f2 = fscore(intersecting_baseline_precision, intersecting_baseline_recall, len(intersecting_baseline_relevant), beta)\n",
    "intersecting_predicted_precision = len(intersecting_predicted_relevant) / len(predicted_pubs)\n",
    "intersecting_predicted_recall = len(intersecting_predicted_core) / len(core_pubs)\n",
    "intersecting_predicted_f2 = fscore(intersecting_predicted_precision, intersecting_predicted_recall, len(intersecting_predicted_relevant), beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Results Summary:\")\n",
    "print(f\"- Predicted Recall: {round(baseline_recall, 3)} ({len(predicted_cp)}/{len(core_pubs)} core publications found)\")\n",
    "print(f\"- Baseline Recall: {round(predicted_recall, 3)} ({len(baseline_cp)}/{len(core_pubs)} core publications found)\")\n",
    "print(\"--\"*20)\n",
    "\n",
    "print(f\"- Cosine Similarity:\")\n",
    "print(f\"• Baseline F2 Score: {cos_baseline_f2}\")\n",
    "print(f\"  • Baseline Relevant: {cos_baseline_relevant.shape[0]}/{len(baseline_pubs)}\")\n",
    "print(f\"  • Baseline Core: {len(cos_baseline_cores)}/{len(baseline_cp)}\")\n",
    "print(f\"• Predicted F2 Score: {cos_predicted_f2}\")\n",
    "print(f\"  • Predicted Relevant: {cos_predicted_relevant.shape[0]}/{len(predicted_pubs)}\")\n",
    "print(f\"  • Predicted Core: {len(cos_predicted_cores)}/{len(predicted_cp)}\")\n",
    "print(\"--\"*20)\n",
    "\n",
    "print(f\"Cluster Results:\")\n",
    "print(f\"• Baseline F2 Score: {cluster_baseline_f2}\")\n",
    "print(f\"  • Baseline Best K: {cluster_baseline_k}\")\n",
    "print(f\"  • Baseline Publications in Best Cluster: {cluster_baseline_relevant.shape[0]} / {len(baseline_pubs)}\")\n",
    "print(f\"  • Baseline Core Publications in Best Cluster: {cluster_baseline_core}/{len(baseline_cp)}\")\n",
    "print(f\"• Predicted F2 Score: {cluster_predicted_f2}\")\n",
    "print(f\"  • Predicted Best K: {cluster_predicted_k}\")\n",
    "print(f\"  • Predicted Publications in Best Cluster: {cluster_predicted_relevant.shape[0]} / {len(predicted_pubs)}\")\n",
    "print(f\"  • Predicted Core Publications in Best Cluster: {cluster_predicted_core}/{len(predicted_cp)}\")\n",
    "print(\"--\"*20)\n",
    "\n",
    "\n",
    "print(f\"- MVEE Results:\")\n",
    "print(f\"• Baseline F2 Score: {mvee_baseline_f2}\")\n",
    "print(f\"  • Relevant Baseline Publications (Inside MVEE): {mvee_baseline_relevant.shape[0]} / {len(baseline_pubs)}\")\n",
    "print(f\"• Predicted F2 Score: {mvee_predicted_f2}\")\n",
    "print(f\"  • Relevant Predicted Publications (Inside MVEE): {mvee_predicted_relevant.shape[0]} / {len(predicted_pubs)}\")\n",
    "print(\"--\"*20)\n",
    "\n",
    "print(f\"- Hull Results:\")\n",
    "print(f\"• Baseline F2 Score: {hull_baseline_f2}\")\n",
    "print(f\"  • Relevant Baseline Publications (Inside Hull): {hull_baseline_relevant.shape[0]} / {len(baseline_pubs)}\")\n",
    "print(f\"• Predicted F2 Score: {hull_predicted_f2}\")\n",
    "print(f\"  • Relevant Predicted Publications (Inside Hull): {hull_predicted_relevant.shape[0]} / {len(predicted_pubs)}\")\n",
    "print(\"--\"*20)\n",
    "\n",
    "\n",
    "print(\" - Aggregated Results:\")\n",
    "print(f\"• Baseline F2 Score: {intersecting_baseline_f2}\")\n",
    "print(f\"  • Baseline: {len(intersecting_baseline_relevant)}/{len(baseline_pubs)}\")\n",
    "print(f\"  • Baseline Core: {len(intersecting_baseline_core)}/{len(baseline_cp)}\")\n",
    "print(f\"• Predicted F2 Score: {intersecting_predicted_f2}\")\n",
    "print(f\"  • Predicted: {len(intersecting_predicted_relevant)}/{len(predicted_pubs)}\")\n",
    "print(f\"  • Predicted Core: {len(intersecting_predicted_core)}/{len(predicted_cp)}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "litqeval-nY2J0JWW-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
