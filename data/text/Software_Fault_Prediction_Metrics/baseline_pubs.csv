id,title,abstract
pub.1166427174,Evaluating the effectiveness of decomposed Halstead Metrics in software fault prediction,"The occurrence of faults in software systems represents an inevitable predicament. Testing is the most common means to detect such faults; however, exhaustive testing is not feasible for any nontrivial system. Software fault prediction (SFP), which identifies software components that are more prone to errors, seeks to supplement the testing process. Thus, testing efforts can be focused on such modules. Various approaches exist for SFP, with machine learning (ML) emerging as the prevailing methodology. ML-based SFP relies on a wide range of metrics, ranging from file-level and class-level to method-level and even line-level metrics. More granularized metrics are expected to possess a higher degree of micro-level coverage of the code. The Halstead metric suite offers coverage at the line level and has been extensively employed across diverse domains such as fault prediction, quality assessment, and similarity approximation for the past three decades. In this article, we propose to decompose Halstead base metrics and evaluate their fault prediction capability. The Halstead base metrics consist of operators and operands. In the context of the Java language, we partition operators into five distinct categories, <i>i.e.</i>, assignment operators, arithmetic operators, logical operators, relational operators, and all other types of operators. Similarly, operands are classified into two classes: constants and variables. For the purpose of empirical evaluation, two experiments were designed. In the first experiment, the Halstead base metrics were used along with McCabe, Lines of Code (LoC), and Halstead-derived metrics as predictors. In the second experiment, decomposed Halstead base metrics were used along with McCabe, LoC, and Halstead-derived metrics. Five public datasets were selected for the experiments. The ML classifiers used included logistic regression, naïve Bayes, decision tree, multilayer perceptron, random forest, and support vector machines. The ML classifiers' effectiveness was assessed through metrics such as accuracy, F-measure, and AUC. Accuracy saw an enhancement from 0.82 to 0.97, while F-measure exhibited improvement from 0.81 to 0.99. Correspondingly, the AUC value advanced from 0.79 to 0.99. These findings highlight the superior performance of decomposed Halstead metrics, as opposed to the original Halstead base metrics, in predicting faults across all datasets."
pub.1146605593,Machine Learning-Based Software Defect Prediction for Mobile Applications: A Systematic Literature Review,"Software defect prediction studies aim to predict defect-prone components before the testing stage of the software development process. The main benefit of these prediction models is that more testing resources can be allocated to fault-prone modules effectively. While a few software defect prediction models have been developed for mobile applications, a systematic overview of these studies is still missing. Therefore, we carried out a Systematic Literature Review (SLR) study to evaluate how machine learning has been applied to predict faults in mobile applications. This study defined nine research questions, and 47 relevant studies were selected from scientific databases to respond to these research questions. Results show that most studies focused on Android applications (i.e., 48%), supervised machine learning has been applied in most studies (i.e., 92%), and object-oriented metrics were mainly preferred. The top five most preferred machine learning algorithms are Naïve Bayes, Support Vector Machines, Logistic Regression, Artificial Neural Networks, and Decision Trees. Researchers mostly preferred Object-Oriented metrics. Only a few studies applied deep learning algorithms including Long Short-Term Memory (LSTM), Deep Belief Networks (DBN), and Deep Neural Networks (DNN). This is the first study that systematically reviews software defect prediction research focused on mobile applications. It will pave the way for further research in mobile software fault prediction and help both researchers and practitioners in this field."
pub.1110660656,Entropy Churn Metrics for Fault Prediction in Software Systems,"Fault prediction is an important research area that aids software development and the maintenance process. It is a field that has been continuously improving its approaches in order to reduce the fault resolution time and effort. With an aim to contribute towards building new approaches for fault prediction, this paper proposes Entropy Churn Metrics (ECM) based on History Complexity Metrics (HCM) and Churn of Source Code Metrics (CHU). The study also compares performance of ECM with that of HCM. The performance of both these metrics is compared for 14 subsystems of 5different software projects: Android, Eclipse, Apache Http Server, Eclipse C/C++ Development Tooling (CDT), and Mozilla Firefox. The study also analyses the software subsystems on three parameters: (i) distribution of faults, (ii) subsystem size, and (iii) programming language, to determine which characteristics of software systems make HCM or ECM more preferred over others."
pub.1138632333,Exclusive use and evaluation of inheritance metrics viability in software fault prediction—an experimental study,"Software Fault Prediction (SFP) assists in the identification of faulty classes, and software metrics provide us with a mechanism for this purpose. Besides others, metrics addressing inheritance in Object-Oriented (OO) are important as these measure depth, hierarchy, width, and overriding complexity of the software. In this paper, we evaluated the exclusive use, and viability of inheritance metrics in SFP through experiments. We perform a survey of inheritance metrics whose data sets are publicly available, and collected about 40 data sets having inheritance metrics. We cleaned, and filtered them, and captured nine inheritance metrics. After preprocessing, we divided selected data sets into all possible combinations of inheritance metrics, and then we merged similar metrics. We then formed 67 data sets containing only inheritance metrics that have nominal binary class labels. We performed a model building, and validation for Support Vector Machine(SVM). Results of Cross-Entropy, Accuracy, F-Measure, and AUC advocate viability of inheritance metrics in software fault prediction. Furthermore, ic, noc, and dit metrics are helpful in reduction of error entropy rate over the rest of the 67 feature sets."
pub.1138769942,Vovel metrics—novel coupling metrics for improved software fault prediction,"Software is a complex entity, and its development needs careful planning and a high amount of time and cost. To assess quality of program, software measures are very helpful. Amongst the existing measures, coupling is an important design measure, which computes the degree of interdependence among the entities of a software system. Higher coupling leads to cognitive complexity and thus a higher probability occurrence of faults. Well in time prediction of fault-prone modules assists in saving time and cost of testing. This paper aims to capture important aspects of coupling and then assess the effectiveness of these aspects in determining fault-prone entities in the software system. We propose two coupling metrics, i.e., Vovel-in and Vovel-out, that capture the level of coupling and the volume of information flow. We empirically evaluate the effectiveness of the Vovel metrics in determining the fault-prone classes using five projects, i.e., Eclipse JDT, Equinox framework, Apache Lucene, Mylyn, and Eclipse PDE UI. Model building is done using univariate logistic regression and later Spearman correlation coefficient is computed with the existing coupling metrics to assess the coverage of unique information. Finally, the least correlated metrics are used for building multivariate logistic regression with and without the use of Vovel metrics, to assess the effectiveness of Vovel metrics. The results show the proposed metrics significantly improve the predicting of fault prone classes. Moreover, the proposed metrics cover a significant amount of unique information which is not covered by the existing well-known coupling metrics, i.e., CBO, RFC, Fan-in, and Fan-out. This paper, empirically evaluates the impact of coupling metrics, and more specifically the importance of level and volume of coupling in software fault prediction. The results advocate the prudent addition of proposed metrics due to their unique information coverage and significant predictive ability."
pub.1035482914,Identifying influential metrics in the combined metrics approach of fault prediction,"Fault prediction is a pre-eminent area of empirical software engineering which has witnessed a huge surge over the last couple of decades. In the development of a fault prediction model, combination of metrics results in better explanatory power of the model. Since the metrics used in combination are often correlated, and do not have an additive effect, the impact of a metric on another i.e. interaction should be taken into account. The effect of interaction in developing regression based fault prediction models is uncommon in software engineering; however two terms and three term interactions are analyzed in detail in social and behavioral sciences. Beyond three terms interactions are scarce, because interaction effects at such a high level are difficult to interpret. From our earlier findings (Softw Qual Prof 15(3):15-23) we statistically establish the pertinence of considering the interaction between metrics resulting in a considerable improvement in the explanatory power of the corresponding predictive model. However, in the aforesaid approach, the number of variables involved in fault prediction also shows a simultaneous increment with interaction. Furthermore, the interacting variables do not contribute equally to the prediction capability of the model.This study contributes towards the development of an efficient predictive model involving interaction among predictive variables with a reduced set of influential terms, obtained by applying stepwise regression."
pub.1142250071,Inheritance metrics feats in unsupervised learning to classify unlabeled datasets and clusters in fault prediction,"Fault prediction is a necessity to deliver high-quality software. The absence of training data and mechanism to labeling a cluster faulty or fault-free is a topic of concern in software fault prediction (SFP). Inheritance is an important feature of object-oriented development, and its metrics measure the complexity, depth, and breadth of software. In this paper, we aim to experimentally validate how much inheritance metrics are helpful to classify unlabeled data sets besides conceiving a novel mechanism to label a cluster as faulty or fault-free. We have collected ten public data sets that have inheritance and C&K metrics. Then, these base datasets are further split into two datasets labeled as C&K with inheritance and the C&K dataset for evaluation. K-means clustering is applied, Euclidean formula to compute distances and then label clusters through the average mechanism. Finally, TPR, Recall, Precision, F1 measures, and ROC are computed to measure performance which showed an adequate impact of inheritance metrics in SFP specifically classifying unlabeled datasets and correct classification of instances. The experiment also reveals that the average mechanism is suitable to label clusters in SFP. The quality assurance practitioners can benefit from the utilization of metrics associated with inheritance for labeling datasets and clusters."
pub.1142562832,Software Fault Localization through Aggregation-Based Neural Ranking for Static and Dynamic Features Selection,"The automatic localization of software faults plays a critical role in assisting software professionals in fixing problems quickly. Despite various existing models for fault tolerance based on static features, localization is still challenging. By considering the dynamic features, the capabilities of the fault recognition models will be significantly enhanced. The current study proposes a model that effectively ranks static and dynamic parameters through Aggregation-Based Neural Ranking (ABNR). The proposed model includes rank lists produced by self-attention layers using rank aggregation mechanisms to merge them into one aggregated rank list. The rank list would yield the suspicious code statements in descending order of the rank. The performance of ABNR is evaluated against the open-source dataset for fault prediction. ABNR model has exhibited noticeable performance in fault localization. The proposed model is evaluated with other existing models like Ochiai, Fault localization technique based on complex network theory, Tarantula, Jaccard, and software-network centrality measure concerning metrics like assertions evaluated, Wilcoxon signed-rank test, and Top-N."
pub.1174850340,An End-to-End Deep Learning Framework for Fault Detection in Marine Machinery,"The Industrial Internet of Things has enabled the integration and analysis of vast volumes of data across various industries, with the maritime sector being no exception. Advances in cloud computing and deep learning (DL) are continuously reshaping the industry, particularly in optimizing maritime operations such as Predictive Maintenance (PdM). In this study, we propose a novel DL-based framework focusing on the fault detection task of PdM in marine operations, leveraging time-series data from sensors installed on shipboard machinery. The framework is designed as a scalable and cost-efficient software solution, encompassing all stages from data collection and pre-processing at the edge to the deployment and lifecycle management of DL models. The proposed DL architecture utilizes Graph Attention Networks (GATs) to extract spatio-temporal information from the time-series data and provides explainable predictions through a feature-wise scoring mechanism. Additionally, a custom evaluation metric with real-world applicability is employed, prioritizing both prediction accuracy and the timeliness of fault identification. To demonstrate the effectiveness of our framework, we conduct experiments on three types of open-source datasets relevant to PdM: electrical data, bearing datasets, and data from water circulation experiments."
pub.1027271441,Cost‐Sensitive Radial Basis Function Neural Network Classifier for Software Defect Prediction,"Effective prediction of software modules, those that are prone to defects, will enable software developers to achieve efficient allocation of resources and to concentrate on quality assurance activities. The process of software development life cycle basically includes design, analysis, implementation, testing, and release phases. Generally, software testing is a critical task in the software development process wherein it is to save time and budget by detecting defects at the earliest and deliver a product without defects to the customers. This testing phase should be carefully operated in an effective manner to release a defect-free (bug-free) software product to the customers. In order to improve the software testing process, fault prediction methods identify the software parts that are more noted to be defect-prone. This paper proposes a prediction approach based on conventional radial basis function neural network (RBFNN) and the novel adaptive dimensional biogeography based optimization (ADBBO) model. The developed ADBBO based RBFNN model is tested with five publicly available datasets from the NASA data program repository. The computed results prove the effectiveness of the proposed ADBBO-RBFNN classifier approach with respect to the considered metrics in comparison with that of the early predictors available in the literature for the same datasets."
pub.1154326721,Deleterious synonymous mutation identification based on selective ensemble strategy,"Although previous studies have revealed that synonymous mutations contribute to various human diseases, distinguishing deleterious synonymous mutations from benign ones is still a challenge in medical genomics. Recently, computational tools have been introduced to predict the harmfulness of synonymous mutations. However, most of these computational tools rely on balanced training sets without considering abundant negative samples that could result in deficient performance. In this study, we propose a computational model that uses a selective ensemble to predict deleterious synonymous mutations (seDSM). We construct several candidate base classifiers for the ensemble using balanced training subsets randomly sampled from the imbalanced benchmark training sets. The diversity measures of the base classifiers are calculated by the pairwise diversity metrics, and the classifiers with the highest diversities are selected for integration using soft voting for synonymous mutation prediction. We also design two strategies for filling in missing values in the imbalanced dataset and constructing models using different pairwise diversity metrics. The experimental results show that a selective ensemble based on double fault with the ensemble strategy EKNNI for filling in missing values is the most effective scheme. Finally, using 40-dimensional biology features, we propose a novel model based on a selective ensemble for predicting deleterious synonymous mutations (seDSM). seDSM outperformed other state-of-the-art methods on the independent test sets according to multiple evaluation indicators, indicating that it has an outstanding predictive performance for deleterious synonymous mutations. We hope that seDSM will be useful for studying deleterious synonymous mutations and advancing our understanding of synonymous mutations. The source code of seDSM is freely accessible at https://github.com/xialab-ahu/seDSM.git."
pub.1104478062,Taxonomy of machine learning algorithms in software fault prediction using object oriented metrics," Prediction of Fault proneness of a software component is the compelling field of investigations in software testing arena. Software coupling plays a vital role in assessing the software quality through fault prediction and complexity measures. Various fault prediction models, have used the object oriented metrics for the predicting and localizing the faults. Many of these metrics have direct influence on the quality of software. More over prior knowledge of the fault proneness of a component may significantly reduce the testing effort and time. The measures of object oriented features like inheritance, polymorphism and encapsulation etc may be used to estimate fault proneness. Many researchers have investigated the usage of object oriented metrics in the software fault prediction. In this study we present taxonomy of usage these metrics in the fault prediction. We also present the analysis of machine learning techniques in fault prediction."
pub.1052913791,Software Fault Prediction with Object-Oriented Metrics Based Artificial Immune Recognition System,"Software testing is a time-consuming and expensive process. Software fault prediction models are used to identify fault-prone classes automatically before system testing. These models can reduce the testing duration, project risks, resource and infrastructure costs. In this study, we propose a novel fault prediction model to improve the testing process. Chidamber-Kemerer Object-Oriented metrics and method-level metrics such as Halstead and McCabe are used as independent metrics in our Artificial Immune Recognition System based model. According to this study, class-level metrics based model which applies AIRS algorithm can be used successfully for fault prediction and its performance is higher than J48 based approach. A fault prediction tool which uses this model can be easily integrated into the testing process."
pub.1154356079,Software Defect Prediction Framework Using Hybrid Software Metric,"Software fault prediction is widely used in the software development industry. Moreover, software development has accelerated significantly during this epidemic. However, the main problem is that most fault prediction models disregard object-oriented metrics, and even academician researcher concentrate on predicting software problems early in the development process. This research highlights a procedure that includes an object-oriented metric to predict the software fault at the class level and feature selection techniques to assess the effectiveness of the machine learning algorithm to predict the software fault. This research aims to assess the effectiveness of software fault prediction using feature selection techniques. In the present work, software metric has been used in defect prediction. Feature selection techniques were included for selecting the best feature from the dataset. The results show that process metric had slightly better accuracy than the code metric."
pub.1130287864,"Towards recent developments in the methods, metrics and datasets of software fault prediction","The world of software systems is amplified with the changing environment magnifying the demand for quality software. Software fault prediction is a requisite activity ensuring the development of economic, efficient and quality software. It is the procedure for the development of models which help to identify faults in modules during early phases of software development lifecycle. Software fault prediction is one of the most prevalent research disciplines. The existing study in this domain includes numerous modelling techniques and software metrics for the early predictions of software faults. This paper aims to explore some of the prominent studies for software fault prediction in the existing literature. In this paper, software fault prediction papers since 1990 to 2017 are investigated. The paper includes the analysis of the studies having empirical validation and a good source of publication. The paper reflects the methods, metrics, and datasets available in the literature for software fault prediction. In addition, the modelling techniques based on traditional and computational intelligence-based methods are also reviewed. This paper is an endeavour to assemble the existing techniques and metrics of software fault prediction with a motive to assist researchers for easy evaluation of suitable metrics for their own research scenarios."
pub.1105597482,Performance and cost-effectiveness of change burst metrics in predicting software faults,"The purpose of this study is to determine a type of software metric at file level exhibiting the best prediction performance. Studies have shown that software process metrics are better predictors of software faults than software product metrics. However, there is need for a specific software process metric which can guarantee the best fault prediction performances consistently across different experimental contexts. We collected software metrics data from Open Source Software projects. We used logistic regression and linear regression algorithms to predict bug status and number of bugs corresponding to a file, respectively. The prediction performance of these models was evaluated against numerical and graphical prediction model performance measures. We found that change burst metrics exhibit the best numerical performance measures and have the highest fault detection probability and least cost of misclassification of software components."
pub.1146160151,Various Aspects of Software Fault Prediction: A Review,"In the domain of software engineering, software fault prediction is a prominent research area. To enhance the quality of software, software fault prediction is introduced. The primary intention of software fault prediction is to search for faults in the earlier stages of software development to minimize the risk of software failure in the future. However, testing is also used to find the faults in the software, but software fault prediction consumes fewer resources and time. There are mainly three aspects of software fault prediction: data sets, metrics, modeling techniques, and performance measures. This paper reviews different aspects of software fault prediction such as metrics and modeling techniques. The survey is summarized in the form of tables. At last, conclusion is discussed."
pub.1144836553,Software Fault Severity Prediction Using Git History Metrics and Commits,"In this paper, we propose new software agnostic metrics extracted from Git history. We compared the proposed metrics to many traditional code-based metrics in terms of fault severity prediction. We used three Machine Learning Algorithms (Random Forest, SVM and Multilayer Perceptron) to build the prediction models. We used data (source code, source code metrics, fault severity information) collected from three different data sources. Results show that the proposed software agnostic metrics perform better in terms of fault severity prediction compared to traditional code-based metrics. They were able to achieve 84% of accuracy in fault severity prediction. We also introduced some terms extracted from commits and showed their effectiveness for fault severity classification."
pub.1099595428,Evaluation of Sampling Techniques in Software Fault Prediction Using Metrics and Code Smells,"The highly imbalanced nature of software fault datasets results in poor performance of machine leaning techniques used for software fault prediction. The objective of this paper is to evaluate sampling techniques and Meta-Cost learning in software fault prediction to alleviate problem of imbalanced data. We evaluate four sampling techniques in metrics as well as code smells based fault prediction on fault data sets of two open source systems ANT and POI. Our results indicate that Resample technique is best for metrics based fault prediction whereas Synthetic Minority Oversampling is best suited for code smells based fault prediction. The results are presented in terms of accuracy measures like G-Mean, F-measure and area under ROC curve. We also evaluate Meta-Cost learning and found that all sampling techniques outperform Meta-Cost learning. Our results also indicate that software metrics are better predictor of software faults than code smells."
pub.1020554705,A comparison between software design and code metrics for the prediction of software fault content,"Software metrics play an important role in measuring the quality of software. It is desirable to predict the quality of software as early as possible, and hence metrics have to be collected early as well. This raises a number of questions that has not been fully answered. In this paper we discuss, prediction of fault content and try to answer what type of metrics should be collected, to what extent design metrics can be used for prediction, and to what degree prediction accuracy can be improved if code metrics are included. Based on a data set collected from a real project, we found that both design and code metrics are correlated with the number of faults. When the metrics are used to build prediction models of the number of faults, the design metrics are as good as the code metrics, little improvement can be achieved if both design metrics and code metrics are used to model the relationship between the number of faults and the software metrics. The empirical results from this study indicate that the structural properties of the software influencing the fault content is established before the coding phase."
pub.1038168456,Software fault prediction metrics: A systematic literature review,ContextSoftware metrics may be used in fault prediction models to improve software quality by predicting fault location.ObjectiveThis paper aims to identify software metrics and to assess their applicability in software fault prediction. We investigated the influence of context on metrics’ selection and performance.MethodThis systematic literature review includes 106 papers published between 1991 and 2011. The selected papers are classified according to metrics and context properties.ResultsObject-oriented metrics (49%) were used nearly twice as often compared to traditional source code metrics (27%) or process metrics (24%). Chidamber and Kemerer’s (CK) object-oriented metrics were most frequently used. According to the selected studies there are significant differences between the metrics used in fault prediction performance. Object-oriented and process metrics have been reported to be more successful in finding faults compared to traditional size and complexity metrics. Process metrics seem to be better at predicting post-release faults compared to any static code metrics.ConclusionMore studies should be performed on large industrial software systems to find metrics more relevant for the industry and to answer the question as to which metrics should be used in a given context.
pub.1101543636,Prediction of software fault-prone classes using an unsupervised hybrid SOM algorithm,In software engineering fault proneness prediction is one of the important fields for quality measurement using multiple code metrics. The metrics thresholds are very practical in measuring the code quality for fault proneness prediction. It helps to improvise the software quality in short time with very low cost. Many researchers are in the race to develop a measuring attribute for the software quality using various methodologies. Currently so many fault proneness prediction models are available. Among that most of the methods are used to identify the faults either by data history or by special supervising algorithms. In most of the real time cases the fault data bases may not be available so that the process becomes tedious. This article proposes a hybrid model for identifying the faults in the software models and also we proposed coupling model along with the algorithm so that the metrics are used to identify the faults and the coupling model couples the metrics and the faults for the developed system software.
pub.1166717178,Decision Tree Regression Analysis of Proposed Metric Suite for Software Fault Prediction,"The objective of this study is to identify a metric suite for software fault prediction that can solve challenges related to reliability, quality, time, and cost of the software project. This research paper describes the design and analysis of the proposed metric suite (requirement-based metric and agile-based metric) to predict faults in software projects that is based on a formula using process metrics as inputs from a real-time, wider dataset from the PROMISE repository. The formula has been developed in Python. Pearson correlation analysis has been applied to determine the relationship between the proposed metric suite and the faults (dependent variable) of software projects. The correlation coefficients of requirement-based metrics and agile-based metrics with faults are 0.82165 and 0.731033, respectively, which implies that the proposed metric suite has a strong positive relationship with the faults. For empirical analysis, decision-tree regression of machine learning has been used to explore the validity of the proposed metric suite. The regression analysis outcomes based on the statistical performance evolution measures (AUC and F1-measure) of the requirement-based metric with predicted faults are 0.9871 and 0.9367, respectively, and of the agile-based metric with predicted faults are 1.0 and 0.67, respectively, revealing that the proposed metric suite can be applied as the best predictor for the prediction of faults. By comparing the prediction and validation results of the proposed metrics for the same dataset, it has been concluded that the requirement-based metric has the best performance with values of MMRE, RMSE, and NRMSE of 3.61e-05, 6.07779, and 0.0034748, respectively."
pub.1154221721,A Review on Software Fault Detection Mechanisms and Fault Prevention Mechanisms in Networks,It is possible to improve software quality by anticipating fault location through the utilization of software metrics within fault prediction models in network. This article provides a comprehensive literature review on the topic of software fault forecasting. The paper also seeks to identify software metrics and evaluate how applicable those metrics are to the process of software fault prediction. It is recommended that additional research be conducted on large industrial software systems to identify metrics that are more pertinent for the industry and to find an answer to the question of which metrics should be employed in a particular setting.
pub.1101391981,Empirical analysis of change metrics for software fault prediction," A quality assurance activity, known as software fault prediction, can reduce development costs and improve software quality. The objective of this study is to investigate change metrics in conjunction with code metrics to improve the performance of fault prediction models. Experimental studies are performed on different versions of Eclipse projects and change metrics are extracted from the GIT repositories. In addition to the existing change metrics, several new change metrics are defined and collected from the Eclipse project repository. Machine learning algorithms are applied in conjunction with the change and source code metrics to build fault prediction models. The classification model with new change metrics performs better than the models using existing change metrics. In this work, the experimental results demonstrate that change metrics have a positive impact on the performance of fault prediction models, and high-performance models can be built with several change metrics."
pub.1124940658,A study on Software Metric Selection for Software Fault Prediction,"For most software systems, superfluous software metrics are often collected. Sometimes, metrics that are collected may be redundant or irrelevant to fault prediction results. Feature (software metric) selection helps separating relevant software metrics from irrelevant or redundant ones, thereby identifying the small set of software metrics that are best predictors of fault proneness for new components, modules, or releases. In this study, we compare three forms of feature selection techniques (filter- and wrapper- based subset evaluators along with two search techniques (Best First (BF) and Greedy Stepwise (GS)), and feature ranking on four datasets from a real world software project. Five learners are used to build fault prediction models with the selected software metrics. Each model is assessed using the Area Under the Receiver Operating Characteristic Curve (AUC). We find that wrapper-based subset evaluators performed best and feature ranking performed worst. In addition, the model built with the logistic regression (LR) learner performs best in terms of the AUC performance metric. This leads us to recommend the use of the wrapper-based subset evaluators to select software metric subsets and the LR learner for building software fault prediction models."
pub.1034417289,Software Metrics Reduction for Fault-Proneness Prediction of Software Modules,"It would be valuable to use metrics to identify the fault-proneness of software modules. However, few research works are on how to select appropriate metrics for fault-proneness prediction currently. We conduct a large-scale comparative experiment of nine different software metrics reduction methods over eleven public-domain data sets from the NASA metrics data repository. The Naive Bayes data miner, with a log-filtering preprocessor on the numeric data, is utilized to construct the prediction model. Comparisons are based on the analysis of variance. Our conclusion is that, reduction methods of software metrics are important to build adaptable and robust software fault-proneness prediction models. Given our results on Naive Bayes and log-filtering, discrete wavelet transformation outperforms other reduction methods, and correlation-based feature selection with genetic search algorithm and information gain can also obtain better predicted performance."
pub.1165018522,Research on Software Fault Feature Data Extraction Method for Software Fault Prediction Technology,"The correlation between software failure characteristics and software failure directly determines the predictive performance of the failure prediction model. The extraction of software fault features is crucial for building equipment software fault prediction models, and is an important process to ensure accurate prediction. However, the software fault feature data extraction method is often complicated to use and has no pertinence to the selected software fault feature data, and it takes a lot of time to complete the extraction steps. This paper summarizes software metrics and software defect types based on research at home and abroad, and selects software metrics and software defect types that are suitable for equipment software. Using regular expression technology and CSV technology research the automatic extraction way of software fault features, and finally constructs a fault data set that can be used for software fault prediction models."
pub.1169823223,Predicting Software Faults Using Machine Learning Techniques: An Empirical Study,"Software fault/defect prediction aids software engineers in identifying defective constructions, including classes and modules early in software development life cycle. Deep learning (DL), machine learning (ML), and all forms of data mining are used in the process of predicting software faults. First, we provide a brief introduction to the fundamentals of ML-based software defect prediction. The objective of software fault prediction is to identify potentially problematic codes well in advance of actual testing by utilizing commonalities between software projects. There are several reasons why software fault prediction is important and necessary in software engineering as improved software quality, cost savings, improved project management, better risk management, and increased efficiency. It assists in achieving target software quality while optimizing cost, effort, and problem resolution. The absence of reliable performance metrics for evaluating the efficacy of fault prediction models is a serious barrier to the field of software fault prediction. Then we moved on to talk about software defect management, software analysis, software defect metrics, and software defect prediction. After that, many different machine learning methods were broken down and examined for their merits and weaknesses. These methods included logistic regression (LR), support vector machine (SVM), random forest (RF), and Naive Bayes (NB). To conclude, this study reveals the pertinent approaches for better fault prediction."
pub.1049597330,A systematic review of software fault prediction studies,"This paper provides a systematic review of previous software fault prediction studies with a specific focus on metrics, methods, and datasets. The review uses 74 software fault prediction papers in 11 journals and several conference proceedings. According to the review results, the usage percentage of public datasets increased significantly and the usage percentage of machine learning algorithms increased slightly since 2005. In addition, method-level metrics are still the most dominant metrics in fault prediction research area and machine learning algorithms are still the most popular methods for fault prediction. Researchers working on software fault prediction area should continue to use public datasets and machine learning algorithms to build better fault predictors. The usage percentage of class-level is beyond acceptable levels and they should be used much more than they are now in order to predict the faults earlier in design phase of software life cycle."
pub.1100926655,Analyzing Fault Prediction Usefulness from Cost Perspective Using Source Code Metrics,Software fault prediction techniques are useful for the purpose of optimizing test resource allocation. Software fault prediction based on source code metrics and machine learning models consists of using static program features as input predictors to estimate the fault proneness of a class or module. We conduct a comparison of five machine learning algorithms on their fault prediction performance based on experiments on 56 open source projects. Several researchers have argued on the application of software engineering economics and testing cost for the purpose of evaluating a software quality assurance activity. We evaluate the performance and usefulness of fault prediction models within the context of a cost evaluation framework and present the results of our experiments. We propose a novel approach using decision trees to predict the usefulness of fault prediction based on distributional characteristics of source code metrics by fusing information from the output of the fault prediction usefulness using cost evaluation framework and distributional source code metrics.
pub.1093657192,A Novel Framework of Software Reliability Evaluation with Software Reliability Growth Models and Software Metrics,"This paper proposes a novel framework of software reliability growth models with software metrics. Our approach is to integrate a classical Poisson-regression-based fault prediction with non-homogeneous Poisson process based software reliability growth models. The remarkable feature of this approach is to handle time series data of fault detections and software metrics for a number of modules at the same time. In the paper, we present the modeling framework that combines Poisson-regression-based fault prediction and software reliability growth models, and also develop an efficient algorithm to estimate model parameters based on EM (expectation-maximization) algorithm. In numerical experiments, by comparing the proposed model with both Poisson-regression-based fault prediction and nonhomogeneous Poisson process based software reliability growth models, we discuss the effectiveness of using time series data of fault detections and software metrics from both viewpoints of reliability estimation and fault prediction."
pub.1085721289,A study on software fault prediction techniques,"Software fault prediction aims to identify fault-prone software modules by using some underlying properties of the software project before the actual testing process begins. It helps in obtaining desired software quality with optimized cost and effort. Initially, this paper provides an overview of the software fault prediction process. Next, different dimensions of software fault prediction process are explored and discussed. This review aims to help with the understanding of various elements associated with fault prediction process and to explore various issues involved in the software fault prediction. We search through various digital libraries and identify all the relevant papers published since 1993. The review of these papers are grouped into three classes: software metrics, fault prediction techniques, and data quality issues. For each of the class, taxonomical classification of different techniques and our observations have also been presented. The review and summarization in the tabular form are also given. At the end of the paper, the statistical analysis, observations, challenges, and future directions of software fault prediction have been discussed."
pub.1043746527,Metrics-Driven Software Quality Prediction Without Prior Fault Data,"Software quality assessment models are quantitative analytical models that are more reliable compared to qualitative models based on personal judgment. These assessment models are classified into two groups: generalized and product-specific models. Measurement-driven predictive models, a subgroup of product-specific models, assume that there is a predictive relationship between software measurements and quality. In recent years, greater attention in quality assessment models has been devoted to measurement-driven predictive models and the field of software fault prediction modeling has become established within the product-specific model category. Most of the software fault prediction studies focused on developing fault predictors by using previous fault data. However, there are cases when previous fault data are not available. In this study, we propose a novel software fault prediction approach that can be used in the absence of fault data. This fully automated technique does not require an expert during the prediction process and it does not require identifying the number of clusters before the clustering phase, as required by the K-means clustering method. Software metrics thresholds are used to remove the need for an expert. Our technique first applies the X-means clustering method to cluster modules and identifies the best cluster number. After this step, the mean vector of each cluster is checked against the metrics thresholds vector. A cluster is predicted as fault-prone if at least one metric of the mean vector is higher than the threshold value of that metric. Three datasets, collected from a Turkish white-goods manufacturer developing embedded controller software, have been used during experimental studies. Experiments revealed that unsupervised software fault prediction can be automated fully and effective results can be achieved by using the X-means clustering method and software metrics thresholds."
pub.1137728788,Analysis of Developers’ Network and Change Burst Metrics as Predictors of Software Faults,"Introduction: Many software quality metrics that can be used as proxies of measuring software quality by predicting software faults have previously been proposed. However determining a superior predictor of software faults given a set of metrics is difficult since prediction performances of the proposed metrics have been evaluated in non–uniform experimental contexts. There is need for software metrics that can guarantee consistent superior fault prediction performances across different contexts. Such software metrics would enable software developers and users to establish software quality. 
Objectives: This research sought to determine a predictor for software faults that requires least effort to detect software faults and has least cost of misclassifying software components as faulty or not given developers’ network metrics and change burst metrics. 
Methods: Experimental data for this study was derived from Jmeter, Gedit, POI and Gimp open source software projects. Logistic regression was used to predict faultiness of a file while linear regression was used to predict number of faults per file. Results: Change burst metrics model exhibited the highest fault detection probabilities with least cost of mis-classification of components as compared to the developers’ network model. 
Conclusion: The study found that change burst metrics could effectively predict software faults."
pub.1110535343,An ANN Based Approach for Software Fault Prediction Using Object Oriented Metrics,"During recent years, the enormous increase in demand for software products has been experienced. High quality software is the major demand of users. Predicting the faults in early stages will improve the quality of software and apparently reduce the development efforts or cost. Fault prediction is majorly based on the selection of technique and the metrics to predict the fault. Thus metrics selection is a critical part of software fault prediction. Currently techniques been evaluated based on traditional set of metrics. There is a need to identify the different techniques and evaluate them on the bases of appropriate metrics. In this research, Artificial neural network is used. For classification task, ANN is one of the most effective technique. Artificial neural network based SFP model is designed for classification in this study. Prediction is performed on the basis of object-oriented metrics. 5 object oriented metrics from CK and Martin metric sets are selected as input parameters. The experiments are performed on 18 public datasets from PROMISE repository. Receiver operating characteristíc curve, accuracy, and Mean squared error are taken as performance parameters for the prediction task. Results of the proposed systems signify that ANN provides significant results in terms of accuracy and error rate."
pub.1068338396,An Approach for Software Fault Prediction to Measure the Quality of Different Prediction Methodologies using Software Metrics,"Background: Software fault prediction is an important task to improve the quality of software. It reduces the time and complexity between modules. Future software faults depend on previous faulty data. Statistical Analysis: The prediction models are created using method level metrics available from NASA datasets of structure oriented CM1 and PC1 datasets and object oriented KC1 and KC2 datasets. These metrics were applied in different classifier like Naive Bayes, J48, K-Star and Random forest to identify the best classifier for small dataset and large dataset based on both structure and object oriented method level metrics. Findings: This paper gives the study and analysis of various methodologies used for predicting faults in both structure and object oriented software. Based on the study, Naïve Bayes is utmost suitable for small datasets and random forest is suitable for large datasets based on the evaluation done by us using various methodologies driven by WEKA tool while equating precision, recall and accuracy. Application: This process of software fault prediction can be applied to E-Commerce applications, where accuracy requires much importance. Keywords: Naive Bayes, Random Forest, Software Metrics, Software Quality, Software Fault Prediction  "
pub.1038612454,An analysis of developer metrics for fault prediction,"Background: Software product metrics have been widely used as independent variables for constructing a fault prediction model. However, fault injection depends not only on characteristics of the products themselves, but also on characteristics of developers involved in the project. Aims: The goal of this paper is to study the effects of developer features on software reliability. Method: This paper proposes developer metrics such as the number of code churns made by each developer, the number of commitments made by each developer and the number of developers for each module. By using the eclipse project dataset, we experimentally analyzed the relationship between the number of faults and developer metrics. Second, the effective of developer metrics for performance improvements of fault prediction models were evaluated. Results: The result revealed that the modules touched by more developer contained more faults. Compared with conventional fault prediction models, developer metrics improved the prediction performance. Conclusions: We conclude that developer metrics are good predictor of faults and we must consider the human factors for improving the software reliability."
pub.1021778698,Empirical Investigation of Metrics for Fault Prediction on Object-Oriented Software,"The importance of software-quality classification models which can predict the modules to be faulty, or not, based on certain software product metrics has increased. Such predictions can be used to target improvement efforts to those modules that need it the most. The application of metrics to build models can assist to focus quality improvement efforts to modules that are likely to be faulty during operations, thereby cost-effectively utilizing the software quality testing and enhancement resources. In the present study we have investigated the relationship between OO metrics and the detection of the faults in the object-oriented software. Fault prediction models are made and validated using regression methods for detecting faulty classes and discover the number of faults in each class. The univariate and multivariate logistic regression models are made by taking the dependent variable as the presence of fault or not. While linear regression models are built using the number of faults as dependent variable. The results of the two models are compared and an investigation on the metrics is presented."
pub.1048903926,Fault Prediction Modeling for Software Quality Estimation: Comparing Commonly Used Techniques,"High-assurance and complex mission-critical software systems are heavily dependent on reliability of their underlying software applications. An early software fault prediction is a proven technique in achieving high software reliability. Prediction models based on software metrics can predict number of faults in software modules. Timely predictions of such models can be used to direct cost-effective quality enhancement efforts to modules that are likely to have a high number of faults. We evaluate the predictive performance of six commonly used fault prediction techniques: CART-LS (least squares), CART-LAD (least absolute deviation), S-PLUS, multiple linear regression, artificial neural networks, and case-based reasoning. The case study consists of software metrics collected over four releases of a very large telecommunications system. Performance metrics, average absolute and average relative errors, are utilized to gauge the accuracy of different prediction models. Models were built using both, original software metrics (RAW) and their principle components (PCA). Two-way ANOVA randomized-complete block design models with two blocking variables are designed with average absolute and average relative errors as response variables. System release and the model type (RAW or PCA) form the blocking variables and the prediction technique is treated as a factor. Using multiple-pairwise comparisons, the performance order of prediction models is determined. We observe that for both average absolute and average relative errors, the CART-LAD model performs the best while the S-PLUS model is ranked sixth."
pub.1023571431,Statistical and Machine Learning Methods for Software Fault Prediction Using CK Metric Suite: A Comparative Analysis,"Experimental validation of software metrics in fault prediction for object-oriented methods using statistical and machine learning methods is necessary. By the process of validation the quality of software product in a software organization is ensured. Object-oriented metrics play a crucial role in predicting faults. This paper examines the application of linear regression, logistic regression, and artificial neural network methods for software fault prediction using Chidamber and Kemerer (CK) metrics. Here, fault is considered as dependent variable and CK metric suite as independent variables. Statistical methods such as linear regression, logistic regression, and machine learning methods such as neural network (and its different forms) are being applied for detecting faults associated with the classes. The comparison approach was applied for a case study, that is, Apache integration framework (AIF) version 1.6. The analysis highlights the significance of weighted method per class (WMC) metric for fault classification, and also the analysis shows that the hybrid approach of radial basis function network obtained better fault prediction rate when compared with other three neural network models."
pub.1093974416,Metrics selection for fault-proneness prediction of software modules,"It would be valuable to use metrics to identify the fault-proneness of software modules. It is important to select the most appropriate particular metric subset for fault-proneness prediction. We proposed an approach of metrics selection, which firstly utilized the correlation analysis to eliminate the high the correlation metrics and then ranked the remaining metrics based on the gray relational analysis. Three classifiers, that were logistic regression model, NaiveBayes, and J48, were utilized to empirically investigate the usefulness of selected metrics. Our results, based on a public domain NASA data set, indicate that 1) proposed method for metrics selection is effective, and 2) using 3-4 metrics gets the balanced performance for fault-proneness prediction of software modules."
pub.1125950864,Empirical Evaluation of Coupling Metrics in Software Fault Prediction,"Software Fault Prediction (SFP) techniques are commonly used to determine the fault proneness of software modules to complement the development and testing process. In SFP, fault prediction is based on software metrics that reflect any aspect of the software, where coupling is one of them. Software coupling is one such metric, which is a measure of the interdependency of software modules. Coupling induces complexity in the coupled module and makes it difficult to comprehend. Eventually, more coupled modules are likely to be faultier. This spurs a need to evaluate the impact of coupling exclusively, on fault proneness. Since, coupling by inheritance is harmless, as it promotes reusability, so coupling through inheritance is not considered. We evaluated seven coupling metrics on 87 different publicly available datasets. After pre-processing, selected datasets are split with all possible coupling metrics. Resulting 474 split datasets are used for the experiments. These datasets have only coupling metrics and nominal-binary class labels. Model building and validation are done for Support Vector Machine. Results of entropy-loss shows that coupling metrics are good predictors of faults in software. Furthermore, {Coupling Between Objects, Design Complexity, Fan-in} outperform the rest of the 30 feature set. Finally, coupling metrics are ranked by keeping in view their position achieved and the number of accompanying metrics. This declares Efferent Coupling as the best coupling metric with respect to the other six coupling metrics in 474 datasets. The paper concludes the viability of coupling metrics in software fault prediction. Evaluating the absolute impact of coupling in SFP and then the relative ranking of coupling metrics is the significance of this paper."
pub.1131392738,Software reliability prediction using package level modularization metrics,"Reliability ensures architectural strength and error free operations of software systems. Software design and architectural measures have been studied as key indicators of faults in software systems. However, association between quantification of reliability prediction using design-level metrics has not been explored. This paper presents a novel approach of developing reliability metrics and it’s prediction using package level metrics. In particular, relevant fault severity information is empirically experimented with package level metrics in an effort-aware classification and ranking scenario. Results obtained hint significant view to predict the reliability of software systems using architectural level metrics. Therefore, the empirical analysis can guide development process to be design-focused and avoid accumulation of faults in implementation phase."
pub.1026108812,Application of Locally Weighted Regression for Predicting Faults Using Software Entropy Metrics,"There are numerous approaches for predicting faults in the software engineering research field. Software entropy metrics introduced by Hassan (Predicting faults using the complexity of code changes, 78–88, 2009) [1] are also popularly used for fault prediction. In previous studies, statistical linear regression (SLR) and support vector regression (SVR) for predicting faults using software entropy metrics have been validated. However, other machine learning approaches have not yet been explored. This study explores the applicability of locally weighted regression (LWR) approach for predicting faults using the software entropy metrics and compares it with SVR. It is noticed that the LWR performs better than SVR in most of the cases."
pub.1094220274,Early Software Fault Prediction using Real Time Defect Data,"Quality of a software component can be measured in terms of fault proneness of data. Quality estimations are made using fault proneness data available from previously developed similar type of projects and the training data consisting of software measurements. To predict faulty modules in software data different techniques have been proposed which includes statistical method, machine learning methods, neural network techniques and clustering techniques. The aim of proposed approach is to investigate that whether metrics available in the early lifecycle (i.e. requirement metrics), metrics available in the late lifecycle (i.e. code metrics) and metrics available in the early lifecycle (i.e. requirement metrics) combined with metrics available in the late lifecycle (i.e. code metrics) can be used to identify fault prone modules by using clustering techniques. This approach has been tested with three real time defect datasets of NASA software projects, JM1, PC1 and CM. Predicting faults early in the software life cycle can be used to improve software process control and achieve high software reliability. The results show that when all the prediction techniques are evaluated, the best prediction model is found to be the fusion of requirement and code metric model."
pub.1139011335,On the Comparison of Static and Dynamic Metrics Toward Fault-Proneness Prediction,"The notion of predicting fault-proneness by utilizing software metric data has acquired the attention of many researchers in the past three decades. The fault-proneness prediction can assist in the systematic distribution of the software development resources, as testers need to put efforts and time on only those software classes where the chances of faults are very high. This study investigates the dichotomization capability of thresholds identified through Receiver Operating Characteristic (ROC) curve and F-measure. These methods were utilized to compute the cut-off values of the software measures extracted from the jEdit software system. Besides Chidamber and Kemerer metric suite, we also assessed the prediction capability of a dynamic measure - Dynamic Coupling between Object classes (DCBO). The dynamic metrics are capable of revealing true execution behaviour of the software system as here the values can only be extracted at the run-time, therefore can handle the object oriented features, such as, polymorphism, inheritance, and dynamic binding, better than the static metrics. The experimental results highlighted the good performance of the DCBO measure, indicating this particular metric as a promising candidate for the purpose of fault proneness prediction."
pub.1130255861,Ensemble Techniques-Based Software Fault Prediction in an Open-Source Project,"Software engineering repositories have been attracted by researchers to mine useful information about the different quality attributes of the software. These repositories have been helpful to software professionals to efficiently allocate various resources in the life cycle of software development. Software fault prediction is a quality assurance activity. In fault prediction, software faults are predicted before actual software testing.  As exhaustive software testing is impossible, the use of software fault prediction models can help the proper allocation of testing resources. Various machine learning techniques have been applied to create software fault prediction models. In this study, ensemble models are used for software fault prediction. Change metrics-based data are collected for an open-source android project from GIT repository and code-based metrics data are obtained from PROMISE data repository and datasets kc1, kc2, cm1, and pc1 are used for experimental purpose. Results showed that ensemble models performed better compared to machine learning and hybrid search-based algorithms. Bagging ensemble was found to be more effective in the prediction of faults in comparison to soft and hard voting."
pub.1145835170,Fault Prediction with Static Software Metrics in Evolving Software: A Case Study in Apache Ant,"Software testing is an integral part of software development. Not only that testing exists in each software iteration cycle, but it also consumes a considerable amount of resources. While resources such as machinery and manpower are often restricted, it is crucial to decide where and how much effort to put into testing. One way to address this problem is to identify which components of the subject under the test are more error-prone and thus demand more testing efforts. Recent development in machine learning techniques shows promising potential to predict faults in different components of a software system. This work conducts an empirical study to explore the feasibility of using static software metrics to predict software faults. We apply four machine learning techniques to construct fault prediction models from the PROMISE data set and evaluate the effectiveness of using static software metrics to build fault prediction models in four continuous versions of Apache Ant. The empirical results show that the combined software metrics generate the least misclassification errors. The fault prediction results vary significantly among different machine learning techniques and data set. Overall, fault prediction models built with the support vector machine (SVM) have the lowest misclassification errors."
pub.1124123706,A Conceptual Framework for Software Fault Prediction Using Neural Networks,"Software testing is a very expensive and critical activity in the software systems’ life-cycle. Finding software faults or bugs is also time-consuming, requiring good planning and a lot of resources. Therefore, predicting software faults is an important step in the testing process to significantly increase efficiency of time, effort and cost usage.In this study we investigate the problem of Software Faults Prediction (SFP) based on Neural Network. The main contribution is to empirically establish the combination of Chidamber and Kemer software metrics that offer the best accuracy for faults prediction with numeric estimations by using feature selection. We also proposed a conceptual framework that integrates the model for fault prediction."
pub.1106137056,Embedded Software Fault Prediction Based on Back Propagation Neural Network,"Predicting software faults before software testing activities can help rational distribution of time and resources. Software metrics are used for software fault prediction due to their close relationship with software faults. Thanks to the non-linear fitting ability, Neural networks are increasingly used in the prediction model. We first filter metric set of the embedded software by statistical methods to reduce the dimensions of model input. Then we build a back propagation neural network with simple structure but good performance and apply it to two practical embedded software projects. The verification results show that the model has good ability to predict software faults."
pub.1135582439,An Empirical Study on Software Fault Prediction Using Product and Process Metrics,"Product and process metrics are measured from the development and evolution of software. Metrics are indicators of software fault-proneness and advanced models using machine learning can be provided to the development team to select modules for further inspection. Most fault-proneness classifiers were built from product metrics. However, the inclusion of process metrics adds evolution as a factor to software quality. In this work, the authors propose a process metric measured from the evolution of software to predict fault-proneness in software models. The process metrics measures change-proneness of modules (classes and interfaces). Classifiers are trained and tested for five large open-source systems. Classifiers were built using product metrics alone and using a combination of product and the proposed process metric. The classifiers evaluation shows improvements whenever the process metrics were used. Evolution metrics are correlated with quality of software and helps in improving software quality prediction for future releases."
pub.1051677507,A new fuzzy rule based algorithm for estimating software faults in early phase of development,"Estimation of reliability and the number of faults present in software in its early development phase, i.e., requirement analysis or design phase is very beneficial for developing reliable software with optimal cost. Software reliability prediction in early phase of development is highly desirable to the stake holders, software developers, managers and end users. Since, the failure data are unavailable in early phase of software development, different reliability relevant software metrics and similar project data are used to develop models for early software fault prediction. The proposed model uses the linguistic values of software metrics in fuzzy inference system to predict the total number of faults present in software in its requirement analysis phase. Considering specific target reliability, weightage of each input software metrics and size of software, an algorithm has been proposed here for developing general fuzzy rule base. For model validation of the proposed model, 20 real software project data have been used here. The linguistic values from four software metrics related to requirement analysis phase have been considered as model inputs. The performance of the proposed model has been compared with two existing early software fault prediction models."
pub.1117372993,Experimental Validation of Inheritance Metrics’ Impact on Software Fault Prediction,"Software faults can cause trivial annoyance to catastrophic failures. Recent work in software fault prediction (SFP) advocates the need for predicting faults before deployment to aid testing process. Object-oriented programming is complex while comparing it with procedural languages having multiple dimensions wherein inheritance is an important aspect. In this paper, we aim to investigate how much inheritance metrics assist in predicting software fault proneness. We first select the Chidamber and Kemerer (CK) metrics, most accepted metric suite for predicting software faults and inheritance metrics. We use 65 publicly available base datasets having CK metrics and some other inheritance metrics to evaluate the impact of inheritance on SFP. We split each dataset into further two datasets: inheritance with CK and CK without inheritance for comparison of results. An artificial neural network (ANN) is used for model building, and accuracy, recall, precision, F1 measures, and true negative rate (TNR) are used for measuring performance. Comparison is made and the results show an acceptable contribution of inheritance metrics in SFP. The testing community can safely use inheritance metrics in predicting software faults. Moreover, high inheritance is not desirable, as this can potentially lead to software faults."
pub.1165544076,Implementation and Validation of Software Fault Prediction Model using Soft-computing based on Proposed Requirement metric,"Finding a software failure prediction model that can address issues with reliability, quality, timeliness, and cost of the software project is the primary objective of this study. The decision-tree regression framework of soft-computing for software fault prediction presented in this article has been implemented in Python and relies on the proposed metric as input and predicted-faults as output. For validation, a larger, real dataset of software projects from the PROMISE repository has been used. The relationship between the proposed metric and the faults (dependent variable) of software projects has been examined using Pearson correlation coefficients with value 0.82165 with faults, which suggests that the proposed metric has a very strong positive connect with the defects. To investigate the usefulness of the suggested metric, decision-tree and K-nearest-neighbor regression have been utilized for empirical investigation and the statistical performance evolution measures (AUC) of the requirement-based metric with predicted-faults were with values 0.9871 and 1.02, respectively. This indicates that the proposed metric suite can be used as the best predictor for fault prediction. The proposed model has been implemented using proposed metric as input and predicted- faults as output. The MMRE, BMMRE, RMSE, NRMSE, and R-Square parameters were used to evaluate the model's performance. The proposed decision-tree regression based model has the best overall performance as compared to the predefined Bayesian-net, fuzzy-inference system, and adaptive neuro-fuzzy inference system based software fault prediction models for the same dataset, with values of MMRE, RMSE, and R-square of 3.61 e-05, 6.07779, and 95.122, respectively."
pub.1137340606,Software Fault Prediction Using LSSVM with Different Kernel Functions,"Software fault prediction is a process, which helps to identify fault prone modules in early stages of software development. It also helps in improving the software quality with optimized effort and cost. Least Square Support Vector Machines (LSSVM) have been explored in problems related to classification. The aim of this paper is to develop and compare, software fault prediction models using LSSVM with Linear, Polynomial and Radial Basis Function (RBF) kernels. The proposed models classify a software module as faulty or non faulty by taking software metrics such as Halstead software metrics as input. Experiments on fifteen open source projects are performed to study the impact of the proposed models. The models are evaluated using Accuracy, F-measure and ROC AUC as the performance measures. The experimental results shows that, LSSVM with polynomial kernel perform better than LSSVM with linear kernel and similar to RBF kernel, and the models developed using LSSVM improve the prediction accuracy of software fault prediction, compared to the most frequently used models."
pub.1093613804,Clustering and Metrics Thresholds Based Software Fault Prediction of Unlabeled Program Modules,"Predicting the fault-proneness of program modules when the fault labels for modules are unavailable is a practical problem frequently encountered in the software industry. Because fault data belonging to previous software version is not available, supervised learning approaches can not be applied, leading to the need for new methods, tools, or techniques. In this study, we propose a clustering and metrics thresholds based software fault prediction approach for this challenging problem and explore it on three datasets, collected from a Turkish white-goods manufacturer developing embedded controller software. Experiments reveal that unsupervised software fault prediction can be automated and reasonable results can be produced with techniques based on metrics thresholds and clustering. The results of this study demonstrate the effectiveness of metrics thresholds and show that the standalone application of metrics thresholds (one-stage) is currently easier than the clustering and metrics thresholds based (two-stage) approach because the selection of cluster number is performed heuristically in this clustering based method."
pub.1093810935,A clustering algorithm for software fault prediction,"Software metrics are used for predicting whether modules of software project are faulty or fault free. Timely prediction of faults especially accuracy or computation faults improve software quality and hence its reliability. As we can apply various distance measures on traditional K-means clustering algorithm to predict faulty or fault free modules. Here, in this paper we have proposed K-Sorensen-means clustering that uses Sorensen distance for calculating cluster distance to predict faults in software projects. Proposed algorithm is then trained and tested using three datasets namely, JM1, PCI and CM1 collected from NASA MDP. From these three datasets requirement metrics, static code metrics and alliance metrics (combining both requirement metrics and static code metrics) have been built and then K-Sorensen-means applied on all datasets to predict results. Alliance metric model is found to be the best prediction model among three models. Results of K-Sorensen-means clustering shown and corresponding ROC curve has been drawn. Results of K-Sorensen-means are then compared with K-Canberra-means clustering that uses other distance measure for evaluating cluster distance."
pub.1094929554,The influence of developer quality on software fault-proneness prediction,"Previous studies have shown that process metrics are useful for building fault-proneness prediction models. In particular, it has been found that those process metrics incorporating developer experience (defined as the percentage of the code a developer contributes) exhibit a good ability to predict fault-proneness. However, developer quality, which we strongly believe should have a great influence on software quality, is surprisingly ignored. In this paper, we first quantify the quality of a developer via the percentage of history bug-introduce commits over all his/her commits during the development process. Then, we leverage developer quality information to develop eight file quality metrics. Finally, we empirically study the usefulness of these eight file quality metrics for fault-proneness prediction. Based on eight open source software systems, our experiment results show that: 1) these proposed file quality metrics capture additional information compared with existing process metrics; 2) almost all the proposed file quality metrics have a significant association with fault-proneness in an expected direction; and 3) the proposed file quality metrics can in general improve the effectiveness of fault-proneness prediction models when together used with existing process metrics. These results suggest that developer quality has a strong influence on software quality and should be taken into account when predicting software fault-proneness."
pub.1087306381,Software Fault Prediction using Computational Intelligence Techniques: A Survey,"Objectives: Software fault prediction is a vital activity in software development to make software more efficient, economic and produce quality software. This is a fruitful approach to decreases the testing efforts (cost and time) of the software testing. Methods: Existence of faults not only reduces the standard of the software, but also increases its development cost and time. In this paper, the detailed survey has done on software fault prediction for categorize software modules as faulty or non-faulty. The goal of this paper is to find the techniques that has used in software fault prediction. The computational intelligence techniques like soft computing, data mining and machine learning based software fault prediction approaches have included. The classification accuracy rate of different methods which is used for fault prediction has explored. Finding: From the survey, it is found that the fuzzy logic and McCabe based metrics are better way to handle the software fault prediction. The McCabe metrics has independent from the programming language. It performs good result for different size of the software. Application: This survey will helpful to select the model which have high accuracy rate for early phase software testing to provide the quality software. The survey also helps to reduce the cost and time of software testing. Keywords: Fuzzy Logic, Software Testing, Software Fault Prediction, Software Fault Detection, Soft Computing"
pub.1038423650,"An exploratory case study of aspect‐oriented metrics for fault proneness, content and fixing effort prediction","
                    Purpose
                    The purpose of this paper is to investigate the relationships between some aspect‐oriented metrics and aspect fault proneness, content and fixing effort.
                  
                  
                    Design/methodology/approach
                    An exploratory case study was conducted using an open source aspect‐oriented software consisting of 76 aspects, and 13 aspect‐oriented metrics were investigated that measure different structural properties of an aspect: size, coupling, cohesion, and inheritance. In addition, different prediction models for aspect fault proneness, content and fixing effort were built using different combinations of metrics' categories.
                  
                  
                    Findings
                    The results obtained from this study indicate statistically significant correlation between most of the size metrics and aspect fault proneness, content and fixing effort. The cohesion metric was also found to be significantly correlated with the same. Moreover, it was observed that the best accuracy in aspect fault proneness, content and fixing effort prediction can be achieved as a function of some size metrics.
                  
                  
                    Originality/value
                    Fault prediction helps software developers to focus their quality assurance activities and to allocate the needed resources for these activities more effectively and efficiently; thus improving software reliability. In literature, some aspect‐oriented metrics have been evaluated for aspect fault proneness prediction, but not for other fault‐related prediction problems such as aspect fault content and fixing effort.
                  "
pub.1083919796,An empirical analysis of the effectiveness of software metrics and fault prediction model for identifying faulty classes,"Software fault prediction models are used to predict faulty modules at the very early stage of software development life cycle. Predicting fault proneness using source code metrics is an area that has attracted several researchers' attention. The performance of a model to assess fault proneness depends on the source code metrics which are considered as the input for the model. In this work, we have proposed a framework to validate the source code metrics and identify a suitable set of source code metrics with the aim to reduce irrelevant features and improve the performance of the fault prediction model. Initially, we applied a t-test analysis and univariate logistic regression analysis to each source code metric to evaluate their potential for predicting fault proneness. Next, we performed a correlation analysis and multivariate linear regression stepwise forward selection to find the right set of source code metrics for fault prediction. The obtained set of source code metrics are considered as the input to develop a fault prediction model using a neural network with five different training algorithms and three different ensemble methods. The effectiveness of the developed fault prediction models are evaluated using a proposed cost evaluation framework. We performed experiments on fifty six Open Source Java projects. The experimental results reveal that the model developed by considering the selected set of source code metrics using the suggested source code metrics validation framework as the input achieves better results compared to all other metrics. The experimental results also demonstrate that the fault prediction model is best suitable for projects with faulty classes less than the threshold value depending on fault identification efficiency (low – 48.89%, median- 39.26%, and high – 27.86%)."
pub.1140308856,Ensemble Techniques-Based Software Fault Prediction in an Open-Source Project,"Software engineering repositories have been attracted by researchers to mine useful information about the different quality attributes of the software. These repositories have been helpful to software professionals to efficiently allocate various resources in the life cycle of software development. Software fault prediction is a quality assurance activity. In fault prediction, software faults are predicted before actual software testing.  As exhaustive software testing is impossible, the use of software fault prediction models can help the proper allocation of testing resources. Various machine learning techniques have been applied to create software fault prediction models. In this study, ensemble models are used for software fault prediction. Change metrics-based data are collected for an open-source android project from GIT repository and code-based metrics data are obtained from PROMISE data repository and datasets kc1, kc2, cm1, and pc1 are used for experimental purpose. Results showed that ensemble models performed better compared to machine learning and hybrid search-based algorithms. Bagging ensemble was found to be more effective in the prediction of faults in comparison to soft and hard voting."
pub.1156096719,Combining object‐oriented metrics and centrality measures to predict faults in object‐oriented software: An empirical validation,"Abstract Many object‐oriented metrics have been proposed in the literature to measure various structural properties of object‐oriented software. Furthermore, many centrality measures have been introduced to identify central nodes in large networks. However, few studies have used them to measure dependencies in software systems. In fact, centrality measures, as opposed to most traditional object‐oriented metrics that mainly focus on intrinsic properties of classes, can be used to better model the control flow and to identify the most important classes in a software system. This paper aims (1) to investigate the relationships between object‐oriented metrics and centrality measures and (2) to explore the ability of their combination to support fault‐proneness prediction from different perspectives (fault‐prone classes, fault severity, and number of faults). Many studies in the literature have addressed the prediction of fault‐prone classes, from different perspectives, using object‐oriented metrics. The main motivation here is in fact to investigate if the information captured by centrality measures is related to fault proneness and complementary to the information captured by object‐oriented metrics and to investigate if the combination of object‐oriented metrics and centrality measures improves the performance of fault‐proneness prediction significantly. We used size, complexity, and coupling object‐oriented metrics in addition to various centrality measures. We collected data from 20 different versions of five open‐source Java software systems. We first studied the relationships between selected metrics and their relationships to fault proneness. Then, we built different models to predict fault‐prone classes using several machine learning algorithms. In addition, we built models to predict if a class contains a high severity fault, and the number of faults in a class. Results indicate that using centrality measures in combination with object‐oriented metrics improves the prediction of fault‐prone classes as well as the prediction of the number of faults in a class. However, the combination has no significant impact, according to the data we collected, on the quality of the prediction of fault severity. Moreover, using centrality measures in combination with object‐oriented metrics also improves the prediction performance of fault proneness and the number of faults in both cross‐version and cross‐system validation."
pub.1156536677,Error-Type—A Novel Set of Software Metrics for Software Fault Prediction,"In software development, identifying software faults is an important task. The presence of faults not only reduces the quality of the software, but also increases the cost of development life cycle. Fault identification can be performed by analysing the characteristics of the buggy source codes from the past and predict the present ones based on the same characteristics using statistical or machine learning models. Many studies have been conducted to predict the fault proneness of software systems. However, most of them provide either inadequate or insufficient information and thus make the fault prediction task difficult. In this paper, we present a novel set of software metrics called Error-type software metrics, which provides prediction models with information about patterns of different types of Java runtime error. Particular, in this study, the ESM values consist of information of three common Java runtime errors which are Index Out Of Bounds Exception, Null Pointer Exception, and Class Cast Exception. Also, we propose a methodology for modelling, extracting, and evaluating error patterns from software modules using Stream X-Machine (a formal modelling method) and machine learning techniques. The experimental results showed that the proposed Error-type software metrics could significantly improve the performances of machine learning models in fault-proneness prediction."
pub.1145950766,An Unsupervised Software Fault Prediction Approach Using Threshold Derivation,"Software fault prediction models help the software quality assurance team to manage the resources optimally during software maintenance. Most of the recently proposed fault prediction approaches are helpful on labeled datasets only. Recently, several threshold-based software fault prediction approaches have been proposed. However, these approaches do not incorporate the distribution of software metrics for metric threshold derivation; hence, they demonstrate poor performance. To fill this gap, we develop an automated fault prediction approach, namely threshold clustering labeling/threshold clustering labeling plus (TCLP), which does not need a labeled dataset. It can identify the faulty and nonfaulty artifacts on unlabeled datasets by self-learning. Our proposed approach is an extension of the state-of-the-art technique known as CLAMI. Unlike CLAMI, we derive the metrics threshold using logarithmic transformation. Thereafter, we label the instances into binary classes (faulty/nonfaulty) using the metric threshold values. TCLP extends this approach one step further by performing fault prediction using a random forest algorithm. The empirical evaluation of the proposed approach on 28 datasets (with the different number of metrics and granularity) collected from five software groups shows that the proposed unsupervised method obtains significantly better results than those of the state-of-the-art methods. The proposed approach impressively enhances the performance of CLAMI in terms of accuracy, F-measure, and Mathews correlation coefficient."
pub.1017158079,Software Fault Prediction at Design Phase,Prediction of fault-prone modules continues to attract researcher's interest due to its significant impact on software development cost. The most important goal of such techniques is to correctly identify the modules where faults are most likely to present in early phases of software development lifecycle. Various software metrics related to modules level fault data have been successfully used for prediction of fault-prone modules. Goal of this research is to predict the faulty modules at design phase using design metrics of modules and faults related to modules. We have analyzed the effect of pre-processing and different machine learning schemes on eleven projects from NASA Metrics Data Program which offers design metrics and its related faults. Using seven machine learning and four preprocessing techniques we confirmed that models built from design metrics are surprisingly good at fault proneness prediction. The result shows that we should choose Naive Bayes or Voting feature intervals with discretization for different data sets as they outperformed out of 28 schemes. Naive Bayes and Voting feature intervals has performed AUC > 0.7 on average of eleven projects. Our proposed framework is effective and can predict an acceptable level of fault at design phases.
pub.1052648435,Prediction approach of software fault-proneness based on hybrid artificial neural network and quantum particle swarm optimization,"The identification of a module's fault-proneness is very important for minimizing cost and improving the effectiveness of the software development process. How to obtain the correlation between software metrics and module's fault-proneness has been the focus of much research. This paper presents the application of hybrid artificial neural network (ANN) and Quantum Particle Swarm Optimization (QPSO) in software fault-proneness prediction. ANN is used for classifying software modules into fault-proneness or non fault-proneness categories, and QPSO is applied for reducing dimensionality. The experiment results show that the proposed prediction approach can establish the correlation between software metrics and modules’ fault-proneness, and is very simple because its implementation requires neither extra cost nor expert's knowledge. Proposed prediction approach can provide the potential software modules with fault-proneness to software developers, so developers only need to focus on these software modules, which may minimize effort and cost of software maintenance."
pub.1111122903,Measuring the Fault Predictability of Software using Deep Learning Techniques with Software Metrics,"Minimization of failures is the major expectation from reliable software. Predicting the software faults supports in identifying the location in the faulty modules for detailed testing to increase the maintainability. This paper presents fault prediction using some of the deep learning techniques utilizing source code metrics of the software. Accuracy, f-measure, recall, precision, receiver operating characteristic (ROC) curves and area under curve (AUC) values are considered to measure the performance of the deep learning methods. Experimental analysis on five NASA public benchmarked datasets depict Convolutional Neural Network (CNN) classifier as a more robust software fault prediction model achieving the highest accuracy rates. CNN is followed by Artificial Neural Network (ANN) and then Self-Organizing Map (SOM). Learning Vector Quantization (LVQ) version 3 and MultiLVQ have the worst performance on software fault prediction using software metrics."
pub.1101527675,Software Metrics for Fault Prediction Using Machine Learning Approaches a Literature Review with PROMISE Repository Dataset,"Software testing is an important and critical phase of software development life cycle to find software faults or defects and then correct those faults. However, testing process is a time-consuming activity that requires good planning and a lot of resources. Therefore, technique and methodology for predicting the testing effort is important process prior the testing process to significantly increase efficiency of time, effort and cost usage. Correspond to software metric usage for measuring software quality, software metric can be used to identify the faulty modules in software. Furthermore, implementing machine learning technique will allow computer to “learn” and able to predict the fault prone modules. Research in this field has become a hot issue for more than ten years ago. However, considering the high importance of software quality with support of machine learning methods development, this research area is still being highlighted until this year. In this paper, a survey of various software metric used for predicting software fault by using machine learning algorithm is examined. According to our review, this is the first study of software fault prediction that focuses to PROMISE repository dataset usage. Some conducted experiments from PROMISE repository dataset are compared to contribute a consensus on what constitute effective software metrics and machine learning method in software fault prediction."
pub.1173561702,A comparative study of deep learning techniques in software fault prediction,"Software fault prediction (SFP) is an important approach in software engineering that ensures software quality and reliability. Prediction of software faults helps developers identify faulty components in software systems. Several studies focus on software metrics which are input into machine learning models to predict faulty components. However, such studies may not capture the semantic and structural information of software that is necessary for building fault prediction models with better performance. Therefore, this paper discusses the effectiveness of deep learning models including Deep Belief Networks (DBN), Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), and Long-Short Term Memory (LSTM) that are utilized to construct fault prediction models based on the contextual information. The experiment, which has been conducted on seven Apache datasets, with Precision, Recall, and F1-score are performance metrics. The comparison results show that LSTM and RNN are potential techniques for building highly accurate fault prediction models."
pub.1171496332,Rand-Index Target Projective Gradient Deep Belief Network for Software Fault Prediction,"Predicting defective software modules before testing is a valuable operation that reduces time and cost of software testing.  Source code fault prediction plays a vital role in improving software quality that effectively assists in optimization testing resource allocation.  Several machine learning and ensemble learning techniques has been extensively evolved over the recent few years to predict defect at an early stage. These techniques made predictions based on historical defect data, the software metrics. Nevertheless, the time efficient and accurate fault predictions are the major challenging tasks that yet have to be addressed. In order to ensure accurate software fault prediction, a method called Rand-Index Target Projective Gradient Deep Belief Network (RTPGDBN) is designed. The proposed RTPGDBN method comprises of three processes namely acquiring JAVA packages, software metric selection and classification. First, the number of JAVA packages is used as input from the dataset. Second with the JAVA packages obtained as input, Rand similarity indexive target projection function is applied for selecting the most significant software metrics in order to minimize time complexity of fault prediction. Third, with the selected metrics, classification is performed using Tversky Gradient Deep Belief neural network. Also, gradient descent function is applied to minimize classification error, therefore ensuring accurate software fault classification results obtained at the output layer. Experimental setup of proposed RPGDDBN and existing methods are implemented in Java language and the dataset collected from smell prediction replication package. Performance analysis is carried out with different quantitative metrics such as accuracy, precision, recall, F-measure, and time complexity and space complexity. Through extensive experiments on repository data, experimental results indicate that our RPGDDBN method outperforms two state-of-the-art defect detection methods in terms of different performance metrics."
pub.1141489482,Software Fault Prediction Using Data Mining Techniques on Software Metrics,"Software industries have enormous demand for fault prediction of the faulty module and fault removal techniques. Many researchers have developed different fault prediction models to predict the fault at an early stage of the software development life cycle (SDLC). But the state-of-the-art model still suffers from the performance and generalize validation of the models. However, some researchers refer to data mining techniques, machine learning, and artificial intelligence play crucial roles in developing fault prediction models. A recent study stated that metric selection techniques also help to enhance the performance of models. Hence, to resolve the issue of improving the fault prediction model’s performance and validation, we have used data mining, instance selection, metric selection, and ensemble methods to beat the state-of-the-art results. For the validation, we have collected the 22 software projects from the four different software repositories. We have implemented three machine learning algorithms and three ensemble methods with two metric selection methods on 22 datasets. The statistical evaluation of the implemented model performed using Wilcoxon signed-rank test and the Friedman test followed by the Nemenyi test to find the significant model. As a result, the Random forest algorithm produces the best result with an average median of 95.43% (accuracy) and 0.96 (f-measure) on 22 software projects. Based on the Nemenyi test, Random forest (RF) is performing better with 4.54 (accuracy mean score) and 4.41 (f-measure mean score) shown in the critical diagram. Experimental study shows that data mining techniques with PCA provide better accuracy and f-measure."
pub.1156889503,Gaussian kernelized feature selection and improved multilayer perceptive deep learning classifier for software fault prediction,"Software fault prediction is the significant process of identifying the errors or defects or faults in a software product. But, accurate and timely detection is the major challenging issue in different existing approaches to predicting software defects. A novel Gaussian linear feature embedding-based statistical test piecewise multilayer perceptive deep learning classifier (GLFE-STPMPDLC) is introduced to improve software fault prediction accuracy and minimize time consumption. First, the input data are collected from the dataset. Next, the software metrics selection is carried out to select the significant metrics using Gaussian kernelized locally linear embedding with lesser software fault prediction. Then classification is carried out by Kaiser Meyer piecewise multilayer perceptive deep learning classifier for software fault prediction. The novelty of Kaiser–Meyer–Olkin (KMO) correlation test analyzes testing and training instances. The innovation of the Heaviside step activation function is applied for analyzing the KMO correlation test results and providing the final software fault prediction results. Finally, accurate fault prediction outcomes are achieved at the output layer with lesser error. Simulation of proposed GLFE-STPMPDLC technique achieves better 5%, 3%, 3% and 3% enhancement of fault prediction accuracy, precision, recall, and f-measure and 13% faster prediction time compared to conventional methods."
pub.1106990703,An effective fault prediction model developed using an extreme learning machine with various kernel methods,"System analysts often use software fault prediction models to identify fault-prone modules during the design phase of the software development life cycle. The models help predict faulty modules based on the software metrics that are input to the models. In this study, we consider 20 types of metrics to develop a model using an extreme learning machine associated with various kernel methods. We evaluate the effectiveness of the mode using a proposed framework based on the cost and efficiency in the testing phases. The evaluation process is carried out by considering case studies for 30 object-oriented software systems. Experimental results demonstrate that the application of a fault prediction model is suitable for projects with the percentage of faulty classes below a certain threshold, which depends on the efficiency of fault identification (low: 47.28%; median: 39.24%; high: 25.72%). We consider nine feature selection techniques to remove the irrelevant metrics and to select the best set of source code metrics for fault prediction."
pub.1090948347,"The application of ROC analysis in threshold identification, data imbalance and metrics selection for software fault prediction","Software engineers have limited resources and need metrics analysis tools to investigate software quality such as fault-proneness of modules. There are a large number of software metrics available to investigate quality. However, not all metrics are strongly correlated with faults. In addition, software fault data are imbalanced and affect quality assessment tools such as fault prediction or threshold values that are used to identify risky modules. Software quality is investigated for three purposes. First, the receiver operating characteristics (ROC) analysis is used to identify threshold values to identify risky modules. Second, the ROC analysis is investigated for imbalanced data. Third, the ROC analysis is considered for feature selection. This work validated the use of ROC to identify thresholds for four metrics (WMC, CBO, RFC and LCOM). The ROC results after sampling the data are not significantly different from before sampling. The ROC analysis selects the same metrics (WMC, CBO and RFC) in most datasets, while other techniques have a large variation in selecting metrics."
pub.1094812525,A Model for Early Prediction of Faults in Software Systems,"Quality of a software component can be measured in terms of fault proneness of data. Quality estimations are made using fault proneness data available from previously developed similar type of projects and the training data consisting of software measurements. To predict faulty modules in software data different techniques have been proposed which includes statistical method, machine learning methods, neural network techniques and clustering techniques. Predicting faults early in the software life cycle can be used to improve software process control and achieve high software reliability. The aim of proposed approach is to investigate that whether metrics available in the early lifecycle (i.e. requirement metrics), metrics available in the late lifecycle (i.e. code metrics) and metrics available in the early lifecycle (i.e. requirement metrics) combined with metrics available in the late lifecycle (i.e. code metrics) can be used to identify fault prone modules using decision tree based Model in combination of K-means clustering as preprocessing technique. This approach has been tested with CM1 real time defect datasets of NASA software projects. The high accuracy of testing results show that the proposed Model can be used for the prediction of the fault proneness of software modules early in the software life cycle."
pub.1103336804,Automated Tool for Extraction of Software Fault Data,"Open-source software repositories contain lots of useful information related to software development, software design, and software’s common error patterns. To access the software quality an automated software fault data extraction and preparation, which can be used for further prediction is still a major issue. Prediction of software fault has recently attracted the attention of software engineers. These prediction models require training fault data of projects. The fault training data contains information of software metrics and related bug information, and these data have to be prepared for each project. But it is not so easy to collect and prepare the fault data for the prediction model. We developed an automatic tool which extracts and prepares fault data for the prediction models. By using these automatic tools, we have extracted the data from the open-source projects developed in various languages. Extraction of fault data of various projects which includes source code and related defects from open-source software repository is performed. Various versions of open-source project software were taken from source forge and used for this purpose."
pub.1093452865,Tree-based Software Quality Estimation Models for Fault Prediction,"Complex high-assurance software systems depend highly on reliability of their underlying software applications. Early identification of high-risk modules can assist in directing quality enhancement efforts to modules that are likely to have a high number of faults. Regression tre models are simple and effective as software equality prediction models, and timely predictions from such models can be used to achieve high software reliability. This paper presents a case study from our comprehensive evaluation (with sever al large case studies) of currently available regression tr ee algorithms for software fault prediction. These are, CART-LS (least squar es),S-PLUS, and CART-LAD (least absolute deviation). The case study presented comprises of software design metrics collected from a large network telecommunications system consisting of almost 13 million lines of code. Tree models using design metrics are built to predict number of faults in modules. Besides being compared for fault prediction accuracy, algorithms are also compared based on structure and complexity of their tree models. Performance metrics, average absolute and aver age relative errors are used to eualuate fault prediction accuracy. Number of terminal nodes and number of independent variables utilized by a free model are used to gauge complexity and structure of regression trees. It was observe dthat S-PLUS trees had poor pr edictive accuracy and were large and more complex. On the other hand, CART-LAD trees had good accuracy and were simple and easy to interpret."
pub.1173855579,Effort-Aware Fault-Proneness Prediction Using Non-API-Based Package-Modularization Metrics,"Source code complexity of legacy object-oriented (OO) software has a trickle-down effect over the key activities of software development and maintenance. Package-based OO design is widely believed to be an effective modularization. Recently, theories and methodologies have been proposed to assess the complementary aspects of legacy OO systems through package-modularization metrics. These package-modularization metrics basically address non-API-based object-oriented principles, like encapsulation, commonality-of-goal, changeability, maintainability, and analyzability. Despite their ability to characterize package organization, their application towards cost-effective fault-proneness prediction is yet to be determined. In this paper, we present theoretical illustration and empirical perspective of non-API-based package-modularization metrics towards effort-aware fault-proneness prediction. First, we employ correlation analysis to evaluate the relationship between faults and package-level metrics. Second, we use multivariate logistic regression with effort-aware performance indicators (ranking and classification) to investigate the practical application of proposed metrics. Our experimental analysis over open-source Java software systems provides statistical evidence for fault-proneness prediction and relatively better explanatory power than traditional metrics. Consequently, these results guide developers for reliable and modular package-based software design."
pub.1095569204,An Empirical Analysis on Effective Fault Prediction Model Developed Using Ensemble Methods,"Software fault prediction models are employed to optimize testing resource allocation by identifying fault-prone classes before testing phases. We apply three different ensemble methods to develop a model for predicting fault proneness. We propose a framework to validate the source code metrics and select the right set of metrics with the objective to improve the performance of the fault prediction model. The fault prediction models are then validated using a cost evaluation framework. We conduct a series of experiments on 45 open source project dataset. Key conclusions from our experiments are: (1) Majority Voting Ensemble (MVE) methods outperformed other methods (2) selected set of source code metrics using the suggested source code metrics using validation framework as the input achieves better results compared to all other metrics (3) fault prediction method is effective for software projects with a percentage of faulty classes lower than the threshold value (low × 54.82%, medium × 41.04%, high × 28.10%)"
pub.1094318505,An Outlier Detection Algorithm Based on Object-Oriented Metrics Thresholds,"Detection of outliers in software measurement datasets is a critical issue that affects the performance of software fault prediction models built based on these datasets. Two necessary components of fault prediction models, software metrics and fault data, are collected from the software projects developed with object-oriented programming paradigm. We proposed an outlier detection algorithm based on these kinds of metrics thresholds. We used Random Forests machine learning classifier on two software measurement datasets collected from jEdit open-source text editor project and experiments revealed that our outlier detection approach improves the performance of fault predictors based on Random Forests classifier."
pub.1042029858,Estimating software readiness using predictive models,"In this study, defect tracking is used as a proxy method to predict software readiness. The number of remaining defects in an application under development is one of the most important factors that allow one to decide if a piece of software is ready to be released. By comparing predicted number of faults and number of faults discovered in testing, software manager can decide whether the software is likely ready to be released or not.The predictive model developed in this research can predict: (i) the number of faults (defects) likely to exist, (ii) the estimated number of code changes required to correct a fault and (iii) the estimated amount of time (in minutes) needed to make the changes in respective classes of the application. The model uses product metrics as independent variables to do predictions. These metrics are selected depending on the nature of source code with regards to architecture layers, types of faults and contribution factors of these metrics. The use of neural network model with genetic training strategy is introduced to improve prediction results for estimating software readiness in this study. This genetic-net combines a genetic algorithm with a statistical estimator to produce a model which also shows the usefulness of inputs.The model is divided into three parts: (1) prediction model for presentation logic tier (2) prediction model for business tier and (3) prediction model for data access tier. Existing object-oriented metrics and complexity software metrics are used in the business tier prediction model. New sets of metrics have been proposed for the presentation logic tier and data access tier. These metrics are validated using data extracted from real world applications. The trained models can be used as tools to assist software mangers in making software release decisions."
pub.1129302370,Noise Filtering and Imbalance Class Distribution Removal for Optimizing Software Fault Prediction using Best Software Metrics Suite,"Software fault detection is by far the most prevalent field of predictive analysis in the software engineering paradigm and several research centers have launched new ventures in this area. Predicting faults in software components before they are delivered to the end-users is of key importance, as it can save time, effort, and inconvenience associated with identifying and addressing these issues at later stages. This paper presents a software defect prediction technique to alleviate some basic problems of existing frameworks for predicting software defects. This study aims to combine simple noise removal, imbalanced class distribution, and software metrics selection techniques for optimizing defect prediction in software. The technique was tested on ten software fault prediction datasets. The experimental results including recall, precision, F-measure, accuracy, and ROC-AUC values show that the proposed method enhances fault prediction performance and the results obtained are better than or close to several comparative models. This proves the validity of our model."
pub.1047713528,An empirical analysis of package-modularization metrics: Implications for software fault-proneness,"ContextIn a large object-oriented software system, packages play the role of modules which group related classes together to provide well-identified services to the rest of the system. In this context, it is widely believed that modularization has a large influence on the quality of packages. Recently, Sarkar, Kak, and Rama proposed a set of new metrics to characterize the modularization quality of packages from important perspectives such as inter-module call traffic, state access violations, fragile base-class design, programming to interface, and plugin pollution. These package-modularization metrics are quite different from traditional package-level metrics, which measure software quality mainly from size, extensibility, responsibility, independence, abstractness, and instability perspectives. As such, it is expected that these package-modularization metrics should be useful predictors for fault-proneness. However, little is currently known on their actual usefulness for fault-proneness prediction, especially compared with traditional package-level metrics.ObjectiveIn this paper, we examine the role of these new package-modularization metrics for determining software fault-proneness in object-oriented systems.MethodWe first use principal component analysis to analyze whether these new package-modularization metrics capture additional information compared with traditional package-level metrics. Second, we employ univariate prediction models to investigate how these new package-modularization metrics are related to fault-proneness. Finally, we build multivariate prediction models to examine the ability of these new package-modularization metrics for predicting fault-prone packages.ResultsOur results, based on six open-source object-oriented software systems, show that: (1) these new package-modularization metrics provide new and complementary views of software complexity compared with traditional package-level metrics; (2) most of these new package-modularization metrics have a significant association with fault-proneness in an expected direction; and (3) these new package-modularization metrics can substantially improve the effectiveness of fault-proneness prediction when used with traditional package-level metrics together.ConclusionsThe package-modularization metrics proposed by Sarkar, Kak, and Rama are useful for practitioners to develop quality software systems."
pub.1094464848,Assessing UML Design Metrics for Predicting Fault-prone Classes in a Java System,"Identifying and fixing software problems before implementation are believed to be much cheaper than after implementation. Hence, it follows that predicting fault-proneness of software modules based on early software artifacts like software design is beneficial as it allows software engineers to perform early predictions to anticipate and avoid faults early enough. Taking this motivation into consideration, in this paper we evaluate the usefulness of UML design metrics to predict fault-proneness of Java classes. We use historical data of a significant industrial Java system to build and validate a UML-based prediction model. Based on the case study we have found that level of detail of messages and import coupling —both measured from sequence diagrams, are significant predictors of class fault-proneness. We also learn that the prediction model built exclusively using the UML design metrics demonstrates a better accuracy than the one built exclusively using code metrics."
pub.1130675464,Efficacy of Inheritance Aspect in Software Fault Prediction—A Survey Paper,"Software fault prediction (SFP) is a research area that helps development and testing process deliver software of good quality. Software metrics are of various types and are used in SFP for measurements. Inheritance is a prominent feature, which measures the depth, breadth, and complexity of object-oriented software. A few studies exclusively addressed the efficacy of inheritance in SFP. This provokes the need to identify the potential ingredients associated with inheritance, which can be helpful in SFP. In this paper, our aim is to collecting, organizing, categorizing, and investigating published fault prediction studies. Findings include identification of 54 inheritance metrics, 78 public datasets with various combinations of 10 inheritance metrics, 60% use of method level & use of private datasets, an increased number of studies using machine learning approaches. This study will facilitate scholars to studying previous literature on software fault prediction having software metrics, with their methods, public data sets, performance evaluation of machine learning algorithms, and findings of experimental results in a comfortable, and efficient way, emphasizing the inherited aspect specifically."
pub.1012387372,Can traditional fault prediction models be used for vulnerability prediction?,"Finding security vulnerabilities requires a different mindset than finding general faults in software—thinking like an attacker. Therefore, security engineers looking to prioritize security inspection and testing efforts may be better served by a prediction model that indicates security vulnerabilities rather than faults. At the same time, faults and vulnerabilities have commonalities that may allow development teams to use traditional fault prediction models and metrics for vulnerability prediction. The goal of our study is to determine whether fault prediction models can be used for vulnerability prediction or if specialized vulnerability prediction models should be developed when both models are built with traditional metrics of complexity, code churn, and fault history. We have performed an empirical study on a widely-used, large open source project, the Mozilla Firefox web browser, where 21% of the source code files have faults and only 3% of the files have vulnerabilities. Both the fault prediction model and the vulnerability prediction model provide similar ability in vulnerability prediction across a wide range of classification thresholds. For example, the fault prediction model provided recall of 83% and precision of 11% at classification threshold 0.6 and the vulnerability prediction model provided recall of 83% and precision of 12% at classification threshold 0.5. Our results suggest that fault prediction models based upon traditional metrics can substitute for specialized vulnerability prediction models. However, both fault prediction and vulnerability prediction models require significant improvement to reduce false positives while providing high recall."
pub.1094234269,Empirical Investigation of Fault Prediction Capability of Object Oriented Metrics of Open Source Software,"Open source software systems are playing important roles in many scientific and business software applications. To ensure acceptable levels of software quality Open source software (OSS) development process uses advanced and effective techniques. Quality improvement involves the detection of potential relationship between defect and open source software metrics. Many companies are investing in open source projects for making effective software. But, because open source software is often developed with a different management style and groups of people than the industrial ones, the quality and reliability of the code needs to be investigated. Hence, more projects need to be measured to obtain information about the characteristics and nature of the source code. This paper presents an empirical study of the fault prediction capabilities of object-oriented metrics given by Chidamber and Kemerer. We have carried out an empirical study and tried to find whether these metrics are significantly associated with faults or not. For this we have extracted source code processed it for metrics and associated it with the bugs. Finally the fault prediction capabilities of object oriented metrics have been evaluated by using Naïve Bayes and J48 machine learning algorithms"
pub.1181465883,A Comparative Analysis of Techniques Used for Software Fault Identification: A Survey,"In the domain of the software fault prediction numerous methods have been introduced and implemented using data mining techniques and machine learning models. Nevertheless, initial and early fault prediction is big challenging to be overcome and improvised with higher classification rate of fault prediction. In order to fix this issue several software solutions and approaches are suggested by many researchers. In this paper a comparative study is done amongst all these approaches. Some software solutions for defect prediction are based on the software metrics evaluation but they are time consuming. To resolve this considerable time complexity many researchers suggested the software defect prediction model incorporating the machine learning model and got the better result."
pub.1152788194,Issues-Driven features for software fault prediction,"Context: Software systems are an integral part of almost every modern industry. Unfortunately, the more complex the software, the more likely it will fail. A promising strategy is applying fault prediction models to predict which components may be defective. Since features are essential to the prediction model’s success, extracting significant features can improve the model’s accuracy. Previous research studies used software metrics as features in fault prediction models. One disadvantage of these features is that they measure the code developed rather than the requirements. On the other hand, faults are frequently the result of a mismatch between the software’s behavior and its needs. Objective: We present a novel paradigm for constructing features that consider the requirements as well by combining novel requirement metrics, called Issues-Driven features, and traditional code metrics. Method: We experimentally compare the performance of Issues-Driven features and state-of-the-art traditional features on 86 open-source projects from two organizations. Results: The results show that Issues-Driven features are significantly better than state-of-the-art features and achieve an improvement of 6 to 13 percent in terms of AUC. Conclusions: The study concludes that integrating the requirements into fault prediction features overcomes the limitations of traditional software metrics that are agnostic to the requirements of the software."
pub.1036142276,Software fault prediction for object oriented systems,"There always has been a demand to produce efficient and high quality software. There are various object oriented metrics that measure various properties of the software like coupling, cohesion, inheritance etc. which affect the software to a large extent. These metrics can be used in predicting important quality attributes such as fault proneness, maintainability, effort, productivity and reliability. Early prediction of fault proneness will help us to focus on testing resources and use them only on the classes which are predicted to be fault-prone. Thus, this will help in early phases of software development to give a measurement of quality assessment. This paper provides the review of the previous studies which are related to software metrics and the fault proneness. In other words, it reviews several journals and conference papers on software fault prediction. There is large number of software metrics proposed in the literature. Each study uses a different subset of these metrics and performs the analysis using different datasets. Also, the researchers have used different approaches such as Support vector machines, naive bayes network, random forest, artificial neural network, decision tree, logistic regression etc. Thus, this study focuses on the metrics used, dataset used and the evaluation or analysis method used by various authors. This review will be beneficial for the future studies as various researchers and practitioners can use it for comparative analysis."
pub.1056837196,Empirical study of fault prediction for open‐source systems using the Chidamber and Kemerer metrics,"Software testers are usually provoked with projects that have faults. Predicting a class's fault‐proneness is vital for minimising cost and improving the effectiveness of the software testing. Previous research on software metrics has shown strong relationships between software metrics and faults in object‐oriented systems using a binary variable. However, these models do not consider the history of faults in classes. In this work, a dependent variable is proposed that uses fault history to rate classes into four categories (none, low risk, medium risk and high risk) and to improve the predictive capability of fault models. The study is conducted on many releases of four open‐source systems. The study tests the statistical differences in seven machine learning algorithms to find whether the proposed variable can be used to build better prediction models. The performance of the classifiers using the four categories is significantly better than the binary variable. In addition, the results show improvements on the reliability of the prediction models as the software matures. Therefore the fault history improves the prediction of fault‐proneness of classes in open‐source systems."
pub.1120136181,The usefulness of software metric thresholds for detection of bad smells and fault prediction,"Context Software metrics may be an effective tool to assess the quality of software, but to guide their use it is important to define their thresholds. Bad smells and fault also impact the quality of software. Extracting metrics from software systems is relatively low cost since there are tools widely used for this purpose, which makes feasible applying software metrics to identify bad smells and to predict faults. Objective To inspect whether thresholds of object-oriented metrics may be used to aid bad smells detection and fault predictions. Method To direct this research, we have defined three research questions (RQ), two related to identification of bad smells, and one for identifying fault in software systems. To answer these RQs, we have proposed detection strategies for the bad smells: Large Class, Long Method, Data Class, Feature Envy, and Refused Bequest, based on metrics and their thresholds. To assess the quality of the derived thresholds, we have made two studies. The first one was conducted to evaluate their efficacy on detecting these bad smells on 12 systems. A second study was conducted to investigate for each of the class level software metrics: DIT, LCOM, NOF, NOM, NORM, NSC, NSF, NSM, SIX, and WMC, if the ranges of values determined by thresholds are useful to identify fault in software systems. Results Both studies confirm that metric thresholds may support the prediction of faults in software and are significantly and effective in the detection of bad smells. Conclusion The results of this work suggest practical applications of metric thresholds to identify bad smells and predict faults and hence, support software quality assurance activities.Their use may help developers to focus their efforts on classes that tend to fail, thereby minimizing the occurrence of future problems."
pub.1120756787,Empirical Analysis of Object-Oriented Metrics and Centrality Measures for Predicting Fault-Prone Classes in Object-Oriented Software,"A large number of metrics have been proposed in the literature to measure various structural properties of object-oriented software. Furthermore, many centrality measures have been introduced to identify central nodes in large networks. To the best of our knowledge, only few empirical software engineering studies have explored these metrics in the case of software systems. This paper aims at providing further evidence on the usefulness of centrality measures as indicators of software defect proneness by: (1) investigating the relationships between object-oriented metrics and centrality measures, and (2) exploring how they can be combined to improve the prediction of fault-prone classes in object-oriented software. We collected data from five different versions of one open source Java software system. We used the Principal Component Analysis technique to eliminate metrics (measures) providing redundant information. Then, we built different models to predict fault-prone classes using four machine learning algorithms. Results indicate that: (1) some centrality measures capture information that is not captured by traditional object-oriented metrics, and (2) combining centrality measures with object-oriented metrics improves the performance of fault-prone classes prediction."
pub.1094938372,Utilizing Computational Intelligence in Estimating Software Readiness,"Defect tracking using computational intelligence methods is used to predict software readiness in this study. By comparing predicted number of faults and number of faults discovered in testing, software managers can decide whether the software are ready to be released or not. Our predictive models can predict: (i) the number of faults (defects), (ii) the amount of code changes required to correct a fault and (iii) the amount of time (in minutes) to make the changes in respective object classes using software metrics as independent variables. The use of neural network model with a genetic training strategy is introduced to improve prediction results for estimating software readiness in this study. Existing object-oriented metrics and complexity software metrics are used in the Business Tier neural network based prediction model. New sets of metrics have been defined for the Presentation Logic Tier and Data Access Tier."
pub.1068093720,A UML Approximation of Three Chidamber-Kemerer Metrics and Their Ability to Predict Faulty Code across Software Projects,"Design-complexity metrics, while measured from the code, have shown to be good predictors of fault-prone object-oriented programs. Some of the most often used metrics are the Chidamber and Kemerer metrics (CK). This paper discusses how to make early predictions of fault-prone object-oriented classes, using a UML approximation of three CK metrics. First, we present a simple approach to approximate Weighted Methods per Class (WMC), Response For Class (RFC) and Coupling Between Objects (CBO) CK metrics using UML collaboration diagrams. Then, we study the application of two data normalization techniques. Such study has a twofold purpose: to decrease the error approximation in measuring the mentioned CK metrics from UML diagrams, and to obtain a more similar data distribution of these metrics among software projects so that better prediction results are obtained when using the same prediction model across different software projects. Finally, we construct three prediction models with the source code of a package of an open source software project (Mylyn from Eclipse), and we test them with several other packages and three different small size software projects, using their UML and code metrics for comparison. The results of our empirical study lead us to conclude that the proposed UML RFC and UML CBO metrics can predict fault-proneness of code almost with the same accuracy as their respective code metrics do. The elimination of outliers and the normalization procedure used were of great utility, not only for enabling our UML metrics to predict fault-proneness of code using a code-based prediction model but also for improving the prediction results of our models across different software packages and projects."
pub.1006045342,Empirical analysis of network measures for predicting high severity software faults,"Network measures are useful for predicting fault-prone modules. However, existing work has not distinguished faults according to their severity. In practice, high severity faults cause serious problems and require further attention. In this study, we explored the utility of network measures in high severity faultproneness prediction. We constructed software source code networks for four open-source projects by extracting the dependencies between modules. We then used univariate logistic regression to investigate the associations between each network measure and fault-proneness at a high severity level. We built multivariate prediction models to examine their explanatory ability for fault-proneness, as well as evaluated their predictive effectiveness compared to code metrics under forward-release and cross-project predictions. The results revealed the following: (1) most network measures are significantly related to high severity fault-proneness; (2) network measures generally have comparable explanatory abilities and predictive powers to those of code metrics; and (3) network measures are very unstable for cross-project predictions. These results indicate that network measures are of practical value in high severity fault-proneness prediction."
pub.1094932766,Software Defect Prediction Using Exception Handling Call Graphs: A Case Study,"The ability to predict which modules are fault-prone can assist in directing quality enhancement efforts to modules at risk. This is especially critical for high-assurance systems where software failures may have severe consequences. While the field of defect prediction based on software metrics is mature, no study has addressed the use of metrics for predicting faults related to exception handling. In this paper, we propose exception-based software metrics that are based on the structural attributes of exception handling call graphs. We empirically validate the proposed metrics through a case study of Hadoop Core using data mined from software repositories and defect reports. The results of our case study are comparable to the results of other software metric studies in the literature. We also show that our exception - based software metrics can be better predictors of fault-proneness of exception classes compared to conventional software metrics."
pub.1030311613,Applying machine learning to software fault-proneness prediction,"The importance of software testing to quality assurance cannot be overemphasized. The estimation of a module’s fault-proneness is important for minimizing cost and improving the effectiveness of the software testing process. Unfortunately, no general technique for estimating software fault-proneness is available. The observed correlation between some software metrics and fault-proneness has resulted in a variety of predictive models based on multiple metrics. Much work has concentrated on how to select the software metrics that are most likely to indicate fault-proneness. In this paper, we propose the use of machine learning for this purpose. Specifically, given historical data on software metric values and number of reported errors, an Artificial Neural Network (ANN) is trained. Then, in order to determine the importance of each software metric in predicting fault-proneness, a sensitivity analysis is performed on the trained ANN. The software metrics that are deemed to be the most critical are then used as the basis of an ANN-based predictive model of a continuous measure of fault-proneness. We also view fault-proneness prediction as a binary classification task (i.e., a module can either contain errors or be error-free) and use Support Vector Machines (SVM) as a state-of-the-art classification method. We perform a comparative experimental study of the effectiveness of ANNs and SVMs on a data set obtained from NASA’s Metrics Data Program data repository."
pub.1051639317,Prediction of Software Quality Model Using Gene Expression Programming,"There has been number of measurement techniques proposed in the literature. These metrics can be used in assessing quality of software products, thereby controlling costs and schedules. The empirical validation of object-oriented (OO) metrics is essential to ensure their practical relevance in industrial settings. In this paper, we empirically validate OO metrics given by Chidamber and Kemerer for their ability to predict software quality in terms of fault proneness. In order to analyze these metrics we use gene expression programming (GEP). Here, we explore the ability of OO metrics using defect data for open source software. Further, we develop a software quality metric and suggest ways in which software professional may use this metric for process improvement. We conclude that GEP can be used in detecting fault prone classes. We also conclude that the proposed metric may be effectively used by software managers tin predicting faulty classes in earlier phases of software development."
pub.1084650039,A Combined-Learning Based Framework for Improved Software Fault Prediction,"Software Fault Prediction (SFP) is found to be vital to predict the fault-proneness of software modules, which allows software engineers to focus development activities on fault-prone modules, thereby prioritize and optimize tests, improve software quality and make better use of resources. In this regard, machine learning has been successfully applied to solve classification problems for SFP. Nevertheless, the presence of different software metrics, the redundant and irrelevant features and the imbalanced nature of software datasets have created more and more challenges for the classification problems. Therefore, the objective of this study is to independently examine software metrics with multiple Feature Selection (FS) combined with Data Balancing (DB) using Synthetic Minority Oversampling Techniques for improving classification performance. Accordingly, a new framework that efficiently handles those challenges in a combined form on both Object Oriented Metrics (OOM) and Static Code Metrics (SCM) datasets is proposed. The experimental results confirm that the prediction performance could be compromised without suitable Feature Selection Techniques (FST). To mitigate that, data must be balanced. Thus our combined technique assures the robust performance. Furthermore, a combination of Random Forts (RF) with Information Gain (IG) FS yields the highest Receiver Operating Characteristic (ROC) curve (0.993) value, which is found to be the best combination when SCM are used, whereas the combination of RF with Correlation-based Feature Selection (CFS) guarantees the highest ROC (0.909) value, which is found to be the best choice when OOM are used. Therefore, as shown in this study, software metrics used to predict the fault proneness of the software modules must be carefully examined and suitable FST for software metrics must be cautiously selected. Moreover, DB must be applied in order to obtain robust performance. In addition to that, dealing with the challenges mentioned above, the proposed framework ensures the remarkable classification performance and lays the pathway to quality assurance of software."
pub.1123202181,Experimental Study on Software Fault Prediction Using Machine Learning Model,"Faults are the leading cause of time consuming and cost wasting during software life cycle. Predicting faults in early stage improves the quality and reliability of the system and also reduces cost for software development. Many researches proved that software metrics are effective elements for software fault prediction. In addition, many machine learning techniques have been developed for software fault prediction. It is important to determine which set of metrics are effective for predicting fault by using machine learning techniques. In this paper, we conduct an experimental study to evaluate the performance of seven popular techniques including Logistic Regression, K-nearest Neighbors, Decision Tree, Random Forest, Naïve Bayes, Support Vector Machine and Multilayer Perceptron using software metrics from Promise repository dataset usage. Our experiment is performed on both method-level and class-level datasets. The experimental results show that Support Vector Machine archives a higher performance in class-level datasets and Multilayer Perception produces a better accuracy in method-level datasets among seven techniques above."
pub.1094791278,"Using product, process, and execution metrics to predict fault-prone software modules with classification trees","Software-quality classification models can make predictions to guide improvement efforts to those modules that need it the most. Based on software metrics, a model can predict which modules will be considered fault-prone, or not. We consider a module fault-prone if any faults were discovered by customers. Useful predictions are contingent on the availability of candidate predictors that are actually related to faults discovered by customers. With a diverse set of candidate predictors in hand, classification-tree modeling is a robust technique for building such software quality models. This paper presents an empirical case study of four releases of a very large telecommunications system. The case study used the regression-tree algorithm in the S-Plus package and then applied our general decision rule to classify modules. Results showed that in addition to product metrics, process metrics and execution metrics were significant predictors of faults discovered by customers."
pub.1020598622,Software fault prediction: A literature review and current trends,"Software engineering discipline contains several prediction approaches such as test effort prediction, correction cost prediction, fault prediction, reusability prediction, security prediction, effort prediction, and quality prediction. However, most of these prediction approaches are still in preliminary phase and more research should be conducted to reach robust models. Software fault prediction is the most popular research area in these prediction approaches and recently several research centers started new projects on this area. In this study, we investigated 90 software fault prediction papers published between year 1990 and year 2009 and then we categorized these papers according to the publication year. This paper surveys the software engineering literature on software fault prediction and both machine learning based and statistical based approaches are included in this survey. Papers explained in this article reflect the outline of what was published so far, but naturally this is not a complete review of all the papers published so far. This paper will help researchers to investigate the previous studies from metrics, methods, datasets, performance evaluation metrics, and experimental results perspectives in an easy and effective manner. Furthermore, current trends are introduced and discussed."
pub.1122709358,Empirical validation of object-oriented metrics on cross-projects with different severity levels,"An object-oriented (OO) metrics has become crucial desideratum for software effort and fault predictions. To strengthen the adequacy of object-oriented metrics, it becomes important to know relationship between OO metrics and fault proneness at different levels of severity. It is inconceivable to build model of accurate estimate due to the inherent uncertainty in development projects. Empirical validation of software metrics is essential issue to determine applicability of prediction model. In this study, empirical validation is done on OO metrics given by Chidamber and Kemerer (CK suite) for predicting faults at different severity levels. This paper also instanced on defect prediction using cross-projects (CP) because of the unpredictability in selection of software attributes by analogy-based approach that deliver imprecise and ambiguous solution. This paper depicts detection of fault-proneness by extracting the relevant OO metrics and such models helps to focus on fault-prone modules of new projects by allocating more resources to them with use of regression and other machine learning methods. Combination of CP data with regression techniques improves effectiveness of prediction by extracting similar features impacted by all datasets."
pub.1164632021,"Software Fault Prediction Using Combinations of Code Smells, Code Metrics, and Code Smell Metrics With Ensemble and Deep Learning",Code smells are the structural characteristics of the software under development that indicate poor code choices and can cause errors or failures in the software and they can degrade the software maintenance and evolution processes. Software fault prediction (SFP) helps predict the probability of the existence of software faults utilizing code characteristics and metrics. Code smells-based datasets are based on a variety of code measures such as information about the presence of certain code smells or a combination of code smells with code metrics and code smell metrics with code metrics. We investigate the effectiveness and usefulness of these different combinations for performance evaluation and improvement of SFP models. We label the unlabeled datasets using clustering and pseudo-labeling techniques. We implement models considering ensemble methods and deep learning algorithms and compare performance. We use k-fold cross-validation and our results outperform existing benchmark studies. We conclude that code smells-based software defect prediction has optimal accuracy and precision.
pub.1143458302,Prediction of software fault-prone classes using ensemble random forest with adaptive synthetic sampling algorithm,"The process of predicting fault module in software is known as Software Fault Prediction (SFP) which is important for releasing software versions that are dependent on the predefined metrics due to historical faults in software. The fault prediction in software such as components, classes and modules, at an early stage in the development cycle, is important as it significantly contributes to time reduction and cost reduction. Therefore, the modules that are used for processing each step is reduced by the unnecessary efforts eliminated the faults during development process. However, the problem of imbalanced dataset becomes a significant challenge during SFP for software fault prediction at an early stage. The limitations such as inclusion of software metric for SFP models, cost effectiveness of the fault and the fault density prediction, are still few obstacles faced by research. The proposed Butterfly optimization performs feature selection that helps to predict meticulous and remarkable results by developing the applications of Machine Learning techniques. The present research uses Ensemble Random Forest with Adaptive Synthetic Sampling (E-RF-ADASYN) for fault prediction by using various classifiers which is mentioned in the proposed method section. The proposed E-RF-ADASYN obtained Area Under Curve (AUC) of 0.854767 better when compared with the existing method Rough-KNN Noise-Filtered Easy Ensemble (RKEE) of 0.771."
pub.1023938551,A comparison of some soft computing methods for software fault prediction,"The main expectation from reliable software is the minimization of the number of failures that occur when the program runs. Determining whether software modules are prone to fault is important because doing so assists in identifying modules that require refactoring or detailed testing. Software fault prediction is a discipline that predicts the fault proneness of future modules by using essential prediction metrics and historical fault data. This study presents the first application of the Adaptive Neuro Fuzzy Inference System (ANFIS) for the software fault prediction problem. Moreover, Artificial Neural Network (ANN) and Support Vector Machine (SVM) methods, which were experienced previously, are built to discuss the performance of ANFIS. Data used in this study are collected from the PROMISE Software Engineering Repository, and McCabe metrics are selected because they comprehensively address the programming effort. ROC-AUC is used as a performance measure. The results achieved were 0.7795, 0.8685, and 0.8573 for the SVM, ANN and ANFIS methods, respectively."
pub.1093907757,An Artificial Immune System Approach for Fault Prediction in Object-Oriented Software,"The features of real-time dependable systems are availability, reliability, safety and security. In the near future, real-time systems will be able to adapt themselves according to the specific requirements and real-time dependability assessment technique will be able to classify modules as faulty or fault-free. Software fault prediction models help us in order to develop dependable software and they are commonly applied prior to system testing. In this study, we examine Chidamber-Kemerer (CK) metrics and some method-level metrics for our model which is based on Artificial Immune Recognition System (AIRS) algorithm. The dataset is a part of NASA Metrics Data Program and class-level metrics are from PROMISE repository. Instead of validating individual metrics, our mission is to improve the prediction performance of our model. The experiments indicate that the combination of CK and the lines of code metrics provide the best prediction results for our fault prediction model. The consequence of this study suggests that class-level data should be used rather than methodlevel data to construct relatively better fault prediction models. Furthermore, this model can constitute a part of real-time dependability assessment technique for the future."
pub.1034120246,Iterative identification of fault-prone binaries using in-process metrics,"Code churn, the amount of code change taking place within a software unit over time, has been correlated with fault-proneness in software systems. We investigate the use of code churn and static metrics collected at regular time intervals during the development cycle to predict faults in an iterative, in-process manner. We collected 159 churn and structure metrics from six, four-month snapshots of a 1 million LOC Microsoft product. The number of software faults fixed during each period is recorded per binary module. Using stepwise logistic regression, we create a prediction model to identify fault-prone binaries using three parameters: code churn (the number of new and changed blocks); class Fan In and class Fan Out (normalized by lines of code). The iteratively-built model is 80.0% accurate at predicting fault-prone and non-fault-prone binaries. These fault-prediction models have the advantage of allowing the engineers to observe how their fault-prediction profile evolves over time."
pub.1140014949,Software fault prediction using machine learning techniques with metric thresholds,"BACKGROUND: Fault data is vital to predicting the fault-proneness in large systems. Predicting faulty classes helps in allocating the appropriate testing resources for future releases. However, current fault data face challenges such as unlabeled instances and data imbalance. These challenges degrade the performance of the prediction models. Data imbalance happens because the majority of classes are labeled as not faulty whereas the minority of classes are labeled as faulty. AIM: The research proposes to improve fault prediction using software metrics in combination with threshold values. Statistical techniques are proposed to improve the quality of the datasets and therefore the quality of the fault prediction. METHOD: Threshold values of object-oriented metrics are used to label classes as faulty to improve the fault prediction models The resulting datasets are used to build prediction models using five machine learning techniques. The use of threshold values is validated on ten large object-oriented systems. RESULTS: The models are built for the datasets with and without the use of thresholds. The combination of thresholds with machine learning has improved the fault prediction models significantly for the five classifiers. CONCLUSION: Threshold values can be used to label software classes as fault-prone and can be used to improve machine learners in predicting the fault-prone classes."
pub.1152287487,The Effect of Environmental Metrics on Software Fault Prediction,"In this study, besides the software metrics, the environmental metrics such as experience of software engineer, similar project experience, size of the project, programming language, time spent on analysis and development are also explored to see whether they also affect the results of software fault prediction and what would be the success rates. The dataset for this study was generated from combining various data from 10 projects. A total of 36 metrics and 6676 test cases were evaluated. The errors occurred in the test cases are not just considered as an error, their priority and cases that cannot be tested are also taken into consideration. Nine fault levels are employed in models. Models are created with four different algorithms which have achieved a success rate of; 76% by the decision tree algorithm, 94% by the nearest neighbors algorithm, 90% by the random forests algorithm and 73% by the Adaboost Classifier Algorithm. It was observed that environmental metrics are indeed effective in software fault prediction and when applied with machine learning algorithms a high rate of success can be achieved."
pub.1092440727,A bayesian belief network based model for predicting software faults in early phase of software development process,"It is always better to have an idea about the future situation of a present work. Prediction of software faults in the early phase of software development life cycle can facilitate to the software personnel to achieve their desired software product. Early prediction is of great importance for optimizing the development cost of a software project. The present study proposes a methodology based on Bayesian belief network, developed to predict total number of faults and to reach a target value of total number of faults during early development phase of software lifecycle. The model has been carried out using the information from similar or earlier version software projects, domain expert’s opinion and the software metrics. Interval type-2 fuzzy logic has been applied for obtaining the conditional probability values in the node probability tables of the belief network. The output pattern corresponding to the total number of faults has been identified by artificial neural network using the input pattern from similar or earlier project data. The proposed Bayesian framework facilitates software personnel to gain the required information about software metrics at early phase for achieving targeted number of software faults. The proposed model has been applied on twenty six software project data. Results have been validated by different statistical comparison criterion. The performance of the proposed approach has been compared with some existing early fault prediction models."
pub.1124877925,On Fault Localization Using Machine Learning Techniques,"Early prediction of faulty modules provides a way to support software quality assurance activities through improved scheduling and effectiveness of process control. Different fault prediction models have been proposed by researchers for early prediction of faults. However, despite predicting faulty classes, these techniques don’t provide information about identifying the location of occurrence of faults. In this paper, we aim to propose a methodology not only to predict faults but also for fault localization as well. We first make use of various datasets to build a software fault prediction model based. We make use of random forest machine learning technique to train our model. We also extract CK-metrics from different modules and we then make use of these metrics for fault localization. In order to do validation, we make use of case studies where we do fault prediction, fault localization and then run test cases to see if our prediction was correct."
pub.1120262086,A taxonomy of metrics for software fault prediction,"In the field of Software Fault Prediction (SFP), researchers exploit software metrics to build predictive models using machine learning and/or statistical techniques. SFP has existed for several decades and the number of metrics used has increased dramatically. Thus, the need for a taxonomy of metrics for SFP arises firstly to standardize the lexicon used in this field so that the communication among researchers is simplified and then to organize and systematically classify the used metrics. In this doctoral symposium paper, I present my ongoing work which aims not only to build such a taxonomy as comprehensive as possible, but also to provide a global understanding of the metrics for SFP in terms of detailed information: acronym(s), extended name, univocal description, granularity of the fault prediction (e.g., method and class), category, and research papers in which they were used."
pub.1050027319,Practical development of an Eclipse-based software fault prediction tool using Naive Bayes algorithm,"Despite the amount of effort software engineers have been putting into developing fault prediction models, software fault prediction still poses great challenges. This research using machine learning and statistical techniques has been ongoing for 15years, and yet we still have not had a breakthrough. Unfortunately, none of these prediction models have achieved widespread applicability in the software industry due to a lack of software tools to automate this prediction process. Historical project data, including software faults and a robust software fault prediction tool, can enable quality managers to focus on fault-prone modules. Thus, they can improve the testing process. We developed an Eclipse-based software fault prediction tool for Java programs to simplify the fault prediction process. We also integrated a machine learning algorithm called Naive Bayes into the plug-in because of its proven high-performance for this problem. This article presents a practical view to software fault prediction problem, and it shows how we managed to combine software metrics with software fault data to apply Naive Bayes technique inside an open source platform."
pub.1137164925,Literature Review: Predicting Faults in Object-Oriented Software,"Software fault prediction has become quite famous in the software engineering. If software faults are predicted earlier, it leads to good quality of software, and it reduces the resources and time required for testing, which ultimately leads to saving a considerable cost and effort that are used for testing purpose. In this literature study, we studied the major works done so far in the software defect prediction paradigm to find out the various benefit of predicting faults at initial phases of software product development. This paper aims to find answers to questions such as what are the merits and limitations of models developed so far, what are the possible areas of software fault prediction paradigm that are still open for research, what are the best suitable metrics used for predicting errors, and many more. From the literature survey, we analyzed that research conducted for predicting errors in object-oriented software so far was conducted on a small scale and using the limited metric suite. None of the studies gave a generalized model that could perform well for most of the datasets. They do not handle well the problem of imbalanced class distribution and noisy data. Many prediction models have already been developed so far, but most of them focus only on classification problem that is detecting faulty/not faulty classes."
pub.1165744673,Software Quality Sustainability Measurement Using Machine Learning Algorithms,"<p>Software quality is of paramount importance. Software quality can be directly affected by software defect prediction. This topic has become a hot topic over the past few years. Software defects can have a key role on the software quality, leading to higher maintenance costs, overruns, delays, and increased costs. This paper discusses the Machine-learning algorithms - ANN (Particle Swarm Optimization), DT (Decision Trees), NB(Naive Bayes), DT (Decision Trees), DT (Decision Trees), DT (Decision Trees), DT (Decision Trees), DT (Decision Trees), DT (Decision Trees), LC [Linear Classifier]).Software quality is dependent on the ability to predict faults. This helps reduce the time and cost of software testing. Software metrics can be used to determine the program's difficulty and duration. Software metrics can also be used to predict module faults. This requires extensive research. This empirical research seeks to identify the factors that significantly improve fault prediction models and related product metrics. This paper discusses software metrics and offers suggestions for improving software defect prediction.</p>"
pub.1137887098,Comparative analysis of software fault prediction using various categories of classifiers,"The quality of the software being developed varies with the size and complexity of the software. It is a matter of concern in software development as it impairs the faith of customers on the software companies. The quality of software can be improved if the prediction of faults and flaws in it are done in the early phases of the software development and thus reducing the resources to be used in the testing phase. The rise in the use of Object-Oriented technology for developing software has paved the way for considering the Object-Oriented metrics for software fault prediction. Numerous machine learning and statistical techniques have been used to predict the defects in software using these software metrics as independent variables and bug proneness as dependent variable. Our work aims at finding the best category and hence the best classifier for classification of faults. This work uses twenty-one classifiers belonging to five categories of classification on five open source software having Object-Oriented metrics. The classification LearnerApp of MATLAB has been used to evaluate various classification models. The work proposes the use of Ensemble and SVM techniques over KNN, Regression, and Tree. The bagged trees (ensemble) and cubic (SVM) are found to be the best predictors amongst the twenty-one classifiers."
pub.1127699526,Object Oriented Fault Prediction Analysis Using Machine Learning Algorithms,"One of the important key element in the development and maintenance process of software is fault prediction, it concerns the overall success of the system. Predicting software faults at the initial phase helps the developer to build reliable software and also minimise the cost. Fault prediction model provide insights to development team about faulty behaviour and thus act accordingly. The study presented in this paper discusses the performances of various machine learning algorithms in predicting fault prone classes and also investigates the role played by different software metrics of the datasets. First we apply the correlation based feature selection technique to get set of uncorrelated metrics that are highly desirable and informative for prediction. Then we develop model for prediction with the help of some supervised machine learning techniques. These models are validated on six different versions of object oriented java project obtained from GitHub."
pub.1011756592,Comparative Analysis of Decision Trees with Logistic Regression in Predicting Fault-Prone Classes,"There are available metrics for predicting fault prone classes, which may help software organizations for planning and performing testing activities. This may be possible due to proper allocation of resources on fault prone parts of the design and code of the software. Hence, importance and usefulness of such metrics is understandable, but empirical validation of these metrics is always a great challenge. Decision Tree (DT) methods have been successfully applied for solving classification problems in many applications. This paper evaluates the capability of three DT methods and compares its performance with statistical method in predicting fault prone software classes using publicly available NASA data set. The results indicate that the prediction performance of DT is generally better than statistical model. However, similar types of studies are required to be carried out in order to establish the acceptability of the DT models."
pub.1040067116,"Investigating the effect of dataset size, metrics sets, and feature selection techniques on software fault prediction problem","Software quality engineering comprises of several quality assurance activities such as testing, formal verification, inspection, fault tolerance, and software fault prediction. Until now, many researchers developed and validated several fault prediction models by using machine learning and statistical techniques. There have been used different kinds of software metrics and diverse feature reduction techniques in order to improve the models’ performance. However, these studies did not investigate the effect of dataset size, metrics set, and feature selection techniques for software fault prediction. This study is focused on the high-performance fault predictors based on machine learning such as Random Forests and the algorithms based on a new computational intelligence approach called Artificial Immune Systems. We used public NASA datasets from the PROMISE repository to make our predictive models repeatable, refutable, and verifiable. The research questions were based on the effects of dataset size, metrics set, and feature selection techniques. In order to answer these questions, there were defined seven test groups. Additionally, nine classifiers were examined for each of the five public NASA datasets. According to this study, Random Forests provides the best prediction performance for large datasets and Naive Bayes is the best prediction algorithm for small datasets in terms of the Area Under Receiver Operating Characteristics Curve (AUC) evaluation parameter. The parallel implementation of Artificial Immune Recognition Systems (AIRS2Parallel) algorithm is the best Artificial Immune Systems paradigm-based algorithm when the method-level metrics are used."
pub.1146770693,RELMP-MM: an approach to cross project fault prediction using improved regularized extreme learning machine and identical matched metrics,"Cross project fault prediction (CPFP) is a challenging issue in the software fault prediction (SFP) domain due to different data distributions in source and target datasets. To resolve this issue, we have proposed an efficient and improved version of the existing regularized extreme learning machine (RELM), we call it as RELM Plus. The proposed RELM Plus model is further extended using the concept of matched metrics to predict the number of software faults on cross-project data, we call it as RELMP-MM model. The proposed RELMP-MM model selects the source dataset corresponding to the given target dataset based on the number of identical matched metrics. Then, the proposed model predicts the number of software faults on the given target dataset. In this paper, we have considered both within project fault prediction (WPFP) as well as CPFP. The proposed model is validated using twenty-five public datasets. The experimental results along with the statistical analysis show that the proposed RELMP-MM model performs significantly better as compared to existing state of the art models. It shows an improvement of at least 8% to 13% in terms of Average Absolute Error (AAE) and 7% to 12% in terms of Average Relative Error (ARE)."
pub.1092053320,Analysis of Feature Ranking Techniques for Defect Prediction in Software Systems,"Software quality is an important parameter, and it plays a crucial role in software development. One of the most important software quality attributes is fault proneness. It evaluates the quality of the final product. Fault proneness prediction models must be built in order to enhance software quality. There are various software metrics which help in software modeling, but it is a cumbersome and time-consuming process to use all of them. So, there is always a need to select those set of software metrics which help in determining fault proneness. Careful selection of software metrics is a major concern, and it becomes crucial if the search space is too large. This study focuses on the ranking of software metrics for building defect prediction models. Hybrid approach is applied in which feature ranking techniques are used to reduce the search space along with the feature subset selection methods. Classification algorithms are used for training the defect prediction models. The area which is under the receiver operating characteristic curve is utilized for evaluating the performance of the classifiers. The experimental results indicate that most of the feature ranking techniques have almost similar results, and automatic hybrid search outperforms all other feature subset selection methods. Furthermore, the result helps us to focus only on those set of metrics which have almost the same impact on the end result as compared to the original set of metrics."
pub.1061789125,Are Slice-Based Cohesion Metrics Actually Useful in Effort-Aware Post-Release Fault-Proneness Prediction? An Empirical Study,"Background. Slice-based cohesion metrics leverage program slices with respect to the output variables of a module to quantify the strength of functional relatedness of the elements within the module. Although slice-based cohesion metrics have been proposed for many years, few empirical studies have been conducted to examine their actual usefulness in predicting fault-proneness. Objective. We aim to provide an in-depth understanding of the ability of slice-based cohesion metrics in effort-aware post-release fault-proneness prediction, i.e. their effectiveness in helping practitioners find post-release faults when taking into account the effort needed to test or inspect the code. Method. We use the most commonly used code and process metrics, including size, structural complexity, Halstead's software science, and code churn metrics, as the baseline metrics. First, we employ principal component analysis to analyze the relationships between slice-based cohesion metrics and the baseline metrics. Then, we use univariate prediction models to investigate the correlations between slice-based cohesion metrics and post-release fault-proneness. Finally, we build multivariate prediction models to examine the effectiveness of slice-based cohesion metrics in effort-aware post-release fault-proneness prediction when used alone or used together with the baseline code and process metrics. Results. Based on open-source software systems, our results show that: 1) slice-based cohesion metrics are not redundant with respect to the baseline code and process metrics; 2) most slice-based cohesion metrics are significantly negatively related to post-release fault-proneness; 3) slice-based cohesion metrics in general do not outperform the baseline metrics when predicting post-release fault-proneness; and 4) when used with the baseline metrics together, however, slice-based cohesion metrics can produce a statistically significant and practically important improvement of the effectiveness in effort-aware post-release fault-proneness prediction. Conclusion. Slice-based cohesion metrics are complementary to the most commonly used code and process metrics and are of practical value in the context of effort-aware post-release fault-proneness prediction."
pub.1147324391,Hybrid Software Reliability Prediction Model Using Feature Selection and Support Vector Classifier,"The primary purpose of the software industry is to provide high-quality software. Software system failure is caused by faulty software components. The goal of reliable software is to reduce the amount of software programme failures. Software defect prediction is a crucial aspect of developing high-quality software. One can predict software failures by implement essential prediction metrics and previous fault information. A good software fault prediction model makes testing easier while also improving the quality and consistency of software. For defect prediction systems based on diverse parameters, several methodologies have been proposed. However, none of the models meet the criteria for software reliability defect prediction. So in this article we proposed a hybrid software reliability model using feature selection and support vector classifier. In terms of software reliability defect prediction, the provided methodology is acceptable for different software metrics with experimental approvals utilizing a standard dataset. In the methodology, the NASA Metrics Data Program datasets are used for real-time verification and validation."
pub.1094806875,Effect of Coupling on Software Faults: An Empirical Study,"Software product's quality is one of the important aspects that affect the user, the developer, and the product. Measuring quality in the early phases of the project life cycle is a major goal of project planning. Accordingly, several research studies have been proposed to measure the software product quality attributes. In this paper, we empirically study the impact of afferent coupling (Ca), efferent coupling (Ce) and coupling between object (CBO) metrics on fault prediction using bivariate correlation. We built a prediction model using these metrics to predict faults by using multivariate logistic linear regression. A case study of an open source object oriented systems is used to evaluate the correlation between coupling metrics and faults. The results indicate that the efferent coupling (Ce) is a better indicator for fault prediction than afferent coupling (Ca) and CBO (coupling between object)"
pub.1051982045,Comparing Efficiency of Software Fault Prediction Models Developed Through Binary and Multinomial Logistic Regression Techniques,"Software fault prediction method used to improve the quality of software. Defective module leads to decrease the customer satisfaction and improve cost. Software fault prediction technique implies a good investment in better design in future systems to avoid building an error prone modules. The study used software metrics effectiveness in developing models in 2 aspects (binary and multinomial) Logistic Regression. We are developing multivariate (combined effect of object-oriented metrics) models in both aspects for finding the classes in different error categories for the three versions of Eclipse, the Java-based open-source Integrated Development Environment. The distribution of bugs among individual parts of a software system is not uniform, in that case Multinomial aspects helps the tester to prioritize the tests with the knowledge of error range or category and therefore, work more efficiently. Multinomial models are showing better result than Binary models."
pub.1094350855,Software Quality Assessment for Open Source Software Using Logistic & Naive Bayes Classifier,"Quality of a software product being designed, has a critical role in software process management. Detection and prediction of faults in a software with huge lines of code is a very tedious task. So it is very essential, as to reduce the maintanence cost and inturn increase the software reliability. Many object-oriented metrics have found to be suitable for software fault prediction. Using data mining techniques, design of prediction and classification models can be incorporated to give insight of the systems quality to the developing team to effectively tackle the quality problems. In this article, Chidamber and Kemerer Metric suite, along with classifiers which have immense classification capacity have been used in predicting software fault classification accuracy. From the obtained resulted it can be concluded that Logistic classifier is able to obtain better fault classification accuracy when compared to Naive Bayes approach."
pub.1093942126,A Model to Assess the Effectiveness of Fault Prediction Techniques for Quality Assurance,"Fault prediction techniques aim to predict faulty module in order to reduce the effort to be applied in later phase of software development. Majority of the approaches available in literature for fault prediction are based on regression analysis and neural network techniques. It is observed that numerous software metrics are also being used as input for fault prediction. In this paper, a cost evaluation model has been proposed for Object-Oriented software which performs cost based analysis for misclassification of faults. Appropriately, this work focuses on inspecting the usability of fault prediction. Chidamber and Kemerer (CK) metrics suite has been considered to provide requisite input data to design the model using logistic regression and hybrid approach of Neural network and Particle Swarm Optimization (Neuro-PSO and Modified Neuro-PSO). Here, fault considered as dependent variable and CK metric suite are as independent variables. A case study of Eclipse JDT core has been considered for predicting a comparative study of performances of two approaches. Fault prediction is found to be useful where normalized estimated fault removal cost (NEcost) was less than certain threshold value. Modified Neuro-PSO model obtained promising results in terms of cost analysis when compared with those of Neuro-Psoand logistic regression."
pub.1084979189,Effective fault prediction model developed using Least Square Support Vector Machine (LSSVM)," Software developers and project teams spend considerable amount of time in identifying and fixing faults reported by testers and users. Predicting defects and identifying regions in the source code containing faults before it is discovered or invoked by users can be valuable in terms of saving maintenance resources, user satisfaction and preventing major system failures post deployment. Fault prediction can also improve the effectiveness of software quality assurance activities by guiding the test team to focus efforts on fault prone components. The work presented in this paper involves building an effective fault prediction tool by identifying and investigating the predictive power of several well-known and widely used software metrics for fault prediction. We apply ten different feature selection techniques to choose the best set of metrics from a set of twenty source code metrics. We build the fault prediction model using Least Squares Support Vector Machine (LSSVM) learning method associated with linear, polynomial and radial basis function kernel functions. We perform experiments on 30 Open Source Java projects. Experimental results reveals that our prediction model is best suitable for projects with faulty classes less than the threshold value depending on fault identification efficiency (low- 52.139%, median- 46.206%, and high- 32.080%)."
pub.1147342387,Use of Support Vector Machine to Check Whether Process Metrics are as Good as Static Code Metrics,"There can be some faults, while the development of the software. If these faults are not recognized and corrected at any early stage of software development, then it leads to software failure and increase in development cost. So, the most important task is to deal with these software faults. Various models have been proposed to detect the fault proneness of the software using static code metrics. In this paper, we have used support vector machine with poly-kernel and normalized poly-kernel to predict the fault proneness, and both static code metrics and process metrics have been used as independent variables. AUC measure is used as performance evaluation measure to predict the fault proneness. We have also analyzed the results using 3D bar graph and Friedman test. The result of this study shows that in case of both kernels, process metric has positive impact on predicting fault proneness, or we can say that process metric is as good as static code metrics."
pub.1095056147,Fault Tree Based Prediction of Software Systems Safety,"In our modern world, software controls much of the hardware (equipment, electronics, and instruments) around us. Sometimes hardware failure can lead to a loss of human life. When software controls, operates, or interacts with such hardware, software safety becomes a vital concern. To assure the safety of software controlling system, Prediction of software safety should be done at the beginning of system's design. The paper focused on safety prediction using the key node property of fault trees. This metric use parameter “s” related to the fault tree to predict the safety of the software control systems. This metric allow designers to measure and the safety of software systems early in the design process. An applied example is shown in the paper."
pub.1094864932,Token Based Approach for Cross Project Prediction of Fault Prone Modules,"A fault in a module may cause failure of the system. Faults pose a great challenge for the testing and maintenance phase. Fault prediction is of utmost importance to reduce the costs involved in the software development life cycle. Most of the studies use past history of the projects for predicting fault prone modules. Not much higher results are recorded in case of cross project prediction. In this paper, researcher tries to explain the various metrics and classification techniques used for fault prediction. It also describes a list of metrics to improve the results for cross project prediction. Further, an integrated approach is proposed which uses a metric computed from tokens along with the conventional metrics."
pub.1154850757,Piecewise Congruence Regressed Indexive Extreme Learning classifier for Software Fault Prediction,"<p>Early detection of software faults is significant task in the software development process. With the development of defect prediction technology, software with defects negatively impacts on operational costs and finally affects client satisfaction. Therefore, early defect prediction by the project managers is critical and challenging task. Different approaches were developed to predict software faults. However two essential factors are major issues such as timely and accurate detection. Therefore, a novel technique is required for accurate and timely software fault production. In this paper, a Piecewise Congruence Regressed Indexive Extreme Learning Classifier (PRILEC) is introduced for accurate software fault prediction with minimum time. The PRILEC technique consists of two major processes namely feature selection or software metric selection from the input dataset and the classification. In the first process, feature selection or software metric selection process is carried out by using congruence correlative piecewise regression. First, the numbers of features or metrics are collected from the dataset. Then the correlation between the features is measured using congruence coefficient and identifies the more relevant features. With the selected features, the classification is performed by applying statistical indexive levenberg extreme learning classifier for fault prediction with higher accuracy. In the extreme learning classifier, the testing and raining data analysis is performed with the help of Camargo's statistical index. Then the Hardlimit activation function is applied to identify the defective or non-defective software code. Finally, the Levenberg–Marquardt algorithm is applied to minimize the least square problem and obtain the final better classification results at output layer. In this way, software fault prediction is carried out with higher accuracy and minimum time. Experimental assessment of the proposed technique is carried out with respect to fault prediction accuracy, precision, recall, F-measure, prediction, specificity and time complexity with a different number of data. The quantitatively discussed results indicate that the performance of proposed technique increases data accuracy of software fault prediction with a higher minimum time as well as space complexity than the conventional method.</p>"
pub.1155202945,Machine Learning Based Approach for Predicting Fault in Software Engineering by GMFPA: A Survey,"Fault propensity of software is the prospect that the component contains faults. To forecast fault proneness of modules different techniques have been proposed which includes statistical methods, machine learning techniques, etc. Machine learning techniques can be used to analyze data from different perspectives and enable developers to retrieve useful information. Machine learning techniques are proven to be useful in terms of software bug prediction. This is leading to increase in development of machine learning methods for exploring data sets, which can be used in constructing models for predicting quality attributes such as fault proneness. This research work analyzed various fault prediction techniques and proposed a new algorithm GMFPA (Genetic Metric Fault Prediction Algorithm) to explore the fault prone modules by using metrics. The GMFPA is used to identify fault with highest gain value by forming the hypothesis set."
pub.1164762915,Improved Software Fault Prediction Model Based on Optimal Features Set and Threshold Values Using Metaheuristic Approach,"Software fault prediction models are very important to prioritize software classes for effective testing and efficient use of resources so that the testing process’s time, effort, and cost can be reduced. Fault prediction models can be based on either metrics’ threshold values or machine learning. Code metrics’ threshold-based models are easy to automate and faster than machine learning-based models, which can save significant time in the testing process. ROC, Alves ranking, and VARL are famous threshold value calculation techniques. Out of which ROC is the best threshold calculation technique. This research article proposes a new threshold values calculation technique based on metaheuristics. A genetic algorithm and particle swarm optimizer are used to calculate the threshold values, and the proposed technique is tested on ten open-source object-oriented software datasets and four open-source procedural software datasets. Results show that the metaheuristic-based thresholds give better results than ROC-based thresholds."
pub.1118785672,Using Source Code Metrics and Ensemble Methods for Fault Proneness Prediction,"Software fault prediction model are employed to optimize testing resource
allocation by identifying fault-prone classes before testing phases. Several
researchers' have validated the use of different classification techniques to
develop predictive models for fault prediction. The performance of the
statistical models are proven to be influenced by the training and testing
dataset. Ensemble method learning algorithms have been widely used because it
combines the capabilities of its constituent models towards a dataset to come
up with a potentially higher performance as compared to individual models
(improves generalizability). In the study presented in this paper, three
different ensemble methods have been applied to develop a model for predicting
fault proneness. The efficacy and usefulness of a fault prediction model also
depends on the source code metrics which are considered as the input for the
model.
  In this paper, we propose a framework to validate the source code metrics and
select the right set of metrics with the objective to improve the performance
of the fault prediction model. The fault prediction models are then validated
using a cost evaluation framework. We conduct a series of experiments on 45
open source project dataset. Key conclusions from our experiments are: (1)
Majority Voting Ensemble (MVE) methods outperformed other methods; (2) selected
set of source code metrics using the suggested source code metrics using
validation framework as the input achieves better results compared to all other
metrics; (3) fault prediction method is effective for software projects with a
percentage of faulty classes lower than the threshold value (low - 54.82%,
medium - 41.04%, high - 28.10%)"
pub.1121961746,An Overview of Quality Metrics Used in Estimating Software Faults,"Software reliability is highly affected by software quality attributes and measurements. Faults, bugs, and errors are shown not only in the development process but also in end-user period hereby it is required to detect these issues earlier. These are detected by software quality and object-oriented metrics which are commonly used in the fault detection process. CK, MOOD and QMOOD metrics are the most common metrics applied in this area. In this paper is to aim to provide information about popular software quality metrics and their usage in terms of software fault prediction studies. For this purpose, in this work, these three metrics were analyzed separately and their acquisition methods were showed. Moreover, in order for the software to survive with errors, to remove and minimize errors, a number of recommendations are presented in the conclusion section."
pub.1144966921,Heterogeneous Fault Prediction Using Feature Selection and Supervised Learning Algorithms,"Software Fault Prediction (SFP) is the most persuasive research area of software engineering. Software Fault Prediction which is carried out within the same software project is known as With-In Fault Prediction. However, local data repositories are not enough to build the model of With-in software Fault prediction. The idea of cross-project fault prediction (CPFP) has been suggested in recent years, which aims to construct a prediction model on one project, and use that model to predict the other project. However, CPFP requires that both the training and testing datasets use the same set of metrics. As a consequence, traditional CPFP approaches are challenging to implement through projects with diverse metric sets. The specific case of CPFP is Heterogeneous Fault Prediction (HFP), which allows the program to predict faults among projects with diverse metrics. The proposed framework aims to achieve an HFP model by implementing Feature Selection on both the source and target datasets to build an efficient prediction model using supervised machine learning techniques. Our approach is applied on two open-source projects, Linux and MySQL, and prediction is evaluated based on Area Under Curve (AUC) performance measure. The key results of the proposed approach are as follows: It significantly gives better results of prediction performance for heterogeneous projects as compared with cross projects. Also, it demonstrates that feature selection with feature mapping has a significant effect on HFP models. Non-parametric statistical analyses, such as the Friedman and Nemenyi Post-hoc Tests, are applied, demonstrating that Logistic Regression performed significantly better than other supervised learning algorithms in HFP models."
pub.1094390886,Emperical Study of Defects Dependency on Software Metrics Using Clustering Approach,"Defect Prediction prior to the release of software uses metrics and fault data to know which properties of software are associated with faults in classes. In this paper, predication of software defects have been performed with the help of static code metrics. The proposed approach analyzed by multiple regression technique. Initially all the collected metrics are grouped in similar category using the K-means clustering approach results in more similar metric are in one cluster. The clustering performed based on structural information provided by collected data sets. In next step, empirically the impact of defect count metric on different clusters has been identify using regression approach. Finally the regression results shows prediction rate for defect count by each cluster. The result conclude the prediction model developed on clustering totally outperform those models that use only static metrics."
pub.1093431271,Application of Genetic Algorithm as Feature Selection Technique in Development of Effective Fault Prediction Model,"Prediction of faults in a proposed software is helpful in deciding the amount of effort to be given for software development. We observed that, a good number of authors hypothesized that the performance of fault prediction model depends on the source code metrics which are used as input of the model. Feature selection technique is a process of selecting suitable set of source code metrics which may improve the performance of fault prediction model. In this work, genetic algorithm (GA) has been applied as feature selection technique to select the suitable set of source code metrics. This selected set of source code metrics are used as requisite input data to develop a classifier using five different classification techniques such as logistic regression, extreme learning machine, support vector machine (SVM) with three different kernel functions (linear, polynomial, and radial basis kernel functions) in order to predict the faulty and non-faulty classes. In this study, we propose a cost evaluation framework to perform cost based analysis for evaluating the effectiveness of fault prediction model. We perform experiments on thirty number of Java Open Source projects. From the obtained results, it is observed that the model developed using selected set of source code metrics obtained better result as compared to all metrics. From costs analysis framework, it is observed that the developed fault prediction model is best suitable for software with % of faulty classes less than the threshold value depending on fault identification efficiency (low- 46.44%, median- 45.37%, and high- 36.63%)."
pub.1009478335,Application of multivariate analysis for software fault prediction,"Prediction of fault-prone modules provides one way to support software quality engineering through improved scheduling and project control. The primary goal of our research was to develop and refine techniques for early prediction of fault-prone modules. The objective of this paper is to review and improve an approach previously examined in the literature for building prediction models, i.e. principal component analysis (PCA) and discriminant analysis (DA). We present findings of an empirical study at Ericsson Telecom AB for which the previous approach was found inadequate for predicting the most fault-prone modules using software design metrics. Instead of dividing modules into fault-prone and not-fault-prone, modules are categorized into several groups according to the ordered number of faults. It is shown that the first discriminant coordinates (DC) statistically increase with the ordering of modules, thus improving prediction and prioritization efforts. The authors also experienced problems with the smoothing parameter as used previously for DA. To correct this problem and further improve predictability, separate estimation of the smoothing parameter is shown to be required."
pub.1061405707,Analyzing software measurement data with clustering techniques,"For software quality estimation, software development practitioners typically construct quality-classification or fault prediction models using software metrics and fault data from a previous system release or a similar software project. Engineers then use these models to predict the fault proneness of software modules in development. Software quality estimation using supervised-learning approaches is difficult without software fault measurement data from similar projects or earlier system releases. Cluster analysis with expert input is a viable unsupervised-learning solution for predicting software modules' fault proneness and potential noisy modules. Data analysts and software engineering experts can collaborate more closely to construct and collect more informative software metrics."
pub.1121402221,A Hybrid Feature Selection Method for Software Fault Prediction,"Fault prediction aims to identify whether a software module is defect-prone or not according to metrics that are mined from software projects. These metric values, also known as features, may involve irrelevance and redundancy, which hurt the performance of fault prediction models. In order to filter out irrelevant and redundant features, a Hybrid Feature Selection (abbreviated as HFS) method for software fault prediction is proposed. The proposed HFS method consists of two major stages. First, HFS groups features with hierarchical agglomerative clustering; second, HFS selects the most valuable features from each cluster to remove irrelevant and redundant ones based on two wrapper based strategies. The empirical evaluation was conducted on 11 widely-studied NASA projects, using three different classifiers with four performance metrics (precision, recall, F-measure, and AUC). Comparison with six filter-based feature selection methods demonstrates that HFS achieves higher average F-measure and AUC values. Compared with two classic wrapper feature selection methods, HFS can obtain a competitive prediction performance in terms of average AUC while significantly reducing the computation cost of the wrapper process."
pub.1091238720,Applicability of Soft Computing and Optimization Algorithms in Software Testing and Metrics – A Brief Review,"In spite of many years of work by scientists and specialists on various software qualities, testing stays one of the most broadly honed and concentrated on methodologies for evaluating and improving software quality. Our objective, in this paper, is to present how optimization techniques provide solutions to different and difficult issues in different areas of software engineering. Optimization algorithms are mathematical procedures, which intends to best optimal results for the defect, fault, failure to accomplish tractability, strength, and low arrangement cost. In this paper, a comprehensive overview of software testing and metrics based on soft computing and optimization techniques is presented. In this survey, we try to explain some major problems like defect prediction, software fault prediction and their solutions by soft computing and optimization algorithms. The paper presents an overview of the usage of Mathematical optimization Algorithms and soft computing approaches."
pub.1094468337,A Density Based Clustering Approach for Early Detection Of Fault Prone Modules,"Quality of a software component can be measured in terms of fault proneness of data. Quality estimations are made using fault proneness data available from previously developed similar type of projects and the training data consisting of software measurements. To predict fault-proneness of modules different techniques have been proposed which includes statistical methods, machine learning techniques, neural network techniques and clustering techniques. The aim of proposed approach is to investigate that whether metrics available in the early lifecycle (i.e. requirement metrics), metrics available in the late lifecycle (i.e. code metrics) and metrics available in the early lifecycle (i.e. requirement metrics) combined with metrics available in the late lifecycle (i.e. code metrics) can be used to identify fault prone modules by using Density Based Clustering technique. This approach has been tested with real time defect datasets of NASA software projects named as PC1. Predicting faults early in the software life cycle can be used to achieve high software quality. The results show that the fusion of requirement and code metric is the best prediction model for detecting the faults as compared with mostly used code based model."
pub.1028859922,How to measure success of fault prediction models,"Many fault prediction models have been proposed in the software engineering literature, and their success evaluated according to various metrics that are widely used in the statistics community. To be able to make meaningful comparisons among the proposed models, it is important that the metrics assess meaningful properties of the predictions. We examine several of the more common metrics, discuss the advantages and disadvantages of each, and illustrate their application to predictions made on a large industrial system. We conclude that the most useful metrics are the percentage of faults that occur in the predicted most fault-prone files, and the Type II misclassification rate."
pub.1095260649,On Error-Class Distribution in Automotive Model-Based Software,"Software fault prediction promises to be a powerful tool in supporting test engineers upon their decision where to define testing hotspots. However, there are limitations on a cross project prediction and a lack of reports upon application to industrial software, as well as the power of metrics to represent bugs. In this paper, we present a novel analysis based upon faults discovered in model-based automotive software projects and their relationship to metrics used to perform fault prediction. Using our previously released dataset on software metrics, we report bug classes discovered during heavy testing of those automotive software. As the software has been developed following strict coding and development guidelines, we present the results based on a comparison between the discovered error classes and those which might derive a reduced potential error set. Using the three projects from our dataset we determine if any of these bug classes are project specific."
pub.1101636399,A dimensionality reduction-based efficient software fault prediction using Fisher linear discriminant analysis (FLDA),"Software quality is an important factor in the success of software companies. Traditional software quality assurance techniques face some serious limitations especially in terms of time and budget. This leads to increase in the use of machine learning classification techniques to predict software faults. Software fault prediction can help developers to uncover software problems in early stages of software life cycle. The extent to which these techniques can be generalized to different sizes of software, class imbalance problem, and identification of discriminative software metrics are the most critical challenges. In this paper, we have analyzed the performance of nine widely used machine learning classifiers—Bayes Net, NB, artificial neural network, support vector machines, K nearest neighbors, AdaBoost, Bagging, Zero R, and Random Forest for software fault prediction. Two standard sampling techniques—SMOTE and Resample with substitution are used to handle the class imbalance problem. We further used FLDA-based feature selection approach in combination with SMOTE and Resample to select most discriminative metrics. Then the top four classifiers based on performance are used for software fault prediction. The experimentation is carried out over 15 publically available datasets (small, medium and large) which are collected from PROMISE repository. The proposed Resample-FLDA method gives better performance as compared to existing methods in terms of precision, recall, f-measure and area under the curve."
pub.1117956441,Adapting God Class thresholds for software defect prediction: A case study,"In software engineering there is an active research field of defect prediction using software metrics. While the research shows that the prediction of defects using software metrics performs well, prediction using metrics alone lacks clear refactoring capabilities. On the other hand, code smells have the ability to describe the code anomalies precisely, and suggest their refactoring. Therefore, code smells can be a much better starting position for software fault prediction. In this paper, we present the results of preliminary research on the ability to predict software defects with the code smell God Class. The aim of our research was to test the definition of God Class, as defined by Lanza and Marinescu in 2006, in the ability to predict defects in a case study of the open source projects JDT and PDE within the Eclipse framework. The definition of the God Class was adapted using the grid search technique, with the goal of maximizing the fault prediction ability while keeping the base of the original definition. The results show that adaption of the definition in the specific project resulted in improved fault prediction ability."
pub.1175136824,Piecewise Congruence Regressed Indexive Extreme Learning Classifier for Software Fault Prediction,"Software fault prediction is a significant task in software development to discover faults early. It is the process of developing models that can be used by the software practitioners in the early phases of software development life cycle for detecting faulty constructs such as modules or classes. Therefore, early fault prediction is a critical and challenging task faced by the Project managers. Several kinds of approaches were utilized to predict software faults. In this work we propose a Piecewise Congruence Regressed Indexive Extreme Learning Classifier (PRILEC) to predict the software faults accurately. The process consists of two stages namely feature selection or software metric selection and classification. In feature selection process, congruence correlative piecewise regression method is utilized to extract the most relevant features from the given input dataset. In the next phase, statistical indexive levenberg extreme learning classifier is utilized to classify the fault prediction with better accuracy. The testing and training data analysis in extreme learning classifiers is evaluated using Camargo’s statistical index. Hardlimit activation function is utilized to identify the faulty or non-faulty software code. The least square problem can be minimized using Levenberg-Marquardt algorithm and this algorithm can obtain the better classification results. The performance of the proposed approach is evaluated using software fault prediction data analysis dataset. The evaluation metrics such as precision, recall, F-measure, and specificity were used to assess the performance of the proposed algorithm. It was observed that compared with the state-of-the-art traditional methods (Linear regression), proposed technique increases data accuracy of software fault prediction. The system reduces the fault detection time by 4%, 2%, 2%, 2%, 29% and 21% respectively."
pub.1094888151,Application of Neural Network for Predicting Software Developement Faults Using Object-Oriented Design Metrics,"In this paper, we present the application of neural network for predicting software development faults including object-oriented faults. Object-oriented metrics can be used in quality estimation. In practice, quality estimation means either estimating reliability or maintainability. In the context of object-oriented metrics work, reliability is typically measured as the number of defects. Object‐ oriented design metrics are used as the independent variables and the number of faults is used as dependent variable in our study. Software metrics used include those concerning inheritance measures, complexity measures, coupling measures and object memory allocation measures. We also test the goodness of fit of neural network model by comparing the prediction result for software faults with multiple regression model. Our study is conducted on three industrial real - time systems that contain a number of natural faults that has been reported for three years [1]."
pub.1118448223,State-Of-The-Art In Empirical Validation Of Software Metrics For Fault Proneness Prediction: Systematic Review,"With the sharp rise in software dependability and failure cost, high quality
has been in great demand. However, guaranteeing high quality in software
systems which have grown in size and complexity coupled with the constraints
imposed on their development has become increasingly difficult, time and
resource consuming activity. Consequently, it becomes inevitable to deliver
software that have no serious faults. In this case, object-oriented (OO)
products being the de facto standard of software development with their unique
features could have some faults that are hard to find or pinpoint the impacts
of changes. The earlier faults are identified, found and fixed, the lesser the
costs and the higher the quality. To assess product quality, software metrics
are used. Many OO metrics have been proposed and developed. Furthermore, many
empirical studies have validated metrics and class fault proneness (FP)
relationship. The challenge is which metrics are related to class FP and what
activities are performed. Therefore, this study bring together the
state-of-the-art in fault prediction of FP that utilizes CK and size metrics.
We conducted a systematic literature review over relevant published empirical
validation articles. The results obtained are analysed and presented. It
indicates that 29 relevant empirical studies exist and measures such as
complexity, coupling and size were found to be strongly related to FP."
pub.1131156376,Deep Learning for Software Defect Prediction,"Software fault prediction is an important and beneficial practice for improving software quality and reliability. The ability to predict which components in a large software system are most likely to contain the largest numbers of faults in the next release helps to better manage projects, including early estimation of possible release delays, and affordably guide corrective actions to improve the quality of the software. However, developing robust fault prediction models is a challenging task and many techniques have been proposed in the literature. Traditional software fault prediction studies mainly focus on manually designing features (e.g. complexity metrics), which are input into machine learning classifiers to identify defective code. However, these features often fail to capture the semantic and structural information of programs. Such information is needed for building accurate fault prediction models. In this survey, we discuss various approaches in fault prediction, also explaining how in recent studies deep learning algorithms for fault prediction help to bridge the gap between programs' semantics and fault prediction features and make accurate predictions."
pub.1094482562,Predictive modeling of software quality for very large telecommunications systems,"Society's reliance on large complex telecommunications systems mandates high reliability. Controlling faults in software requires that one can predict problems early enough to take preventive action. Software metrics are the basis for such predictions, and thus, many organization are collecting volumes of software metric data. Collecting software metrics is not enough. One must translate measurements into predictions. This study systematically presents a methodology for developing models that predict software quality factors. The individual details of this methodology may be familiar, but the whole modeling process must be integrated to produce successful predictions of software quality. We use two example studies to illustrate each step. One predicted the number of faults to be discovered in each module, and the other predicted whether each module would be considered fault-prone. The examples were based on the same data set, consisting of a sample from a very large telecommunications system. The sample of modules represented about 1.3 million lines of code."
pub.1151523109,"A machine and deep learning analysis among SonarQube rules, product, and process metrics for fault prediction","BackgroundDevelopers spend more time fixing bugs refactoring the code to increase the maintainability than developing new features. Researchers investigated the code quality impact on fault-proneness, focusing on code smells and code metrics.ObjectiveWe aim at advancing fault-inducing commit prediction using different variables, such as SonarQube rules, product, process metrics, and adopting different techniques.MethodWe designed and conducted an empirical study among 29 Java projects analyzed with SonarQube and SZZ algorithm to identify fault-inducing and fault-fixing commits, computing different product and process metrics. Moreover, we investigated fault-proneness using different Machine and Deep Learning models.ResultsWe analyzed 58,125 commits containing 33,865 faults and infected by more than 174 SonarQube rules violated 1.8M times, on which 48 software product and process metrics were calculated. Results clearly identified a set of features that provided a highly accurate fault prediction (more than 95% AUC). Regarding the performance of the classifiers, Deep Learning provided a higher accuracy compared with Machine Learning models.ConclusionFuture works might investigate whether other static analysis tools, such as FindBugs or Checkstyle, can provide similar or different results. Moreover, researchers might consider the adoption of time series analysis and anomaly detection techniques."
pub.1031601770,An empirical study of predicting software faults with case-based reasoning,"The resources allocated for software quality assurance and improvement have not increased with the ever-increasing need for better software quality. A targeted software quality inspection can detect faulty modules and reduce the number of faults occurring during operations. We present a software fault prediction modeling approach with case-based reasoning (CBR), a part of the computational intelligence field focusing on automated reasoning processes. A CBR system functions as a software fault prediction model by quantifying, for a module under development, the expected number of faults based on similar modules that were previously developed. Such a system is composed of a similarity function, the number of nearest neighbor cases used for fault prediction, and a solution algorithm. The selection of a particular similarity function and solution algorithm may affect the performance accuracy of a CBR-based software fault prediction system. This paper presents an empirical study investigating the effects of using three different similarity functions and two different solution algorithms on the prediction accuracy of our CBR system. The influence of varying the number of nearest neighbor cases on the performance accuracy is also explored. Moreover, the benefits of using metric-selection procedures for our CBR system is also evaluated. Case studies of a large legacy telecommunications system are used for our analysis. It is observed that the CBR system using the Mahalanobis distance similarity function and the inverse distance weighted solution algorithm yielded the best fault prediction. In addition, the CBR models have better performance than models based on multiple linear regression."
pub.1141855929,Early Stage Fault Prediction via Inter-Project Rule Transfer,"Software fault protection can be first achieved by fault prediction. The earlier the fault prediction can be done in the software development life-cycle, the lower the damage and repair costs caused by the defects that will occur. Machine learning is one well-known method for the decision-making part of automatic software fault prediction. However, the applicability of machine learning methods is low due to the lack of data in the early stages of development processes. In this study, the data needed in the design of rule-base was obtained from counterpart projects, and the fault prediction problem was evaluated by the fuzzy rule-based systems’ point of view since these systems have portability utility which allows rule transfer between different problems with similar goals in the same domain. Briefly, this study aims to show that early-stage fault prediction is possible with the portability characteristics of fuzzy systems sourced from the inter-project rule transfer. Several experiments have been performed by using the software metrics datasets of 5 software projects to support this idea. Fuzzy systems obtained from several combinations of these datasets were evaluated by their prediction accuracy. The results show that more accurate rules can be obtained from previously completed software projects, and the use of rule bases gathered from those projects’ software metrics repositories can be transfered to predict the faulty modules of the current software project."
pub.1013171326,A technique for early prediction of software reliability based on design metrics,"In the early stages of development, it is difficult to quantitatively assess the reliability of a software product. In this context, we propose a bottom-up approach to predict the reliability of an object-oriented software from its product metrics gathered during the architectural design stage. A fault model is constructed to categorize different kinds of faults that can occur in the components making up the software product. Subsequently, the product metrics collected during the software design phase are used to estimate the expected number of different kinds of faults that may occur in a component. Eventually, these estimated values of the different kinds of faults are used to predict the expected values of the total number of faults present in the component. We use the estimated fault content of the component and the number of tests that will be performed over the component, to predict reliability of the component. We adopt a probabilistic approach, Bayesian Belief Network, for reliability prediction of the components from product metrics. Based on predicted reliabilities and usage frequencies of the components, the reliability of a system is predicted. The applicability of our proposed model is illustrated through a case study. Moreover, we performed a set of experiments and also compared our approach with an established approach reported in the literature to investigate the accuracy of our approach. Analysis of the results from our experiments suggests that our approach yields reasonably accurate result."
pub.1094331849,Using Software Metrics Thresholds to Predict Fault-Prone Classes in Object-Oriented Software,"Most code-based quality measurement approaches are based, at least partially, on values of multiple source code metrics. A class will often be classified as being of poor quality if the values of its metrics are above given thresholds, which are different from one metric to another. The metrics thresholds are calculated using various techniques. In this paper, we investigated two specific techniques: ROC curves and Alves rankings. These techniques are supposed to give metrics thresholds which are practical for code quality measurements or even for fault-proneness prediction. However, Alves Rankings technique has not been validated as being a good choice for fault-proneness prediction, and ROC curves only partially on few datasets. Fault-proneness prediction is an important field of software engineering, as it can be used by developers and testers as a test effort indication to prioritize tests. This will allow a better allocation of resources, reducing therefore testing time and costs, and an improvement of the effectiveness of testing by testing more intensively the components that are likely more fault-prone. In this paper, we wanted to compare empirically the selected threshold calculation methods used as part of fault-proneness prediction techniques. We also used a machine learning technique (Bayes Network) as a baseline for comparison. Thresholds have been calculated for different object-oriented metrics using four different datasets obtained from the PROMISE Repository and another one based on the Eclipse project."
pub.1094337253,Class level fault prediction using software clustering,"Defect prediction approaches use software metrics and fault data to learn which software properties associate with faults in classes. Existing techniques predict fault-prone classes in the same release (intra) or in a subsequent releases (inter) of a subject software system. We propose an intra-release fault prediction technique, which learns from clusters of related classes, rather than from the entire system. Classes are clustered using structural information and fault prediction models are built using the properties of the classes in each cluster. We present an empirical investigation on data from 29 releases of eight open source software systems from the PROMISE repository, with predictors built using multivariate linear regression. The results indicate that the prediction models built on clusters outperform those built on all the classes of the system."
pub.1094076507,Efficient Prediction of Software Fault Proneness Modules Using Support Vector Machines and Probabilistic Neural Networks,"A software fault is a defect that causes software failure in an executable product. Fault prediction models usually aim to predict either the probability or the density of faults that the code units contain. Many fault prediction models using software metrics have been proposed in the Software Engineering literature. This study focuses on evaluating high-performance fault predictors based on support vector machines (SVMs) and probabilistic neural networks (PNNs). Five public NASA datasets from the PROMISE repository are used to make these predictive models repeatable, refutable, and verifiable. According to the obtained results, the probabilistic neural networks generally provide the best prediction performance for most of the datasets in terms of the accuracy rate."
pub.1094360116,Predicting Fault-Prone Classes in Object-Oriented Software: An Adaptation of an Unsupervised Hybrid SOM Algorithm,"Many fault-proneness prediction models have been proposed in literature to identify fault-prone code in software systems. Most of the approaches use fault data history and supervised learning algorithms to build these models. However, since fault data history is not always available, some approaches also suggest using semi-supervised or unsupervised fault-proneness prediction models. The HySOM model, proposed in literature, uses function-level source code metrics to predict fault-prone functions in software systems, without using any fault data. In this paper, we adapt the HySOM approach for object-oriented software systems to predict fault-prone code at class-level granularity using object-oriented source code metrics. This adaptation makes it easier to prioritize the efforts of the testing team as unit tests are often written for classes in object-oriented software systems, and not for methods. Our adaptation also generalizes one main element of the HySOM model, which is the calculation of the source code metrics threshold values. We conducted an empirical study using 12 public datasets. Results show that the adaptation of the HySOM model for class-level fault-proneness prediction improves the consistency and the performance of the model. We additionally compared the performance of the adapted model to supervised approaches based on the Naive Bayes Network, ANN and Random Forest algorithms."
pub.1110114459,Majority vote feature selection algorithm in software fault prediction,"Identification and location of defects in software projects is an important task to improve software quality and to reduce software test effort estimation cost. In software fault prediction domain, it is known that 20% of the modules will in general contain about 80% of the faults. In order to minimize cost and effort, it is considerably important to identify those most error prone modules precisely and correct them in time. Machine Learning (ML) algorithms are frequently used to locate error prone modules automatically. Furthermore, the performance of the algorithms is closely related to determine the most valuable software metrics. The aim of this research is to develop a Majority Vote based Feature Selection algorithm (MVFS) to identify the most valuable software metrics. The core idea of the method is to identify the most influential software metrics with the collaboration of various feature rankers. To test the efficiency of the proposed method, we used CM1, JM1, KC1, PC1, Eclipse Equinox, Eclipse JDT datasets and J48, NB, K-NN (IBk) ML algorithms. The experiments show that the proposed method is able to find out the most significant software metrics that enhances defect prediction performance.
nema"
pub.1094889188,Process Metrics are Not Bad Predictors of Fault Proneness,"The correct prediction of faulty modules or classes has a number of advantages such as improving the quality of software and assigning capable development resources to fix such faults. There have been different kinds of fault/defect prediction models proposed in literature, but a great majority of them makes use of static code metrics as independent variables for making predictions. Recently, process metrics have gained a considerable attention as alternative metrics to use for making trust-worthy predictions. The objective of this paper is to investigate different combinations of static code and process metrics for evaluating fault prediction performance. We have used publicly available data sets, along with a frequently used classifier, Naïve Bayes, to run our experiments. We have, both statistically and visually, analyzed our experimental results. The statistical analysis showed evidence against any significant difference in fault prediction performances for a variety of different combinations of metrics. This reinforced earlier research results that process metrics are as good as predictors of fault proneness as static code metrics. Furthermore, the visual inspection of box plots revealed that the best set of metrics for fault prediction is a mix of both static code and process metrics. We also presented evidence in support of some process metrics being more discriminating than others and thus making them as good predictors to use."
pub.1169896032,A Systematic Review of Software Fault Prediction Using Deep Learning: Challenges and Future Perspectives,"The accurate prediction of software faults is crucial in guaranteeing the quality and reliability of software systems. Recent research has highlighted the vast potential of various deep learning models, including convolutional neural networks (CNNs), recurrent neural networks (RNNs), long short-term memory (LSTM) networks, autoencoders, deep belief networks (DBNs), and generative adversarial networks (GANs), in achieving this objective. In this extensive review, we have thoroughly examined the performance metrics and scalability of these models for software fault prediction, as well as their respective architectures. Additionally, we have evaluated frequently used datasets, such as NASA MDP and PROMISE, and addressed challenges such as insufficient data and model interpretability. Our analysis has revealed that the ANN-PSO and LSTM models are particularly effective in predicting software faults. Therefore, we recommend that future research prioritize enhancing software fault prediction using deep learning techniques."
pub.1123525069,Machine Learning Based Prediction of Complex Bugs in Source Code,"During software development and maintenance phases, the fixing of severe bugs are mostly very challenging and needs more efforts to fix them on a priority basis. Several research works have been performed using software metrics and predict fault-prone software module. In this paper, we propose an approach to categorize different types of bugs according to their severity and priority basis and then use them to label software metrics’ data. Finally, we used labeled data to train the supervised machine learning models for the prediction of fault prone software modules. Moreover, to build an effective prediction model, we used genetic algorithm to search those sets of metrics which are highly correlated with severe bugs."
pub.1093549534,Estimating Software Quality with Advanced Data Mining Techniques,"Current software quality estimation models often involve the use of supervised learning methods for building a software fault prediction models. In such models, dependent variable usually represents a software quality measurement indicating the quality of a module by risk-basked class membership, or the number of faults. Independent variables include various software metrics as McCabe, Error Count, Halstead, Line of Code, etc... In this paper we present the use of advanced tool for data mining called Multimethod on the case of building software fault prediction model. Multimethod combines different aspects of supervised learning methods in dynamical environment and therefore can improve accuracy of generated prediction model. We demonstrate the use Multimethod tool on the real data from the Metrics Data Project Data (MDP) Repository. Our preliminary empirical results show promising potentials of this approach in predicting software quality in a software measurement and quality dataset."
pub.1144402180,A hybrid approach to software fault prediction using genetic programming and ensemble learning methods,"Software fault prediction techniques use previous software metrics and also use the fault data to predict fault-prone modules for the next release of software. In this article we review the literature that uses machine-learning techniques to find the defect, fault, ambiguous code, inappropriate branching and prospected runtime errors to establish a level of quality in software. This paper also proposes a hybrid technique for software fault prediction which is based on genetic programming and ensemble learning techniques. There are multiple software fault prediction (machine-learning) techniques available to predict the occurrence of faults. Our experiments perform a comparative study of the performance achieved by simple ensemble methods, simple genetic programming based classification and the hybrid approach. We find that machine learning techniques have different learning abilities that can be exploited by software professionals and researchers for software fault prediction. We find that the performance obtained by this proposed approach is superior to the simple statistical and ensemble techniques used in the automated fault prediction system. However, more studies should be performed on lesser used machine learning techniques."
pub.1129781820,Software Fault Prediction Using Cross-Validation,"Suresh, YeresimeSoftware faults are dangerous. Software systems are often essential to a business operation or organization, and failures in such systems cause disruption of some goal-directed activity (mission critical). Faults in safety-critical systems may result in death, loss of property, or environmental harm. Run-time faults are the most damaging as they are not always detectable during the testing process. Detecting faults before they occur gives the designers a brief inner view of the possible failure and their frequency of appearance. This helps in focused testing and saves time during the software development. Prediction models have the ability to differentiate between various patterns. This article showcases the effectiveness of cross-validation in design and development of a neural network for software fault detection."
pub.1110357416,Improving Software Fault Prediction With Threshold Values,"Software fault prediction has been studied by many researchers to assess the quality of software and to predict where faults may appear in future. However, the performance of fault prediction degrades because of many reasons including unlabeled instances or data imbalance, i.e., modules that contain faults are minority. The data imbalance is common in fault data where the majority of software modules are marked as non-faulty. However, part of these modules are still fault-prone but faults are uncovered yet. Threshold values are used to identify the modules that are complex and more fault prone. The fault prediction models are combined with the use of threshold values to improve the prediction performance. Fault prediction models are built in two phases. First, threshold values are used to spot the most fault prone modules. The modules that have metrics larger than thresholds and were fault free are classified as medium, while modules with faults are classified as high. Second, the new data are used to build prediction models using five machine learning models. Five classifiers were built for ten software systems. We have found improvements in the classification performance of all classifiers when compared with traditional classification."
pub.1122144577,"Identification of latent variables using, factor analysis and multiple linear regression for software fault prediction","Software practitioners develop models by considering the process of software fault prediction in the early stage of the software development life cycle in order to detect faulty modules. Various statistical and machine learning techniques are examined in the past for fault prediction. In this study, we have performed an empirical analysis of object-oriented (OO) metrics with a review of studies from the year 1996 to 2018 in the literature considering the statistical and machine learning techniques for software fault prediction. In this research, the concept of factor analysis and its sub-measures with regression are used to assess the capabilities for fault-proneness. The authors have also grouped the significant predictors i.e. CK and OO metrics using the factor analysis. In this paper, we have identified significant factor’s in five software’s datasets. The model is using the factor analysis with regression technique for estimating software fault-proneness. The results calculated prove the potential and capabilities of factor analysis for grouping important factors and using regression to identify the significant predictors. The experimental results obtained prove the ability of factor analysis with regression for predicting the susceptibility of software towards, the grouping of the components and effective use of the concept researchers and software practitioners. However, the significance and the application of the factor analysis with regression in software fault prediction are still limited and focus on these studies should be considered in order to generalize the results. On the basis of the results obtained, researchers are provided with future guidelines in this research work."
pub.1094692215,Analyzing the Effect of Bagged Ensemble Approach for Software Fault Prediction in Class Level and Package Level Metrics,"Faults in a module tend to cause failure of the software product. These defective modules in the software pose considerable risk by increasing the developing cost and decreasing the customer satisfaction. Hence in a software development life cycle it is very important to predict the faulty modules in the software product. Prediction of the defective modules should be done as early as possible so as to improve software developers' ability to identify the defect-prone modules and focus quality assurance activities such as testing and inspections on those defective modules. For quality assurance activity, it is important to concentrate on the software metrics. Software metrics play a vital role in measuring the quality of software. Many researchers focused on classification algorithm for predicting the software defect. On the other hand, classifiers ensemble can effectively improve classification performance when compared with a single classifier. This paper mainly addresses using ensemble approach of Support Vector Machine (SVM) for fault prediction. Ensemble classifier was examined for Eclipse Package level dataset and NASA KC1 dataset. We showed that proposed ensemble of Support Vector Machine is superior to individual approach for software fault prediction in terms of classification rate through Root Mean Square Error Rate (RMSE), AVC-ROC, ROC curves."
pub.1106438002,Software Fault Prediction Using Artificial Intelligence Techniques,"Detecting faults in the initial stage of the development process has become an important prospect for the codes cost estimation; so a fault predictor model is very much necessary in order to bring down the cost of development and maintenance. Due to these reasons, developing models for fault prediction has become a crucial part of research, and various techniques have been adapted in order to predict faults in a software. Few of them include Artificial Neural Network, Decision Tree, Genetic Algorithm, etc. Among these techniques, Neural Networks and Genetic Algorithms have become a growing concern over the years and are being applied in various fields such as optimization, prediction or classification. These techniques make use of various software metrics to assess the characteristic of any software system such as number of faults, maintenance of class, etc. Most commonly used are Chidamber and Kemerer (CK) metrics which are found to be efficient from many researches."
pub.1014977526,Iterative software fault prediction with a hybrid approach,"In this study, we consider a software fault prediction task that can assist a developer during the lifetime of a project. We aim to improve the performance of software fault prediction task while keeping it as applicable. Initial predictions are constructed by Fuzzy Inference Systems (FISs), whereas subsequent predictions are performed by data-driven methods. In this paper, an Artificial Neural Network and Adaptive Neuro Fuzzy Inference System are employed. We propose an iterative prediction model that begins with a FIS when no data are available for the software project and continues with a data-driven method when adequate data become available. To prove the usability of this iterative prediction approach, software fault prediction experiments are performed using expert knowledge for the initial version and information about previous versions for subsequent versions. The datasets employed in this paper comprise different versions of Ant, jEdit, Camel, Xalan, Log4j and Lucene projects from the PROMISE repository. The metrics of the models are common object-oriented metrics, such as coupling between objects, weighted methods per class and response for a class. The results of the models are evaluated according to the receiver operating characteristics with the area under the curve approach. The results indicate that the iterative software fault prediction is successful and can be transformed into a tool that can automatically locate fault-prone modules due to its well-organized information flow. We also implement the proposed methodology as a plugin for the Eclipse environment."
pub.1094804021,ImpactScale: Quantifying Change Impact to Predict Faults in Large Software Systems,"In software maintenance, both product metrics and process metrics are required to predict faults effectively. However, process metrics cannot be always collected in practical situations. To enable accurate fault prediction without process metrics, we define a new metric, ImpactScale. ImpactScale is the quantified value of change impact, and the change propagation model for ImpactScale is characterized by probabilistic propagation and relation-sensitive propagation. To evaluate ImpactScale, we predicted faults in two large enterprise systems using the effort-aware models and Poisson regression. The results showed that adding ImpactScale to existing product metrics increased the number of detected faults at 10% effort (LOC) by over 50%. ImpactScale also improved the predicting model using existing product metrics and dependency network measures."
pub.1049063895,The prediction of faulty classes using object-oriented design metrics,"Contemporary evidence suggests that most field faults in software applications are found in a small percentage of the software's components. This means that if these faulty software components can be detected early in the development project's life cycle, mitigating actions can be taken, such as a redesign. For object-oriented applications, prediction models using design metrics can be used to identify faulty classes early on. In this paper we report on a study that used object-oriented design metrics to construct such prediction models. The study used data collected from one version of a commercial Java application for constructing a prediction model. The model was then validated on a subsequent release of the same application. Our results indicate that the prediction model has a high accuracy. Furthermore, we found that an export coupling (EC) metric had the strongest association with fault-proneness, indicating a structural feature that may be symptomatic of a class with a high probability of latent faults."
pub.1127360881,A Better Set of Object-Oriented Design Metrics for Within-Project Defect Prediction,"Background: Using design metrics to predict fault-prone elements of a software design can help to focus attention on classes that need redesign and more extensive testing. However, some design metrics have been pointed out to be theoretically invalid, and the usefulness of some metrics is questioned. Aim: To identify a set of object-oriented metrics that are theoretically valid, and useful for identifying fault-prone classes in a design. Method: Drawing on four well-known sets of design metrics (CK, LK, MOOD and QMOOD), we propose a consolidated set of metrics that covers many aspects of object-oriented software design. We conduct two experiments, first using a single large system and then considering successive releases of that system, to compare the usefulness of the consolidated set with the other four sets for within-project prediction of fault-prone classes. Results: Both experiments suggest the consolidated set is effective at identifying fault-prone classes, outperforming the other metric sets (though at a cost of more false alarms). Conclusion: This paper adds to knowledge about the usefulness of existing sets of design metrics for within-project defect prediction, and identifies a consolidated set of metrics that is more effective than the existing sets at identifying fault-prone classes."
pub.1145548586,Examining the Predictive Capability of Advanced Software Fault Prediction Models – An Experimental Investigation Using Combination Metrics," Background: Fault prediction is a key problem in software engineering domain. In recent years, an increasing interest in exploiting machine learning techniques to make informed decisions to improve software quality based on available data has been observed.   Aim: The study aims to build and examine the predictive capability of advanced fault prediction models based on product and process metrics by using machine learning classifiers and ensemble design.   Method: Authors developed a methodological framework, consisting of three phases i.e., (i) metrics identification (ii) experimentation using base ML classifiers and ensemble design (iii) evaluating performance and cost sensitiveness. The study has been conducted on 32 projects from the PROMISE, BUG, and JIRA repositories.   Result: The results shows that advanced fault prediction models built using ensemble methods show an overall median of F-score ranging between 76.50% and 87.34% and the ROC(AUC) between 77.09% and 84.05% with better predictive capability and cost sensitiveness. Also, non-parametric tests have been applied to test the statistical significance of the classifiers.   Conclusion: The proposed advanced models have performed impressively well for inter project fault prediction for projects from PROMISE, BUG, and JIRA repositories. "
pub.1037300096,An Empirical Study on Fault Prediction using Token-Based Approach,"Since exhaustive testing is not possible, prediction of fault prone modules can be used for prioritizing the components of a software system. Various approaches have been proposed for the prediction of fault prone modules. Most of them uses module metrics as quality estimators. In this study, we proposed a tokenbased approach and combine the metric evaluated from our approach with the module metrics to further improve the prediction results. We conducted the experiment on an open source project for evaluating the approach. The proposed approach is further compared with the existing fault prone filtering technique. The results show that the proposed approach is an improvement over fault prone filtering technique."
pub.1008953383,Predicting Fault-Prone Modules by Word Occurrence in Identifiers,"Prediction of fault-prone modules is an important area of software engineering. We assumed that the occurrence of faults is related to the semantics in the source code modules. Semantics in a software module can be extracted from identifiers in the module. We then analyze the relationship between occurrence of “words” in identifiers and the existence of faults. To do so, we first decompose the identifiers into words, and investigate the occurrence of words in a module. Modeling by the random forest technique, we made a model of occurrence of words and existence of faults. We compared the word occurrence model with traditional models using CK metrics and LOC. The result of comparison showed that the occurrence of words is a good prediction measure as well as CK metrics and LOC."
pub.1136591567,Fault Prediction based on Software Metrics and SonarQube Rules. Machine or Deep Learning?,"Background. Developers spend more time fixing bugs and refactoring the code
to increase the maintainability than developing new features. Researchers
investigated the code quality impact on fault-proneness focusing on code smells
and code metrics. Objective. We aim at advancing fault-inducing commit
prediction based on SonarQube considering the contribution provided by each
rule and metric. Method. We designed and conducted a case study among 33 Java
projects analyzed with SonarQube and SZZ to identify fault-inducing and
fault-fixing commits. Moreover, we investigated fault-proneness of each
SonarQube rule and metric using Machine and Deep Learning models. Results. We
analyzed 77,932 commits that contain 40,890 faults and infected by more than
174 SonarQube rules violated 1,9M times, on which there was calculated 24
software metrics available by the tool. Compared to machine learning models,
deep learning provide a more accurate fault detection accuracy and allowed us
to accurately identify the fault-prediction power of each SonarQube rule. As a
result, fourteen of the 174 violated rules has an importance higher than 1\%
and account for 30\% of the total fault-proneness importance, while the fault
proneness of the remaining 165 rules is negligible. Conclusion. Future works
might consider the adoption of timeseries analysis and anomaly detection
techniques to better and more accurately detect the rules that impact
fault-proneness."
pub.1122004086,An approach for fault prediction in SOA-based systems using machine learning techniques," Purpose Software fault prediction is an important concept that can be applied at an early stage of the software life cycle. Effective prediction of faults may improve the reliability and testability of software systems. As service-oriented architecture (SOA)-based systems become more and more complex, the interaction between participating services increases frequently. The component services may generate enormous reports and fault information. Although considerable research has stressed on developing fault-proneness prediction models in service-oriented systems (SOS) using machine learning (ML) techniques, there has been little work on assessing how effective the source code metrics are for fault prediction. The paper aims to discuss this issue.   Design/methodology/approach  In this paper, the authors have proposed a fault prediction framework to investigate fault prediction in SOS using metrics of web services. The effectiveness of the model has been explored by applying six ML techniques, namely, Naïve Bayes, Artificial Networks (ANN), Adaptive Boosting (AdaBoost), decision tree, Random Forests and Support Vector Machine (SVM), along with five feature selection techniques to extract the essential metrics. The authors have explored accuracy, precision, recall, f -measure and receiver operating characteristic curves of the area under curve values as performance measures.    Findings The experimental results show that the proposed system can classify the fault-proneness of web services, whether the service is faulty or non-faulty, as a binary-valued output automatically and effectively.   Research limitations/implications One possible threat to internal validity in the study is the unknown effects of undiscovered faults. Specifically, the authors have injected possible faults into the classes using Java C3.0 tool and only fixed faults are injected into the classes. However, considering the Java C3.0 community of development, testing and use, the authors can generalize that the undiscovered faults should be few and have less impact on the results presented in this study, and that the results may be limited to the investigated complexity metrics and the used ML techniques.   Originality/value In the literature, only few studies have been observed to directly concentrate on metrics-based fault-proneness prediction of SOS using ML techniques. However, most of the contributions are regarding the fault prediction of the general systems rather than SOS. A majority of them have considered reliability, changeability, maintainability using a logging/history-based approach and mathematical modeling rather than fault prediction in SOS using metrics. Thus, the authors have extended the above contributions further by applying supervised ML techniques over web services metrics and measured their capability by employing fault injection methods. "
pub.1085611475,Effects of Mean Metric Value Over CK Metrics Distribution Towards Improved Software Fault Predictions,"Object Oriented software design metrics has already proven capability in assessing the overall quality of any object oriented software system. At the design level it is very much desirable to estimate software reliability, which is one of the major indicators of software quality. The reliability can also be predicted with help of identifying useful patterns and applying that knowledge in constructing the system in a more specified and reliable manner. Prediction of software fault at design level will also be helpful in reducing the overall development and maintenance cost. Authors have classified data on the basis of fault occurrence and identified some of the classification algorithm performance up to 97%. The classification is carried out using different classification techniques available in Waikato Environment for Knowledge Analysis (WEKA). Classifiers were applied over defect dataset collected from NASA promise repository for different versions of four systems namely jedit, tomact, xalan, and lucene. The defect data set consist of six metrics of CK metric suite as input set and fault as class variable. Outputs of different classifiers are discussed using measures produced by data mining tool WEKA. Authors found Naive Bayes classifier as one of the best classifiers in terms of classification accuracy. Results show that if overall distribution of CK metrics is as per proposed Mean Metric Value (MMV), the probability of overall fault occurrence can be predicted under consideration of lower standard deviation values with respect to given metric values."
pub.1157863318,Software Fault Prediction using Wrapper based Feature Selection Approach employing Genetic Algorithm,"Software fault prediction helps in early identification of software faults and as a result it improves the software quality. It uses previous software metrics and fault data as independent features, to detect whether there is a fault in the software or not. Early prediction of software faults saves a lot of money and effort required to correct those faults. But, as the amount of data is very huge, it is essential for feature selection to get the most useful information. In this paper, we proposed a Genetic Algorithm-based feature selection method that identifies the most useful subset of features for classification purposes. We used a combination of Genetic Algorithm with KNN Classifier, Decision Tree Classifier and Naive Bayes Classifier for our experiments. Our results suggest that, by using Genetic Algorithm for feature selection, our prediction accuracy improved in all the three classifiers for all the datasets and also the number of features were reduced."
pub.1170058943,Development of optimised software fault prediction model using machine learning,"Software fault prediction is a crucial task, especially with the rapid improvements in software technology and increasing complexity of software. As identifying and addressing bugs early in the development process can significantly minimize the costs and enhance the software quality. Software fault prediction using machine learning algorithms has gained significant attention due to its potential to improve software quality and save time in the testing phase. This research paper investigates the impact of classification models on bug prediction performance and explores the use of bio-inspired optimization techniques to enhance model results. Through experiments, it is demonstrated that applying bio-inspired algorithms improves the accuracy of fault prediction models. The evaluation is based on multiple performance metrics and the results show that KNN with BACO (Binary Ant Colony Optimization) generally outperform the other models in terms of accuracy. The BACO-KNN fault prediction model attains the accuracy of 96.39% surpassing the previous work."
pub.1170590194,Software Fault Prediction in Service-Oriented Based Systems,"Software fault prediction plays a crucial role in enhancing software quality and minimizing maintenance cost. Primary goal of software fault prediction is to identify flaws before testing stage, that will save the expense and duration of software development while improving the software product’s quality. In recent years, deep learning techniques have gained significant attention in the field of software fault prediction due to their ability to extract complex patterns and features from large-scale software datasets. This paper aims to provide a comprehensive overview of the existing research on software fault prediction using deep learning techniques. It covers a wide range of studies, including various deep learning models, feature engineering approaches, evaluation metrics, and datasets used in this domain. We examine strategies for predicting software faults in Service-Oriented Architecture based systems using deep learning and hybrid optimization-enabled deep learning methods. The findings reveal that hybrid deep learning and nature-inspired enabled deep learning techniques are more effective than just using machine learning and deep learning approaches."
pub.1030154314,Software Metrics Evaluation Based on Entropy,"The complexity of modern software, the commercial constraints and the expectation for high quality product demands the accurate fault prediction based on OO design metrics in the class level in the early stages of software development. The object oriented class metrics are used as quality predictors in the entire OO software development life cycle even when a highly iterative, incremental model or agile software process is employed. Recent research has shown some of the OO design metrics are useful for predicting fault-proneness of classes. In this chapter the empirical validation of a set of metrics proposed by Chidamber and Kemerer is performed to assess their ability in predicting the software quality in terms of fault proneness and degradation. The authors have also proposed the design complexity of object-oriented software with Weighted Methods per Class metric (WMC-CK metric) expressed in terms of Shannon entropy, and error proneness."
pub.1158632073,Software fault prediction using deep learning techniques,"Software fault prediction (SFP) techniques identify faults at the early stages of the software development life cycle (SDLC). We find machine learning techniques commonly used for SFP compared to deep learning methods, which can produce more accurate results. Deep learning offers exceptional results in various domains, such as computer vision, natural language processing, and speech recognition. In this study, we use three deep learning methods, namely, long short-term memory (LSTM), bidirectional LSTM (BILSTM), and radial basis function network (RBFN) to predict software faults and compare our results with existing models to show how our results are more accurate. Our study uses Chidamber and Kemerer (CK) metrics-based datasets to conduct experiments and test our proposed algorithm. We conclude that LSTM and BILSTM perform better, whereas RBFN is faster in producing the required results. We use k-fold cross-validation to do the model evaluation. Our proposed models provide software developers with a more accurate and efficient SFP mechanism."
pub.1140460556,Smart Prediction Method of Software Defect Using Neuro-Fuzzy Approach,"Faults in software program structures continue to be a primary problem. A software fault is a disorder that reasons software failure in an executable product. A form of software fault predictions techniques were proposed, however none has proven to be continually correct. So, on this examine the overall performance of the Adaptive Neuro Fuzzy Inference System (ANFIS) in predicting software program defects and software program reliability has been reviewed. The datasets are taken from NASA Metrics Data Program (MDP) statistics repository. In the existing work a synthetic intelligence technique viz. Adaptive Neuro Fuzzy Inference System (ANFIS) goes for use for software disorder prediction."
pub.1035563496,Construction of Membership Function for Software Metrics,"A software developer has to deal with a lot of challenging requirements such as cost prediction, defect prediction, reliability prediction, testing effort prediction, safety prediction, and many more while developing quality software. However, it has been found that the most of the software development activity is performed by human beings. This may introduce various faults across the development, causing failures in near future. Therefore, prediction of software defect has been one of the major areas of concern. A number of the software defect prediction model using software metrics has been proposed in last two decades. However, predicting software defect by taking all the software metrics (traditional, object oriented and process) is computationally complex. Therefore, an intelligent selection of metrics plays a vital role in improving the software quality. In the early phases of the software development life cycle, software metrics are associated with uncertainty and can be assessed in linguistic terms. Construction of membership function is very important because the success of a method depends on the membership functions used. Therefore, in this paper, a methodology has been proposed to construct the membership functions of software metrics."
pub.1110892251,Machine learning based software fault prediction utilizing source code metrics,"In the conventional techniques, it requires prior knowledge of faults or a special structure, which may not be realistic in practice while detecting the software faults. To deal with this problem, in this work, the proposed approach aims to predict the faults of the software utilizing the source code metrics. In addition, the purpose of this paper is to measure the capability of the software fault predictability in terms of accuracy, f-measure, precision, recall, Area Under ROC (Receiver Operating Characteristic) Curve (AUC). The study investigates the effect of the feature selection techniques for software fault prediction. As an experimental analysis, our proposed approach is validated from four publicly available datasets. The result predicted from Random Forest technique outperforms the other machine learning techniques in most of the cases. The effect of the feature selection techniques has increased the performance in few cases, however, in the maximum cases it is negligible or even the worse."
pub.1042231867,Object-Oriented Software Metrics,"Software measurement is considered to be an efficient means to monitor the quality of software projects, predict cost of maintenance, assess reusability of components, provide prediction of faults in similar projects, and contribute to improvement of the software development process. This chapter surveys software metrics literature with particular focus on object-oriented metrics, and metrics for measuring code complexity. Furthermore, we provide a critical view of software metrics and their usability."
pub.1015004077,Prediction Interval of Cumulative Number of Software Faults Using Multilayer Perceptron,"Software reliability is one of the most important attributes in software quality metrics. To predict the number of software faults detected in testing phase, many approaches have been applied during the last four decades. Among them, the neural network approach plays a significant role to estimate and predict the number of software fault counts. In this paper, we focus on a prediction problem with the common multilayer perceptron neural networks, and derive the predictive interval of the cumulative number of software faults in sequential software testing. We apply the well-known back propagation algorithm for feed forward neural network architectures and the delta method to construct the prediction intervals. In numerical experiments with four real software development project data sets, we evaluate the one-stage look ahead prediction interval of the cumulative number of software faults, and compare three data transform methods, which are needed for pre-processing the underlying data, in terms of average relative error, coverage rate and predictive interval width."
pub.1160498200,Empirical Validation of Entropy-Based Redundancy Metrics as Reliability Indicators Using Fault-Proneness Attribute and Complexity Metrics,"Software reliability is one of the most important software quality attributes. It is generally predicted using different software metrics that measure internal quality attributes like cohesion and complexity. Therefore, continuous focus on software metrics proposed to predict software reliability still required. In this context, an entropy-based suite of four metrics is proposed to monitor this attribute. The different metrics composing this suite are manually computed and only theoretically validated. Hence, we aim to propose an empirical approach to validate them as useful indicators of software reliability. Therefore, we start by assessing these metrics, using a set of programs retrieved from real software projects. The obtained dataset is served to empirically validate them as reliability indicators. Given that software reliability as external attribute, cannot be directly evaluated, we use two main experiments to perform the empirical validation of these metrics. In the first experiment, we study the relationship between the redundancy metrics and measurable attributes of reliability like fault-proneness. In the second one, we study whether the combination of redundancy metrics with existed complexity and size metrics that are validated as significant reliability indicators can ameliorate the performance of the developed fault-proneness prediction model. The validation is carried out using appropriate machine learning techniques. The experiments outcome showed up that, redundancy metrics provide promising results as indicators of software reliability."
pub.1118258074,Software Metrics Evaluation Based on Entropy,"Software engineering activities in the Industry has come a long way with
various improve- ments brought in various stages of the software development
life cycle. The complexity of modern software, the commercial constraints and
the expectation for high quality products demand the accurate fault prediction
based on OO design metrics in the class level in the early stages of software
development. The object oriented class metrics are used as quality predictors
in the entire OO software development life cycle even when a highly iterative,
incremental model or agile software process is employed. Recent research has
shown some of the OO design metrics are useful for predicting fault-proneness
of classes. In this paper the empirical validation of a set of metrics proposed
by Chidamber and Kemerer is performed to assess their ability in predicting the
software quality in terms of fault proneness and degradation. We have also
proposed the design complexity of object-oriented software with Weighted
Methods per Class metric (WMC-CK metric) expressed in terms of Shannon entropy,
and error proneness."
pub.1105947916,A Systematic Approach Towards Development of Universal Software Fault Prediction Model Using Object-Oriented Design Measurement,"A new systematic approach towards development of a software fault prediction model for trustworthiness and excellence enhancement of software systems by predicting fault-proneness in different severity level of module after coding has been performed in this paper. The classification ability of data mining technique and important object-oriented metrics of object-oriented software system are used to develop this fault prediction model. This model predict the severity level of object-oriented software module based on the number of faults in nominal, low, mid, high and not fault prone (NFP). A different decision tree like Hoeffding tree (VFDT) is created for existing project data Eclipse 2.0 in order to gain information for the purpose of decision-making whether a particular module is faulty or not, and if faulty then in which category. The rules that are obtained from VFDT decision tree algorithm are transformed into fuzzy rules and join together with the fuzzy inference system (FIS) of soft computing approach to predict fault-proneness of object-oriented module in different categories of fault or also not fault free for target data that is other two version of existing project data Eclipse 2.1 and Eclipse 3.0. The main aim of developing this fault prediction model is that to give a direct help to software manager in identifying fault-prone module by including this model before testing phase and just after coding phase so that testing effort can be reduced. And indirectly, this model helps the common people in getting reliable and quality-based system."
pub.1037719922,Software Quality Estimation with Case-Based Reasoning,"The software quality team of a software project often strives to predict the operational quality of software modules prior to software deployment. A timely software quality prediction can be used for enacting any preventive actions so as to reduce software faults from occurring during system operations. This is especially important for high-assurance systems where software reliability is very critical. The two most commonly used models for software quality estimation are, software fault prediction and software quality classification. Generally, such models use software metrics as predictors of a software module's quality, which is either represented by the expected number of faults or a class membership to quality-based groups. This study presents a comprehensive methodology for building software quality estimation models with case-based reasoning (cbr), a computational intelligence technique that is suited for experience-based analysis. A cbr system is a practical option for software quality modeling, because it uses an organization's previous experience with its software development process to estimate the quality of a currently under-development software project. In the context of software metrics and quality data collected from a high-assurance software system, software fault prediction and software quality classification models are built. The former predicts the number of faults in software modules, while the latter predicts the class membership of the modules into the fault-prone and not fault-prone groups. This study presents in-depth details for the cbr models so as to facilitate a comprehensive understanding of the cbr technology as applied to software quality estimation."
pub.1062959702,INCREMENTAL DEVELOPMENT OF FAULT PREDICTION MODELS,"The identification of fault-prone modules has a significant impact on software quality assurance. In addition to prediction accuracy, one of the most important goals is to detect fault prone modules as early as possible in the development lifecycle. Requirements, design, and code metrics have been successfully used for predicting fault-prone modules. In this paper, we investigate the benefits of the incremental development of software fault prediction models. We compare the performance of these models as the volume of data and their life cycle origin (design, code, or their combination) evolve during project development. We analyze 14 data sets from publicly available software engineering data repositories. These data sets offer both design and code metrics. Using a number of modeling techniques and statistical significance tests, we confirm that increasing the volume of training data improves model performance. Further models built from code metrics typically outperform those that are built using design metrics only. However, both types of models prove to be useful as they can be constructed in different phases of the life cycle. Code-based models can be used to increase the effectiveness of assigning verification and validation activities late in the development life cycle. We also conclude that models that utilize a combination of design and code level metrics outperform models which use either one metric set exclusively."
pub.1028696564,Neural Network Parameter Optimization Based on Genetic Algorithm for Software Defect Prediction,"Software fault prediction approaches are much more efficient and effective to detect software faults compared to software reviews. Machine learning classification algorithms have been applied for software defect prediction. Neural network has strong fault tolerance and strong ability of nonlinear dynamic processing of software defect data. However, practicability of neural network is affected due to the difficulty of selecting appropriate parameters of network architecture. Software fault prediction datasets are often highly imbalanced class distribution. Class imbalance will reduce classifier performance. A combination of genetic algorithm and bagging technique is proposed for improving the performance of the software defect prediction. Genetic algorithm is applied to deal with the parameter optimization of neural network. Bagging technique is employed to deal with the class imbalance problem. The proposed method is evaluated using the datasets from NASA metric data repository. Results have indicated that the proposed method makes an improvement in neural network prediction performance."
pub.1003542538,Object-oriented software fault prediction using neural networks,"This paper introduces two neural network based software fault prediction models using Object-Oriented metrics. They are empirically validated using a data set collected from the software modules developed by the graduate students of our academic institution. The results are compared with two statistical models using five quality attributes and found that neural networks do better. Among the two neural networks, Probabilistic Neural Networks outperform in predicting the fault proneness of the Object-Oriented modules developed."
pub.1142220184,The Effect of the Dataset Size on the Accuracy of Software Defect Prediction Models: An Empirical Study,"The ongoing development of computer systems requires massive software projects. Running the components of these huge projects for testing purposes might be a costly process; therefore, parameter estimation can be used instead. Software defect prediction models are crucial for software quality assurance. This study investigates the impact of dataset size and feature selection algorithms on software defect prediction models. We use two approaches to build software defect prediction models: a statistical approach and a machine learning approach with support vector machines (SVMs). The fault prediction model was built based on four datasets of different sizes. Additionally, four feature selection algorithms were used. We found that applying the SVM defect prediction model on datasets with a reduced number of measures as features may enhance the accuracy of the fault prediction model. Also, it directs the test effort to maintain the most influential set of metrics. We also found that the running time of the SVM fault prediction model is not consistent with dataset size. Therefore, having fewer metrics does not guarantee a shorter execution time. From the experiments, we found that dataset size has a direct influence on the SVM fault prediction model. However, reduced datasets performed the same or slightly lower than the original datasets."
pub.1005295069,A decision tree logic based recommendation system to select software fault prediction techniques,"Identifying a reliable fault prediction technique is the key requirement for building effective fault prediction model. It has been found that the performance of fault prediction techniques is highly dependent on the characteristics of the fault dataset. To mitigate this issue, researchers have evaluated and compared a plethora of fault prediction techniques by varying the context in terms of domain information, characteristics of input data, complexity, etc. However, the lack of an accepted benchmark makes it difficult to select fault prediction technique for a particular context of prediction. In this paper, we present a recommendation system that facilitates the selection of appropriate technique(s) to build fault prediction model. First, we have reviewed the literature to elicit the various characteristics of the fault dataset and the appropriateness of the machine learning and statistical techniques for the identified characteristics. Subsequently, we have formalized our findings and built a recommendation system that helps in the selection of fault prediction techniques. We performed an initial appraisal of our presented system and found that proposed recommendation system provides useful hints in the selection of the fault prediction techniques."
pub.1157030229,An Exploratory Framework for Intelligent Labelling of Fault Datasets,"Software fault prediction (SFP) has become a pivotal aspect in realm of software quality. Nevertheless, discipline of software quality suffers the starvation of fault datasets. Most of the research endeavors are focused on type of dataset, its granularity, metrics usedand metrics extractors. However, spo-radic attention has been exerted on developmentof fault datasets and their associated challenges. There are very few publicly available datasets limiting the possibilities of comprehensive experiments on way to improvising the quality of software. Current research targets to address the challenges pertinent to fault dataset collection and developmentif one is not available publicly. It also considers dynamic identification of available resources such as public dataset, open-source software archieves, metrics parsers and intelligent labeling techniques. A framework for datasetcollection and development process has been furnished alongwith evaluation procedure for the identified resources."
pub.1006547483,Investigating of high and low impact faults in object-oriented projects,"For optimum utilization of resources and reducing the cost of software, the fault detection and elimination process must be properly planned and for this type of planning prediction of fault-prone module is gaining importance among researchers. It would be valuable to know how object-oriented design metrics and class fault-proneness are related when fault impact is taken into account. In this paper, we use the logistic regression method to empirically investigate the usefulness of object-oriented design metrics in predicting fault-proneness when taking fault impact into account. Our results, based on a public domain NASA Promise data set, indicate that most of these design metrics are statistically related to fault-proneness of classes across fault impact, and the prediction capabilities of the investigated metrics greatly depend on the impact of faults. More specifically, these design metrics are able to predict high/low impact faults in fault-prone classes."
pub.1017703063,A Fault Prediction Model with Limited Fault Data to Improve Test Process,"Software fault prediction models are used to identify the fault-prone software modules and produce reliable software. Performance of a software fault prediction model is correlated with available software metrics and fault data. In some occasions, there may be few software modules having fault data and therefore, prediction models using only labeled data can not provide accurate results. Semi-supervised learning approaches which benefit from unlabeled and labeled data may be applied in this case. In this paper, we propose an artificial immune system based semi-supervised learning approach. Proposed approach uses a recent semi-supervised algorithm called YATSI (Yet Another Two Stage Idea) and in the first stage of YATSI, AIRS (Artificial Immune Recognition Systems) is applied. In addition, AIRS, RF (Random Forests) classifier, AIRS based YATSI, and RF based YATSI are benchmarked. Experimental results showed that while YATSI algorithm improved the performance of AIRS, it diminished the performance of RF for unbalanced datasets. Furthermore, performance of AIRS based YATSI is comparable with RF which is the best machine learning classifier according to some researches."
pub.1094982599,PERFORMANCE ANALYSIS OF DATA MINING ALGORITHMS FOR SOFTWARE QUALITY PREDICTION,"Data mining techniques are applied in building software fault prediction models for improving the software quality. Early identification of high-risk modules can assist in quality enhancement efforts to modules that are likely to have a high number of faults. Classification tree models are simple and effective as software quality prediction models, and timely predictions of defects from such models can be used to achieve high software reliability. In this paper, the performance of five data mining classifier algorithms named J48, CART, Random Forest, BFTree and Naïve Bayesian classifier(NBC) are evaluated based on 10 fold cross validation test. Experimental results using KC2 NASA software metrics dataset demonstrates that decision trees are much useful for fault predictions and based on rules generated only some measurement attributes in the given set of the metrics play an important role in establishing final rules and for improving the software quality by giving correct predictions. Thus we can suggest that these attributes are sufficient for future classification process. To evaluate the performance of the above algorithms Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), Receiver Operating Characteristic (ROC) and Accuracy measures are applied."
pub.1023817307,Risk chain prediction metrics for predicting fault proneness in object oriented systems,"The paper presents two atypical risk chain prediction metrics for barometer coupling and accord in software systems. Our aboriginal metric, Ideal Coupling between Object classes (ICBO), is based on the acclaimed CBO coupling metric, while the added metric, Ideal Lack of Cohesion on Methods (ILCOM5), is based on the LCOM5 accord metric. One advantage of the proposed risk chain prediction metrics is that they can be computed in a simpler way as compared to some of the structural metrics. We empirically advised ICBO and ILCOM5 for admiration fault proneness of classes in a ample accessible antecedent arrangement and compared these metrics with a host of absolute structural and risk chain prediction metrics for the aforementioned task."
pub.1126865150,Linear regression with factor analysis in fault prediction of software,"In software fault prediction, before beginning with the real software testing process, faultprone software modules are identified with the help of various properties related to the software project. This leads to the achievement of minimal cost apart from the desired software quality. In this study, Object oriented metrics were used to find the main factors. The technique used to find the important predictors is Factor analysis (FA) and regression is used to analyze the goodness of fit of different models drawn from previous studies. Following this, identification of various factors associated with the software fault prediction process is done. In addition, a robust model is developed on the basis of the distinct identified factors. The research work is the extension of our previous work. This research provides a novel approach of different aspects of the software fault prediction process and also assists in discovering the different types of problems associated with the term i.e. software fault prediction. Towards the end, the statistical comparison and the challenges of the paper are discussed along with the future guidelines of the study."
pub.1061788438,Empirical validation of object-oriented metrics on open source software for fault prediction,"Open source software systems are becoming increasingly important these days. Many companies are investing in open source projects and lots of them are also using such software in their own work. But, because open source software is often developed with a different management style than the industrial ones, the quality and reliability of the code needs to be studied. Hence, the characteristics of the source code of these projects need to be measured to obtain more information about it. This paper describes how we calculated the object-oriented metrics given by Chidamber and Kemerer to illustrate how fault-proneness detection of the source code of the open source Web and e-mail suite called Mozilla can be carried out. We checked the values obtained against the number of bugs found in its bug database - called Bugzilla - using regression and machine learning methods to validate the usefulness of these metrics for fault-proneness prediction. We also compared the metrics of several versions of Mozilla to see how the predicted fault-proneness of the software system changed during its development cycle."
pub.1164114213,A Machine Learning Approach to Predict Software Faults,"A software fault prediction system ensures that software is bug-free during the development and testing phases before it is put into production (Azeem et al. in Inf Softw Technol 108:115–138, 2019). Predicting software breakdown during software development is essential to ensuring quality and reliability. The paper categorizes the National Aeronautics and Space Administration (NASA) Promise datasets, namely CM1, JM1, and PC1. A component, class, or module should be tested for faults at an early stage of the development process. As a result, costs and time will be reduced. Findings, as measured by the F1-score three defect datasets, yielded a classification performance of 99–100% with the most successful execution using the Support Vector matrix."
pub.1142033866,Evaluation of Software Fault Proneness with a Support Vector Machine and Biomedical Applications,"The high throughput and good quality software are developed if effective defect prone modules can be predicted by testers at early stages. This enables the testers to focus on the activities, allocation of effort, and efficient resource management. Accurate prediction of fault inclined modules in software development manner allows effective detection and identity of defects. The existing researches used support vector machine (SVM) in standalone mode in the sense that no pre-processing is performed before invoking classification; thus degrading the accuracy of prediction. This chapter delivered a singular approach combining SVM and feature choice for software fault proneness prediction (SFPP). Experiments suggest that the accuracy of the proposed method using five object-oriented (OO) metrics, that is, line of code (LOC), program level (L), branch count (BR), and unique operands. Hence, the OO metrics have a large prone in defect prone modules."
pub.1147982789,A hybrid approach based on k-nearest neighbors and decision tree for software fault prediction,"Software testing is a very important part of the software development life cycle to develop reliable and bug-free software but it consumes a lot of resources like development time, cost, and effort. Researchers have developed many techniques to get prior knowledge of fault-prone modules so that testing time and cost can be reduced. In this research article, a hybrid approach of distance-based pruned classification and regression tree (CART) and k- nearest neighbors is proposed to improve the performance of software fault prediction. The proposed technique is tested on eleven medium to large scale software fault prediction datasets and performance is compared with decision tree classifier, SVM and its three variations, random forest, KNN, and classification and regression tree. Four performance metrics are used for comparison purposes that are accuracy, precision, recall, and f1-score. Results show that our proposed approach gives better performance for accuracy, precision, and f1-score performance metrics. The second experiment shows a significant amount of running time improvement over the standard k-nearest neighbor algorithm."
pub.1000158778,Empirical validation of object-oriented metrics for predicting fault proneness models,"Empirical validation of software metrics used              to predict software quality attributes is important to ensure their practical relevance in software organizations. The aim of this work is to find the relation of object-oriented (OO) metrics with fault proneness at different severity levels of faults. For this purpose, different prediction models have been developed using regression and machine learning methods. We evaluate and compare the performance of these methods to find which method performs better at different severity levels of faults and empirically validate OO metrics given by Chidamber and Kemerer. The results of the empirical study are based on public domain NASA data set. The performance of the predicted models was evaluated using Receiver Operating Characteristic (ROC) analysis. The results show that the area under the curve (measured from the ROC analysis) of models predicted using high severity faults is low as compared with the area under the curve of the model predicted with respect to medium and low severity faults. However, the number of faults in the classes correctly classified by predicted models with respect to high severity faults is not low. This study also shows that the performance of machine learning methods is better than logistic regression method with respect to all the severities of faults. Based on the results, it is reasonable to claim that models targeted at different severity levels of faults could help for planning and executing testing by focusing resources on fault-prone parts of the design and code that are likely to cause serious failures."
pub.1095092354,A practical method for the software fault-prediction,"In the paper, a novel machine learning method, SimBoost, is proposed to handle the software fault-prediction problem when highly skewed datasets are used. Although the method, proved by empirical results, can make the datasets much more balanced, the accuracy of the prediction is still not satisfactory. Therefore, a fuzzy-based representation of the software module fault state has been presented instead of the original faulty/non-faulty one. Several experiments were conducted using datasets from NASA Metrics Data Program. The discussion of the results of experiments is provided."
pub.1110383574,Software fault classification using extreme learning machine: a cognitive approach,"The software fault classification is very crucial in the development of reliable and high-quality software products. The fault classification allows determining and concentrating on fault software modules for early prediction of fault in time. As a result, it saves the time and money of the industry. Generally, various metrics are generated to represent the fault. But, selecting the dominant metrics from the available set is a challenge. Therefore, in this paper, a sequential forward search (SFS) with extreme learning machine (ELM) approach has used for fault classification. The number of features available in the metrics are selected to represent the fault using SFS and operated on ELM to verify the performance of software fault classification. Also, various activation functions of ELM have tested for the proposed work to identify the best model. The experimental result demonstrates that ELM with radial basis function achieves the good results compared to other activation function. Also, the proposed method has shown good results in comparison to support vector machine."
pub.1169436683,Nonparametric Statistical Feature Scaling Based Quadratic Regressive Convolution Deep Neural Network for Software Fault Prediction,"The development of defect prediction plays a significant role in improving software quality. Such predictions are used to identify defective modules before the testing and to minimize the time and cost. The software with defects negatively impacts operational costs and finally affects customer satisfaction. Numerous approaches exist to predict software defects. However, the timely and accurate software bugs are the major challenging issues. To improve the timely and accurate software defect prediction, a novel technique called Nonparametric Statistical feature scaled QuAdratic regressive convolution Deep nEural Network (SQADEN) is introduced. The proposed SQADEN technique mainly includes two major processes namely metric or feature selection and classification. First, the SQADEN uses the nonparametric statistical Torgerson–Gower scaling technique for identifying the relevant software metrics by measuring the similarity using the dice coefficient. The feature selection process is used to minimize the time complexity of software fault prediction. With the selected metrics, software fault perdition with the help of the Quadratic Censored regressive convolution deep neural network-based classification. The deep learning classifier analyzes the training and testing samples using the contingency correlation coefficient. The softstep activation function is used to provide the final fault prediction results. To minimize the error, the Nelder–Mead method is applied to solve non-linear least-squares problems. Finally, accurate classification results with a minimum error are obtained at the output layer. Experimental evaluation is carried out with different quantitative metrics such as accuracy, precision, recall, F-measure, and time complexity. The analyzed results demonstrate the superior performance of our proposed SQADEN technique with maximum accuracy, sensitivity and specificity by 3%, 3%, 2% and 3% and minimum time and space by 13% and 15% when compared with the two state-of-the-art methods."
pub.1093622002,Quality Prediction Model of Object-Oriented Software System using Computational Intelligence,"Effective prediction of the fault-proneness plays a very important role in the analysis of software quality and balance of software cost, and it also is an important problem of software engineering. Importance of software quality is increasing leading to development of new sophisticated techniques, which can be used in constructing models for predicting quality attributes. In this paper, we use fuzzy $c$-means clustering (FCM) and radial basis function neural network (RBFNN) to construct prediction model of the fault-proneness, RBFNN is used as a classificatory, and FCM is as a cluster. Object-oriented software metrics are as input variables of fault prediction model. Experiments results confirm that designed model is very effective for predicting a class's fault-proneness, it has a high accuracy, and its implementation requires neither extra cost nor expert's knowledge. It also is automated. Therefore, proposed model was very useful in predicting software quality and classing the fault-proneness."
pub.1035878787,Predicting Fault-Prone Modules: A Comparative Study,"Offshore and outsourced software development is a rapidly increasing trend in global software business environment. Predicting fault-prone modules in outsourced software product may allow both parties to establish mutually satisfactory, cost-effective testing strategies and product acceptance criteria, especially in iterative transitions. In this paper, based on industrial software releases data, we conduct an empirical study to compare ten classifiers over eight sets of code attributes, and provide recommendations to aid both the client and vendor to assess the products’ quality through defect prediction. Overall, a generally high accuracy is observed, which confirms the usefulness of the metric-based classification. Furthermore, two classification techniques, Random Forest and Bayesian Belief Network, outperform the others in terms of predictive accuracy; in more detail, the former is the most cost-effective and the latter is of the lowest fault-prone module escaping rate. Our study also concludes that code metrics including size, traditional complexity, and object-oriented complexity perform fairly well."
pub.1131849590,A Taxonomy of Metrics for Software Fault Prediction,"Researchers in the field of Software Fault Prediction (SFP) make use of software metrics to build predictive models, for example, by means of machine learning and statistical techniques. The number of metrics used for SFP has increased dramatically in the last few decades. Therefore, a taxonomy of metrics for SFP could be useful to standardize the lexicon, to simplify the communication among researchers/practitioners, and to organize and classify such metrics. In this research, we built a taxonomy of metrics for SFP with the aim of making it as comprehensive as possible. We exploited and extended two Systematic Literature Reviews (SLRs) to collect and classify a total of 512 metrics for SFP and then to build our taxonomy. We also provide information on the metrics in this taxonomy in terms of: acronym(s), extended name, description, granularity of the prediction, category, and research papers in which they were used. To allow the taxonomy to be constantly updated over time, we provide external contributors the possibility to ask for changes via pull-requests on GitHub."
pub.1094349395,Prediction of fault-proneness at early phase in object-oriented development,"To analyse the complexity of object-oriented software, several metrics have been proposed. Among them, Chidamber and Kemerer's (1994) metrics are well-known object-oriented metrics. Also, their effectiveness has been empirically evaluated from the viewpoint of estimating the fault-proneness of object-oriented software. In the evaluations, these metrics were applied, not to the design specification but to the source code, because some of them measure the inner complexity of a class, and such information cannot be obtained until the algorithm and the class structure are determined at the end of the design phase. However, the estimation of the fault-proneness should be done in the early phase so as to effectively allocate effort for fixing the faults. This paper proposes a new method to estimate the fault-proneness of an object class in the early phase, using several complexity metrics for object-oriented software. In the proposed method, we introduce four checkpoints into the analysis/design/implementation phase, and we estimate the fault-prone classes using applicable metrics at each checkpoint."
pub.1006613351,Investigating ARIMA models of software system quality,"In this paper, we investigate how to incorporate program complexity measures with a software quality model. We collect software complexity metrics and fault counts from each build during the testing phase of a large commercial software system. Though the data are limited in quantity, we are able to predict the number of faults in the next build. The technique we used is called times series analysis and forecasting. The methodology assumes that future predictions are based on the history of past observations. We will show that the combined complexity quality model is an improvement over the simpler quality only model. Finally, we explore how the testing process used in this development may be improved by using these predictions and suggest areas for future research."
pub.1037231893,A survey on software fault detection based on different prediction approaches,"One of the software engineering interests is quality assurance activities such as testing, verification and validation, fault tolerance and fault prediction. When any company does not have sufficient budget and time for testing the entire application, a project manager can use some fault prediction algorithms to identify the parts of the system that are more defect prone. There are so many prediction approaches in the field of software engineering such as test effort, security and cost prediction. Since most of them do not have a stable model, software fault prediction has been studied in this paper based on different machine learning techniques such as decision trees, decision tables, random forest, neural network, Naïve Bayes and distinctive classifiers of artificial immune systems (AISs) such as artificial immune recognition system, CLONALG and Immunos. We use four public NASA datasets to perform our experiment. These datasets are different in size and number of defective data. Distinct parameters such as method-level metrics and two feature selection approaches which are principal component analysis and correlation based feature selection are used to evaluate the finest performance among the others. According to this study, random forest provides the best prediction performance for large data sets and Naïve Bayes is a trustable algorithm for small data sets even when one of the feature selection techniques is applied. Immunos99 performs well among AIS classifiers when feature selection technique is applied, and AIRSParallel performs better without any feature selection techniques. The performance evaluation has been done based on three different metrics such as area under receiver operating characteristic curve, probability of detection and probability of false alarm. These three evaluation metrics could give the reliable prediction criteria together."
pub.1093508390,An Empirical Approach for Software Fault Prediction,"Measuring software quality in terms of fault proneness of data can help the tomorrow's programmers to predict the fault prone areas in the projects before development. Knowing the faulty areas early from previous developed projects can be used to allocate experienced professionals for development of fault prone modules. Experienced persons can emphasize the faulty areas and can get the solutions in minimum time and budget that in turn increases software quality and customer satisfaction. We have used Fuzzy C Means clustering technique for the prediction of faulty/non-faulty modules in the project. The datasets used for training and testing modules available from NASA projects namely CM1, PC1 and JM1 include requirement and code metrics which are then combined to get a combination metric model. These three models are then compared with each other and the results show that combination metric model is found to be the best prediction model among three. Also, this approach is compared with others in the literature and is proved to be more accurate. This approach has been implemented in MATLAB7.9."
pub.1091531667,Prediction and Improvement of Safety in Software Systems,"The modern military's ability to fight depends heavily on complex software systems, making the safety of such of software of paramount importance. The transformation of the military's analog combat systems to computer-based systems has been plagued by software problems ranging from benign flight simulator issues to 'smart' ships finding themselves dead in the water. The military's interest in increasing automation in order to reduce manpower requirements makes even trivial software safety issues a serious concern. The software engineering community is not well equipped to reduce the safety risks incurred through use of such systems, and stands to benefit from metrics, analysis tools, and techniques that address software system safety from a design perspective. The purpose of this research project was to propose and develop tools that software engineers can use to address the issue of software safety. The project focused on safety prediction and improvement through the use of software fault trees coupled with ""key nodes,"" or fault tree-based safety metric, and an algorithm for estimating the improvement costs necessary to achieve a targeted level of software safety. The safety prediction metric uses the key node property of fault trees while the improvement algorithm is based on the mathematical relationship between nodes in a fault tree, and yields an estimate of the man-hours necessary to improve a system to a targeted safety value based on cost functions supplied by a component s developer. These metrics and algorithms allow designers to measure and improve the safety of software systems early in the design process, allowing for a reduction in costs and an improvement in resource allocation."
pub.1167346904,Using Deep Learning and Object-Oriented Metrics to Identify Critical Components in Object-Oriented Systems,"This paper aims at studying the ability of deep machine learning to predict software faults based on object-oriented metrics. This research investigated software faults from the perspective of fault-proneness, faults number and faults frequency, and used data collected from several versions of a Java open-source software system. This study relied on Chidamber and Kemerer suite of metrics as proxy to capture various software characteristics. In this study, the deep learning regression and classification results were compared to linear and logistic regressions. Auto-Encoders (AE) and Principal Components Analysis (PCA) have been used to reduce redundant information from the dataset. To evaluate the prediction ability of the models, this research used the inter-version validation strategy. The results showed that the models can achieve a significant average performance up to 89%."
pub.1095355101,Fault Prediction using Early Lifecycle Data,"The prediction of fault-prone modules in a software project has been the topic of many studies. In this paper, we investigate whether metrics available early in the development lifecycle can be used to identify fault-prone software modules. More precisely, we build predictive models using the metrics that characterize textual requirements. We compare the performance of requirements-based models against the performance of code-based models and models that combine requirement and code metrics. Using a range of modeling techniques and the data from three NASA projects, our study indicates that the early lifecycle metrics can play an important role in project management, either by pointing to the need for increased quality monitoring during the development or by using the models to assign verification and validation activities."
pub.1175017175,Automating Fault Prediction in Software Testing Using Machine Learning Techniques: A Real-World Applications,"Software testing is essential for ensuring the reliability and quality of software systems. Fault prediction and proneness have become critical concerns for the tech industry and software professionals. Traditional methods rely on past fault occurrences or faulty modules, which are often resource-intensive and exhaustive. Consequently, there's a growing interest in predictive techniques for early fault detection during the development lifecycle. In this research, Machine learning (ML) classification models have been proposed for fault prediction in software testing, using historical data to train models that recognize patterns indicative of faulty code. Automated software fault recovery models driven by ML further enhance performance, reduce faults, and optimize time and costs. Software defect predictive development models using various ML classification models, including Neural Networks (NN), applied to a real-world testing dataset have been proposed. To overcome Class imbalance problem, SMOTE ENN (Synthetic Minority Oversampling Technique Edited Nearest Neighbor) method has been implemented and accuracy has been used as the primary evaluation metric. The Random Forest model achieved a notable fault prediction accuracy of 93 %. Additionally, through comprehensive literature analysis, the research delineates trends, highlights strengths, and suggests potential future research directions."
pub.1164029710,Ensemble-based software fault prediction with two staged data pre-processing,"Software fault prediction is the process of identifying the software modules which are more likely to be defective or faulty before the testing phase of software development life-cycle model. We use software metric values of different modules for the known software project to train the software fault prediction model. Our objective is to implement the ensemble-based models on software fault data sets along with feature selection and data re-sampling techniques to achieve the improved performance. In this paper, we have designed a two-stage data pre-processing technique on the data set before passing it through the ensemble-based model for training. It has been found that the two-stage pre-processing model outperforms the general ensemble-based model. It gives an improvement of 1 to 6% for all the used classifiers viz., Bagging, Dagging, Rotation Forest, Random Forest and AdaBoost."
pub.1031264269,Perspectives,Three perspectives on Software Process Improvement through Metrics are given in this chapter. The views of Norman Fenton and José D. Carrillo Verdun were presented at EUREX Metrics Workshops in the UK and Spain respectively. Terttu Orci was an active member of the Nordic EUREX team and made a study of Metrics Quality in relevant Process Improvement Experiments.
pub.1136732316,A sequential ensemble model for software fault prediction,"Unlike several other engineering disciplines, software engineering lacks well-defined research strategies. However, with the exponential rise in automation, the demand for software has observed an enormous elevation. Simultaneously, it necessitates having zero failures in the software modules to maximize the availability and optimize the maintenance cost. This has attracted many researchers to try their hand in formalizing the strategies for testing of software. Numerous researchers have suggested various models in this context. The authors in this paper present a sequential ensemble model to predict software faults. The employment of ensemble modeling in software fault prediction is motivated by its competence in various domains. The proposed model is also implemented on the 8 datasets taken from PROMISE and ECLIPSE repository. The proposed model's performance is evaluated using various error metrics, viz. average absolute error, average relative error, and prediction. The obtained results are encouraging and thus establish the competence of the proposed model."
pub.1093713517,Application of Random Forest in Predicting Fault-Prone Classes,"There are available metrics for predicting fault prone classes, which may help software organizations for planning and performing testing activities. This may be possible due to proper allocation of resources on fault prone parts of the design and code of the software. Hence, importance and usefulness of such metrics is understandable, but empirical validation of these metrics is always a great challenge. Random Forest (RF) algorithm has been successfully applied for solving regression and classification problems in many applications. This paper evaluates the capability of RF algorithm in predicting fault prone software classes using open source software. The results indicate that the prediction performance of Random Forest is good. However, similar types of studies are required to be carried out in order to establish the acceptability of the RF model."
pub.1005687457,An iterative semi-supervised approach to software fault prediction,"Background: Many statistical and machine learning techniques have been implemented to build predictive fault models. Traditional methods are based on supervised learning. Software metrics for a module and corresponding fault information, available from previous projects, are used to train a fault prediction model. This approach calls for a large size of training data set and enables the development of effective fault prediction models. In practice, data collection costs, the lack of data from earlier projects or product versions may make large fault prediction training data set unattainable. Small size of the training set that may be available from the current project is known to deteriorate the performance of the fault predictive model. In semi-supervised learning approaches, software modules with known or unknown fault content can be used for training. Aims: To implement and evaluate a semi-supervised learning approach in software fault prediction. Methods: We investigate an iterative semi-supervised approach to software quality prediction in which a base supervised learner is used within a semi-supervised application. Results: We varied the size of labeled software modules from 2% to 50% of all the modules in the project. After tracking the performance of each iteration in the semi-supervised algorithm, we observe that semi-supervised learning improves fault prediction if the number of initially labeled software modules exceeds 5%. Conclusion: The semi-supervised approach outperforms the corresponding supervised learning approach when both use random forest as base classification algorithm."
pub.1103211236,Static Analysis and Code Complexity Metrics as Early Indicators of Software Defects,"Software is an important part of automotive product development, and it is commonly known that software quality assurance consumes considerable effort in safety-critical embedded software development. Increasing the effectiveness and efficiency of this effort thus becomes more and more important. Identifying problematic code areas which are most likely to fail and therefore require most of the quality assurance attention is required. This article presents an exploratory study investigating whether the faults detected by static analysis tools combined with code complexity metrics can be used as software quality indicators and to build pre-release fault prediction models. The combination of code complexity metrics with static analysis fault density was used to predict the pre-release fault density with an accuracy of 78.3%. This combination was also used to separate high and low quality components with a classification accuracy of 79%."
pub.1093526612,Analysis and Prediction of Mandelbugs in an Industrial Software System,"Mandelbugs are faults that are triggered by complex conditions, such as interaction with hardware and other software, and timing or ordering of events. These faults are considerably difficult to detect with traditional testing techniques, since it can be challenging to control their complex triggering conditions in a testing environment. Therefore, it is necessary to adopt specific verification and/or fault-tolerance strategies for dealing with them in a cost-effective way. In this paper, we investigate how to predict the location of Mandelbugs in complex software systems, in order to focus V&V activities and fault tolerance mechanisms in those modules where Mandelbugs are most likely present. In the context of an industrial complex software system, we empirically analyze Mandelbugs, and investigate an approach for Mandelbug prediction based on a set of novel software complexity metrics. Results show that Mandelbugs account for a noticeable share of faults, and that the proposed approach can predict Mandelbug-prone modules with greater accuracy than the sole adoption of traditional software metrics."
pub.1127350819,Soft Computing Approaches to Investigate Software Fault Proneness in Agile Software Development Environment,"This chapter presents framework which makes use of product and process metrics to predict faulty modules in agile software development environment. The proposed model makes use of soft computing methods, like Mandani and Takagi–Sugeno style fuzzy inference system, artificial neural network, and adaptive neuro fuzzy inference system, for building fault prediction models. For achieving the goal of the study, several experiments are performed on the ‘Ant dataset project version’ of the ‘PROMISE’ data repository. Additionally, to assess outcomes of the proposed prediction model, evaluation criteria based upon receiver operating characteristics with the area under curve (AUC (ROC)) is applied. The application of the proposed model can help the developers not only in the design phase but also in testing and maintenance phases. It also reduces the time effort in code and review process."
pub.1113500619,Software Defect Prediction Using Principal Component Analysis and Naïve Bayes Algorithm,"How can I deliver defect-free software? Can I achieve more with less resources? How can I reduce time, effort, and cost involved in developing software? Software defect prediction is an important area of research which can significantly help the software development teams grappling with these questions in an effective way. A small increase in prediction accuracy will go a long way in helping software development teams improve their efficiency. In this paper, we have proposed a framework which uses PCA for dimensionality reduction and Naïve Bayes classification algorithm for building the prediction model. We have used seven projects from NASA Metrics Data Program for conducting experiments. We have seen an average increase of 10.3% in prediction accuracy when the learning algorithm is applied with the key features extracted from the datasets."
pub.1107417253,Revisiting the size effect in software fault prediction models,"BACKGROUND: In object oriented (OO) software systems, class size has been acknowledged as having an indirect effect on the relationship between certain artifact characteristics, captured via metrics, and fault-proneness, and therefore it is recommended to control for size when designing fault prediction models. AIM: To use robust statistical methods to assess whether there is evidence of any true effect of class size on fault prediction models. METHOD: We examine the potential mediation and moderation effects of class size on the relationships between OO metrics and number of faults. We employ regression analysis and bootstrapping-based methods to investigate the mediation and moderation effects in two widely-used datasets comprising seventeen systems. RESULTS: We find no strong evidence of a significant mediation or moderation effect of class size on the relationships between OO metrics and faults. In particular, size appears to have a more significant mediation effect on CBO and Fan-out than other metrics, although the evidence is not consistent in all examined systems. On the other hand, size does appear to have a significant moderation effect on WMC and CBO in most of the systems examined. Again, the evidence provided is not consistent across all examined systems CONCLUSION: We are unable to confirm if class size has a significant mediation or moderation effect on the relationships between OO metrics and the number of faults. We contend that class size does not fully explain the relationships between OO metrics and the number of faults, and it does not always affect the strength/magnitude of these relationships. We recommend that researchers consider the potential mediation and moderation effect of class size when building their prediction models, but this should be examined independently for each system."
pub.1036735372,Thresholds based outlier detection approach for mining class outliers: An empirical case study on software measurement datasets,"Predicting the fault-proneness labels of software program modules is an emerging software quality assurance activity and the quality of datasets collected from previous software version affects the performance of fault prediction models. In this paper, we propose an outlier detection approach using metrics thresholds and class labels to identify class outliers. We evaluate our approach on public NASA datasets from PROMISE repository. Experiments reveal that this novel outlier detection method improves the performance of robust software fault prediction models based on Naive Bayes and Random Forests machine learning algorithms."
pub.1173476073,Feature Selection using Genetic Algorithm for Software Fault Prediction,"The field of software engineering has seen an increase in research aimed at predicting software defects. The importance of non-functional defects in this study can effectively predict software defects, thus simplifying software testing, reducing costs, and improving the overall software testing process. However, the presence of noise in the data set often causes software bug prediction performance to decrease. In this work, a Genetic Algorithm (GA) is used to improve the accuracy of software fault prediction. It is used as a feature selection (FS) algorithm. The technology was evaluated using NASA’s Metrics Data Repository dataset. The results show that the prediction performance of most products is greatly improved when the proposed method is used."
pub.1118229881,A Comparative Study of Various Distance Measures for Software fault prediction,"Different distance measures have been used for efficiently predicting
software faults at early stages of software development. One stereotyped
approach for software fault prediction due to its computational efficiency is
K-means clustering, which partitions the dataset into K number of clusters
using any distance measure. Distance measures by using some metrics are used to
extract similar data objects which help in developing efficient algorithms for
clustering and classification. In this paper, we study K-means clustering with
three different distance measures Euclidean, Sorensen and Canberra by using
datasets that have been collected from NASA MDP (metrics data program) .Results
are displayed with the help of ROC curve. The experimental results shows that
K-means clustering with Sorensen distance is better than Euclidean distance and
Canberra distance."
pub.1094009406,Assessing the Differences of Clone Detection Methods Used in the Fault-Prone Module Prediction,"We have investigated through several experiments the differences in the fault-prone module prediction accuracy caused by the differences in the constituent code clone metrics of the prediction model. In the previous studies, they use one or more code clone metrics as independent variables to build an accurate prediction model. While they often use the clone detection method proposed by Kamiya et al. to calculate these metrics, the effect of the detection method on the prediction accuracy is not clear. In the experiment, we built prediction models using a dataset collected from an open source software project. The result suggests that the prediction accuracy is improved, when clone metrics derived from the various clone detection tool are used."
pub.1033610498,Software Defect Analysis of a Multi-release Telecommunications System,"This paper provides a study of several process metrics of an industrial large-scale embedded software system, the Lucent product Lambda-UniteTM MSS. This product is an evolutionary hardware/software system for the metropolitan and wide-area transmission and switching market. An analysis of defect data is performed, including and comparing all major (i.e. feature) releases till end of 2004. Several defect metrics on file-level are defined and analyzed, as basis for a defect prediction model. Main analysis results include the following. Faults and code size per file show only a weak correlation. Portion of faulty files per release tend to decrease across releases. Size and error-proneness in previous release alone is not a good predictor of a file’s faults per release. Customer-found defects are strongly correlated with pre-delivery defects found per subsystem. These results are being compared to a recent similar study of fault distributions; the differences are significant."
pub.1154035108,Research on Efficient Software Defect Prediction Using Deep Learning Approaches,"Software Defect prediction results provide a list of source code artifacts that are prone to defects. Quality assurance teams can effectively devote more energy and allocate limited resources to defect-prone source code verification software products. A module that identifies defect prediction methods for frequent defects before the start of the testing phase. Measurement-based defect-prone modules improve software quality and reduce costs, leading to effective resource allocation. The previous method doesn't analyze the defect pattern, and it has less performance during software development. This work introduces a deep learning-based Pattern-based Modified Hidden Markova Fault Tree (PMHMFT) framework to extract the hidden fault analysis during cross-project validation. The proposed Modified Hidden Markova Fault Tree algorithm constructs the defect fault tree to analyze the cross-project code defect. To prevent defect based on software metrics software prediction model are used. Hidden Markova Fault tree-based classification categorize component as defective and non-defective. Using a Levy flight, optimize the method to search the fault classes efficiently compared to another method. The Markova Fault Tree model construct fault tree based given data; it is easy to identify the fault in software platform. The proposed PMHMFT to implement evaluate the performance using k-fold validation. Thus, the proposed work on software defect prediction achieves higher accuracy in true classification and prediction with less error rate. The software defects are predicted, and these predicted defects are optimized by using Levy flight optimization. Our proposed PMHMFT technique is very useful technique for predicting software defect and gives the better prediction rates in effective manner."
pub.1049568631,The State of the Art in Software Reliability Prediction: Software Metrics and Fuzzy Logic Perspective,"Every day a bulk of software are developed by industries to fulfill the customer and user requirements. Definitely, it has increased the facilities but on the other hand it also increase the probability of errors, faults, failures and also the complexity in the system that subsequently reduces the understandability of the software, make the software more error prone, highly complex and less reliable. As reliability in software based systems is a critical issue, its prediction is of great importance. In this paper, the state of the art in Software Reliability prediction has been presented with two perspectives; Software Metrics and Fuzzy Logic. The overall idea of the paper is to present, analyze, investigate and discuss the various approaches as well as reliability prediction models that are based on either reliability relevant metrics or Fuzzy Logic or both. At the end, paper presents a list of critical findings identified during literature review of various prediction models."
pub.1155451490,Genetic Algorithm-Based Clustering with Neural Network Classification for Software Fault Prediction,"Early prediction of faults enhances software quality and thereby affects the lower cost. However, early prediction of software faults is a crucial task and may lead to the serious issues like underestimation and overestimation. Such misunderstood situations occur when it comes to the predictions of faulty modules during the early stages of the development life cycle. In this direction, a large community of researchers proposed method-level and object-level metrics to achieve project quality. Uncertainty and lack of data availability allowed researchers to perform diverse experimental explorations. Similar project experience developed in the past has played a vital role in analogy-based approaches. Extensive research is carried out on publicly available datasets from the promise repository. In this paper, the authors propose two different methods using an analogy-based approach for fault prediction at early stages. At first, we developed a comprehensive hybrid model integrating genetic algorithm and regression. The second method employs clustering by fusing neural network features for classification with best-fitted reduced parameters that deal with uncertainty. The proposed model achieves 95% accuracy which is better than other considered methods. Experimental design and result findings show validity and phenomenal outcome of proposed methods."
pub.1094342147,Software quality prediction using mixture models with EM algorithm,"The use of the statistical technique of mixture model analysis as a tool for early prediction of fault-prone program modules is investigated. The expectation-maximum likelihood (EM) algorithm is engaged to build the model. By only employing software size and complexity metrics, this technique can be used to develop a model for predicting software quality even without the prior knowledge of the number of faults in the modules. In addition, Akaike Information Criterion (AIC) is used to select the model number which is assumed to be the class number the program modules should be classified. The technique is successful in classifying software into fault-prone and non fault-prone modules with a relatively low error rate, providing a reliable indicator for software quality prediction."
pub.1094125145,Test Effort Optimization by Prediction and Ranking of Fault-prone Software Modules,"Identification of fault-prone or not fault-prone modules is very essential to improve the reliability and quality of a software system. Once modules are categorized as fault-prone or not fault-prone, test effort are allocated accordingly. Testing effort and efficiency are primary concern and can be optimized by prediction and ranking of fault-prone modules. This paper discusses a new model for prediction and ranking of fault-prone software modules for test effort optimization. Model utilizes the classification capability of data mining techniques and knowledge stored in software metrics to classify the software module as fault-prone or not fault-prone. A decision tree is constructed using ID3 algorithm for the existing project data. Rules are derived form the decision tree and integrated with fuzzy inference system to classify the modules as either fault-prone or not fault-prone for the target data. The model is also able to rank the fault-prone module on the basis of its degree of fault-proneness. The model accuracy are validated and compared with some other models by using the NASA projects data set of PROMOSE repository."
pub.1173938167,FSBOA: feature selection using bat optimization algorithm for software fault detection,"Feature selection (FS) plays a crucial role in software fault prediction (SFP), aiming to identify a subset of relevant and discriminative features from a large pool of software metrics. It serves as a critical preprocessing step in building accurate fault prediction models, enabling the identification of potential software faults early in the development life cycle and facilitating effective resource allocation for testing and maintenance activities. The study's objective is to determine how well the bat optimization algorithm (BOA) can extract the features that are most important for correctly predicting software flaws, improve the accuracy of fault prediction, reduce the dimensionality of the feature space, and mitigate the risk of overfitting, thereby enabling more effective resource utilization and better allocation of testing efforts. The forecasting models underwent testing and training utilizing a collection of software metrics, with the datasets undergoing evaluation using several different FS algorithms. An assessment was conducted by contrasting the effectiveness of multiple optimization algorithms, including evolutionary methods such as FS employing genetic algorithm (FSGA), FS employing differential evolution (FSDE), and swarm-based techniques such as FS employing ant colony optimization (FSACO), FS employing particle swarm optimization (FSPSO), FS employing firefly algorithm (FSFA), and FS employing binary grey wolf optimization algorithm (FSBGWO) in relation to FS employing bat optimization algorithm (FSBAO). The results obtained from FSBAO approach demonstrate the effectiveness in solving FS optimization problems with at most accuracy of 98.92%. Furthermore, the experimental results have been statistically validated for the greater efficiency of the proposed FSBAO algorithm. This study's findings have crucial implications for developing a software failure prediction models that is more accurate and efficient."
pub.1153533649,Feature reduction techniques for software bug prediction,"Developing a software entails writing thousands of lines of code. For ensuring quality of the software, this code must be fault free (should perform as it is intended to do). Software faults result in wastage of effort and resources used for developing it. Software bug prediction is a process in the initial period of Software Development Life Cycle (SDLC) which predicts bug-prone modules in a software. Various Machine Learning (ML) methods and feature reduction techniques have been employed for better fault prediction. In this paper six feature reduction techniques have been employed on five software bug datasets of AEEEM software repository in association with random forest-based ensemble classifier. SMOTE and Stratified 10-fold cross validation are used to improve performance of bug prediction model. Three performance metrics (ROC-AUC, F1-Score and accuracy) are ex-tracted for evaluating different dimensions of prediction. Feature agglomeration and Sparse principal component analysis performed better on these datasets for feature reduction."
pub.1024360118,Empirical Evaluation of Hunk Metrics as Bug Predictors,"Reducing the number of bugs is a crucial issue during software development and maintenance. Software process and product metrics are good indicators of software complexity. These metrics have been used to build bug predictor models to help developers maintain the quality of software. In this paper we empirically evaluate the use of hunk metrics as predictor of bugs. We present a technique for bug prediction that works at smallest units of code change called hunks. We build bug prediction models using random forests, which is an efficient machine learning classifier. Hunk metrics are used to train the classifier and each hunk metric is evaluated for its bug prediction capabilities. Our classifier can classify individual hunks as buggy or bug-free with 86 % accuracy, 83 % buggy hunk precision and 77% buggy hunk recall. We find that history based and change level hunk metrics are better predictors of bugs than code level hunk metrics."
pub.1112588385,Software fault prediction based on change metrics using hybrid algorithms: An empirical study,"Quality of the developed software depends on its bug free operation. Although bugs can be introduced in any phase of the software development life-cycle but their identification in earlier phase can lead to reduce the allocation cost of testing and maintenance resources. Software defect prediction studies advocates the use of defect prediction models for identification of bugs prior to the release of the software. Use of bug prediction models can help to reduce the cost and efforts required to develop software. Defect prediction models use the historical data obtained from software projects for training the models and test the model on future release of the software. In the present work, software change metrics have been used for defect prediction. Performances of good machine learning and hybrid algorithms are accessed in prediction of defect with the change metrics. Android project has been used for experimental purpose. Git repository has been used to extract the v4–v5, v2–v5 of android for defect prediction. Obtained results showed that GFS-logitboost-c has best defect prediction capability ."
pub.1137499806,Revisiting the size effect in software fault prediction models,"BACKGROUND: In object oriented (OO) software systems, class size has been
acknowledged as having an indirect effect on the relationship between certain
artifact characteristics, captured via metrics, and faultproneness, and
therefore it is recommended to control for size when designing fault prediction
models. AIM: To use robust statistical methods to assess whether there is
evidence of any true effect of class size on fault prediction models. METHOD:
We examine the potential mediation and moderation effects of class size on the
relationships between OO metrics and number of faults. We employ regression
analysis and bootstrapping-based methods to investigate the mediation and
moderation effects in two widely-used datasets comprising seventeen systems.
RESULTS: We find no strong evidence of a significant mediation or moderation
effect of class size on the relationships between OO metrics and faults. In
particular, size appears to have a more significant mediation effect on CBO and
Fan-out than other metrics, although the evidence is not consistent in all
examined systems. On the other hand, size does appear to have a significant
moderation effect on WMC and CBO in most of the systems examined. Again, the
evidence provided is not consistent across all examined systems CONCLUSION: We
are unable to confirm if class size has a significant mediation or moderation
effect on the relationships between OO metrics and the number of faults. We
contend that class size does not fully explain the relationships between OO
metrics and the number of faults, and it does not always affect the
strength/magnitude of these relationships. We recommend that researchers
consider the potential mediation and moderation effect of class size when
building their prediction models, but this should be examined independently for
each system."
pub.1093313447,A Bayesian Belief Network for Assessing the Likelihood of Fault Content,"To predict software quality, we must consider various factors because software development consists of various activities, which the software reliability growth model (SRGM) does not consider. In this paper, we propose a model to predict the final quality of a software product by using the Bayesian belief network (BBN) model. By using the BBN, we can construct a prediction model that focuses on the structure of the software development process explicitly representing complex relationships between metrics, and handling uncertain metrics, such as residual faults in the software products. In order to evaluate the constructed model, we perform an empirical experiment based on the metrics data collected from development projects in a certain company. As a result of the empirical evaluation, we confirm that the proposed model can predict the amount of residual faults that the SRGM cannot handle."
pub.1093529935,Assessing uncertain predictions of software quality,"Many development organizations try to minimize faults in software as a means for improving customer satisfaction. Assuring high software quality often entails time-consuming and costly development processes. A software quality model based on software metrics can be used to guide enhancement efforts by predicting which modules are fault-prone. The paper presents a way to determine which predictions by a classification tree should be considered uncertain. We conducted a case study of a large legacy telecommunications system. One release was the basis for the training data set, and the subsequent release was the basis for the evaluation data set. We built a classification tree using the TREEDISC algorithm, which is based on chi-squared tests of contingency tables. The model predicted whether a module was likely to have faults discovered by customers, or not, based on software product, process, and execution metrics. We simulated practical use of the model by classifying the modules in the evaluation data set. The model achieved useful accuracy, in spite of the very small proportion of fault-prone modules in the system. We assessed whether the classes assigned to the leaves were appropriate by examining the details of the full tree, and found sizable subsets of modules with substantially uncertain classification. Discovering which modules have uncertain classifications allows sophisticated enhancement strategies to resolve uncertainties. Moreover, TREEDISC is especially well suited to identifying uncertain classifications."
pub.1162721691,A Comparative Study of Wrapper Feature Selection Techniques in Software Fault Prediction,"Abstract
Software fault prediction aims to classify whether the module is defective or not-defective. In software systems, there are some software metrics may contain irrelevant or redundant information that leads to negative impact on the performance of the fault prediction model. Therefore, feature selection is an method that several studies have addressed to reduce computation time, improve prediction performance and provide a better understanding of data in machine learning. Additionally, the presence of imbalanced classes is one of the most challenge in software fault prediction. In this study, we examined the effectiveness of six different wrapper feature selection including Genetic Algorithm, Particle Swarm Optimization, Whale Optimization Algorithm, Cuckoo Search, Mayfly Algorithm and Binary Bat Algorithm for selecting the optimal subset of features. Then, we applied VanilaGAN to train the dataset with optimal features for handling the imbalanced problem. Subsequently, these generated training dataset and the testing dataset are fed to the machine learning techniques. Experimental validation has been done on five dataset collected from Promise repository and Precision, Recall, F1-score, and AUC are evaluation performance measurements."
pub.1148660262,Empirical Investigation of role of Meta-learning approaches for the Improvement of Software Development Process via Software Fault Prediction,"Context: Software Engineering (SE) community has empirically investigated software defect prediction as a proxy to benchmark it as a process improvement activity to assure software quality. In the domain of software fault prediction, the performance of classification algorithms is highly provoked with the residual effects attributed to feature irrelevance and data redundancy issues. Problem: The meta-learning-based ensemble methods are usually carried out to mitigate these noise effects and boost the software fault prediction performance. However, there is a need to benchmark the performance of meta-learning ensemble methods (as fault predictor) to assure software quality control and aid developers in their decision making. Method: We conduct an empirical and comparative study to evaluate and benchmark the improvement in the fault prediction performance via meta-learning ensemble methods as compared to their component base-level fault predictors. In this study, we perform a series of experiments with four well-known meta-level ensemble methods Vote, StackingC (i.e., Stacking), MultiScheme, and Grading. We also use five high-performance fault predictors Logistic (i.e., Logistic Regression), J48 (i.e., Decision Tree), IBK (i.e. k-nearest neighbor), NaiveBayes, and Decision Table (DT). Subsequently, we performed these experiments on public defect datasets with k-fold (k=10) cross-validation. We used F-measure and ROC-AUC (Receiver Operating Characteristic-Area Under Curve) performance measures and applied the four non-parametric tests to benchmark the fault prediction performance results of meta-learning ensemble methods. Results and Conclusion: we conclude that meta-learning ensemble methods, especially Vote could outperform the base-level fault predictors to tackle the feature irrelevance and redundancy issues in the domain of software fault prediction. Having said that, their performance is highly related to the number of base-level classifiers and the set of software fault prediction metrics."
pub.1120970623,Software Development Metrics Prediction Using Time Series Methods,"The software development process is an intricate task, with the growing complexity of software solutions and inflating code-line count being part of the reason for the fall of software code coherence and readability thus being one of the causes for software faults and it’s declining quality. Debugging software during development is significantly less expensive than attempting damage control after the software’s release. An automated quality-related analysis of developed code, which includes code analysis and correlation of development data like an ideal solution. In this paper the ability to predict software faults and software quality is scrutinized. Hereby we investigate four models that can be used to analyze time-based data series for prediction of trends observed in the software development process are investigated. Those models are Exponential Smoothing, the Holt-Winters Model, Autoregressive Integrated Moving Average (ARIMA) and Recurrent Neural Networks (RNN). Time-series analysis methods prove a good fit for software related data prediction. Such methods and tools can lend a helping hand for Product Owners in their daily decision-making process as related to e.g. assignment of tasks, time predictions, bugs predictions, time to release etc. Results of the research are presented."
pub.1062978841,A COMPARATIVE STUDY OF FILTER-BASED AND WRAPPER-BASED FEATURE RANKING TECHNIQUES FOR SOFTWARE QUALITY MODELING,"Data mining techniques have been effectively used for software defect prediction in the last decade. The general process is that a classifier is first trained on historical software data (software metrics and fault data) collected during the software development process and then the classifier is used to predict new program modules (waiting for testing) as either fault-prone or not-fault-prone. The performance of the classifier is influenced by two factors: the software metrics in the training dataset and the proportions of the fault-prone and not-fault-prone modules in that dataset. When a dataset contains too many software metrics and/or very skewed proportions of the two types of modules, several problems may arise including extensive computation and a decline in predictive performance. In this paper, we use feature ranking and data sampling to deal with these problems. We investigate two types of feature ranking techniques (wrapper-based and filter-based), and compare their performances through two case studies on two groups of software measurement datasets. The empirical results demonstrate that filter-based ranking techniques not only show better classification performance but also have a lower computational cost."
pub.1094726488,Validating the Effectiveness of Object-Oriented Metrics over Multiple Releases for Predicting Fault Proneness,"In this paper, we empirically investigate the relationship of existing class level object-oriented metrics with fault proneness over the multiple releases of the software. Here we first, evaluate each metric for their potential to predict faults independently by performing univariate logistic regression analysis. Next, we perform cross-correlation analysis between the significant metrics to find the subset of these metrics for an improved performance. The obtained metrics subset was then used to predict faults over the subsequent releases of the same project datasets. In this study, we used five publicly available project datasets over their multiple successive releases. Our results reported that the identified subset metrics demonstrated an improved fault prediction with higher accuracy and reduced misclassification errors."
pub.1023012456,Evaluating the applicability of reliability prediction models between different software,"The prediction of fault-prone modules in a large software system is an important part in software evolution. Since prediction models in past studies have been constructed and used for individual systems, it has not been practically investigated whether a prediction model based on one system can also predict fault-prone modules accurately in other systems. Our expectation is that if we could build a model applicable to different systems, it would be extremely useful for software companies because they do not need to invest manpower and time for gathering data to construct a new model for every system.In this study, we evaluated the applicability of prediction models between two software systems through two experiments. In the first experiment, a prediction model using 19 module metrics as predictor variables was constructed in each system and was applied to the opposite system mutually. The result showed predictors were too fit to the base data and could not accurately predict fault-prone modules in the different system. On the basis of this result, we focused on a set of predictors showing great effectiveness in every model; and, in consequent, we identified two metrics (Lines of Code and Maximum Nesting Level) as commonly effective predictors in all the models. In the second experiment, by constructing prediction models using only these two metrics, prediction performance were dramatically improved. This result suggests that the commonly effective model applicable to more than two systems can be constructed by focusing on commonly effective predictors."
pub.1119982109,Software Fault Proneness Prediction Using Genetic Based Machine Learning Techniques,"This work is an attempt to propose a software replica to predict fault proneness by means of genetic based method implementing machine learning. The underlying method is collection of data from open source software, where the data will be in form of object oriented metrics. The said data would be used to create model for forecasting the faults. These techniques are known as genetic based Classifier Systems or learning classifier systems. Later in this work, there is in detail description about data collection technique and stepwise algorithm to get the results. In the end it can be concluded that these techniques can be used to make prediction model on object oriented data of software and can be useful pertaining to fault proneness prediction in the near the beginning stages in the development sequence. of any software (SDLC)"
pub.1083877254,Differential analysis of token metric and object oriented metrics for fault prediction,"Due to the scarcity of resources, testing of each module is not possible for large projects. Thus, calculation of fault prone modules can be used for better resource utilization. A proposed token metric and the available object oriented metrics for forecasting the fault prone modules of an open source project has been proposed. The results from both set of metrics are compared to assess the effectiveness of the planned approach. The results concluded that (1) the proposed metric can be utilized for the calculation of fault prone modules with equivalent accuracy as in the case of object oriented metrics; (2) the token metric and object oriented metrics show opposite trends of results in precision and recall; (3) the proposed metric is much better for projects involving high risks."
pub.1151161640,Software Reliability: Development of Software Defect Prediction Models Using Advanced Techniques,"Development of next generation of smarter machines and services requires building an easy-to-use technology stack. These technologies include hardware, embedded software, data, and applications. Smarter machines support carrying out the precise job, better decision making, and create new ways of doing things to reduce cost and increase speed, accuracy, and automation. As technology meets iron through smart machines, there is increased embedded software within products. To provide distinctive customer experience for a solution system, along with reliability of hardware, development of reliable software also plays a critical role. This paper proposes models in which software reliability is a function of the number of residual faults and is measured with the help of software metrics based on development data. The intent is to establish a statistical relationship between product metrics (that deal with the measurement of the software product) or process metrics (the process by which it is developed) with measures of quality. Using both a pattern recognition algorithm approach for classifying fault proneness and applying fuzzy logic to software metrics for defect prediction is found to be beneficial for improving software reliability prediction in early development phases. This paper proposes non-parametric models like Artificial Neural Network from deep learning to predict expected number of failures utilizing past failure data for software reliability estimation and release readiness during launch."
pub.1171406614,Software Fault Prediction Using Cross-Project Analysis: A Study on Class Imbalance and Model Generalization,"Software fault prediction is a critical aspect of software engineering aimed at improving software quality and reliability. However, it faces significant challenges, including the class imbalance issue in fault data and the need for robust predictive models that generalize well across different projects. In this research, we delve into these challenges and investigate the impact of class imbalance and model generalization on software fault prediction using cross-project analysis. Our study addresses three primary research questions: Firstly, we examine the critical issue of class imbalance in fault prediction, which poses a significant hurdle to accurate model performance. Through extensive experimentation with various classifiers on diverse datasets from different software projects, we highlight the variations in classifier performance and the necessity of addressing class imbalance for reliable predictions. Secondly, we evaluate the reliability of cross-project prediction, aiming to understand how effectively predictive models trained on one project can generalize to predict faults in other projects. We demonstrate the importance of training with datasets sharing similar characteristics with the target project for achieving reliable cross-project prediction. Thirdly, we analyze the impact of increasing training samples from different projects on prediction accuracy, emphasizing the benefits of utilizing cross-project analysis to enhance predictive model performance. In addition to addressing these research questions, we provide a comprehensive comparison of classifier performance metrics, including accuracy, precision, recall, and F1 Score. Our findings not only shed light on the challenges and opportunities in software fault prediction but also emphasize the importance of considering class imbalance and model generalization for developing robust and reliable fault prediction models. This research contributes to advancing the field by providing insights into effective modeling approaches and highlighting the motivation behind addressing these challenges."
pub.1015640784,Fuzzy inferencing to identify degree of interaction in the development of fault prediction models,"The software fault prediction models, based on different modeling techniques have been extensively researched to improve software quality for the last three decades. Out of the analytical techniques used by the researchers, fuzzy modeling and its variants are bringing out a major share of the attention of research communities. In this work, we demonstrate the models developed through data driven fuzzy inference system. A comprehensive set of rules induced by such an inference system, followed by a simplification process provides deeper insight into the linguistically identified level of interaction. This work makes use of a publicly available data repository for four software modules, advocating the consideration of compound effects in the model development, especially in the area of software measurement.One related objective is the identification of influential metrics in the development of fault prediction models. A fuzzy rule intrinsically represents a form of interaction between fuzzified inputs. Analysis of these rules establishes that Low and NOT (High) level of inheritance based metrics significantly contributes to the F-measure estimate of the model. Further, the Lack of Cohesion of Methods (LCOM) metric was found insignificant in this empirical study."
pub.1052265779,Software defect prediction using semi-supervised learning with dimension reduction,"Accurate detection of fault prone modules offers the path to high quality software products while minimizing non essential assurance expenditures. This type of quality modeling requires the availability of software modules with known fault content developed in similar environment. Establishing whether a module contains a fault or not can be expensive. The basic idea behind semi-supervised learning is to learn from a small number of software modules with known fault content and supplement model training with modules for which the fault information is not available. In this study, we investigate the performance of semi-supervised learning for software fault prediction. A preprocessing strategy, multidimensional scaling, is embedded in the approach to reduce the dimensional complexity of software metrics. Our results show that the semi-supervised learning algorithm with dimension-reduction preforms significantly better than one of the best performing supervised learning algorithms, random forest, in situations when few modules with known fault content are available for training."
pub.1175433647,A holistic approach to software fault prediction with dynamic classification,"Software Fault Prediction is a critical domain in machine learning aimed at pre-emptively identifying and mitigating software faults. This study addresses challenges related to imbalanced datasets and feature selection, significantly enhancing the effectiveness of fault prediction models. We mitigate class imbalance in the Unified Dataset using the Random-Over Sampling technique, resulting in superior accuracy for minority-class predictions. Additionally, we employ the innovative Ant-Colony Optimization algorithm (ACO) for feature selection, extracting pertinent features to amplify model performance. Recognizing the limitations of individual machine learning models, we introduce the Dynamic Classifier, a ground-breaking ensemble that combines predictions from multiple algorithms, elevating fault prediction precision. Model parameters are fine-tuned using the Grid-Search Method, achieving an accuracy of 94.129% and superior overall performance compared to random forest, decision tree and other standard machine learning algorithms. The core contribution of this study lies in the comparative analysis, pitting our Dynamic Classifier against Standard Algorithms using diverse performance metrics. The results unequivocally establish the Dynamic Classifier as a frontrunner, highlighting its prowess in fault prediction. In conclusion, this research introduces a comprehensive and innovative approach to software fault prediction. It pioneers the resolution of class imbalance, employs cutting-edge feature selection, and introduces dynamic ensemble classifiers. The proposed methodology, showcasing a significant advancement in performance over existing methods, illuminates the path toward developing more accurate and efficient fault prediction models."
pub.1093352764,A Network Clustering Based Software Attribute Selection for Identifying Fault-Prone Modules,"The software defect can damage the reliability and the quality of the software. The static code software metrics have been widely used and played an important role in software defect prediction. Instead of using whole features, it is quite necessary to remove the redundant features and select some meaningful features to improve the prediction performance. This study focuses on the effective attribute selection technique for the software fault classification. We proposed the software attributes network that indicates the mutual information between features and the clustering based attribute selection techniques. The results demonstrate that the proposed network clustering based feature selection performs the best on fault-prone modules prediction. The comparative feature selection techniques are examined to evaluate the result. Furthermore, the best-performed software attributes and the relations between them are shown and carefully analyzed."
pub.1094314855,The Impact of Coupling on the Fault-Proneness of Aspect-Oriented Programs: An Empirical Study,"Coupling in software applications is often used as an indicator of external quality attributes such as fault-proneness. In fact, the correlation of coupling metrics and faults in object-oriented programs has been widely studied. However, there is very limited knowledge about which coupling properties in aspect-oriented programming (AOP) are effective indicators of faults in modules. Existing coupling metrics do not take into account the specificities of AOP mechanisms. As a result, these metrics are unlikely to provide optimal predictions of pivotal quality attributes such as fault-proneness. This impacts further by restraining the assessments of AOP empirical studies. To address these issues, this paper presents an empirical study to evaluate the impact of coupling sourced from AOP-specific mechanisms. We utilise a novel set of coupling metrics to predict fault occurrences in aspect-oriented programs. We also compare these new metrics against previously proposed metrics for AOP. More specifically, we analyse faults from several releases of three AspectJ applications and perform statistical analyses to reveal the effectiveness of these metrics when predicting faults. Our study shows that a particular set of fine-grained directed coupling metrics have the potential to help create better fault prediction models for AO programs."
pub.1163385006,Analysis of Different Sampling Techniques for Software Fault Prediction,"The process of predicting whether or not a software module is faulty based on specific metrics is known as software fault prediction. Software faults predicted in prior stages help in the management of resources and time required during software testing and maintenance. Over the years, various supervised machine learning-based techniques for fault prediction have been suggested. The models are trained using a labeled dataset that consists of multiple independent variables like lines of codes, the complexity of the software, the size of the software, etc., and a dependent binary variable that is either true or false. Recent research in software fault prediction focuses on data quality. In this paper, we have mainly focused on the class imbalance problem. In imbalanced data, one of the class labels has a higher number of observations, while the other class label has a lower number of observations. Different over-sampling and under-sampling techniques are used to tackle the class imbalance problem. In this paper, random under-sampling, random over-sampling, and SMOTE are applied to six PROMISE datasets. A decision tree classifier is used to create the model. The efficiency of different sampling techniques is compared using the ROC-AUC score and F1-score."
pub.1150158499,Static code metrics-based deep learning architecture for software fault prediction,"Software fault prediction (SFP) refers to the early prediction of fault-prone modules in software development which are susceptible to faults and can incur high development cost. Machine learning (ML)-based classifiers are extensively being used for SFP. Machine learning models utilize handcrafted metrics (or features), i.e., static code metrics for classification of software modules into one of the two categories, i.e., {buggy, clean}. It involves overhead of selecting the most significant features due to the presence of some correlated or non-significant features. With the shifting paradigm of machine learning to deep learning, it is desirable to improve the performance of SFP classifiers to keep pace up with the changing industrial needs. This study proposes a novel model (SCM-DLA-SFP) based on deep learning architecture (DLA) to predict the defects utilizing the static code metrics (SCMs). The defect dataset with SCMs is fed to the input layer of specially designed deep learning model, where the input is automatically conditioned using normalization. Then, the conditioned data pass through dense layers of deep neural network architecture to predict the faulty modules. The study utilizes five datasets from PROMISE repository namely camel, jedit, lucene, synapse and xalan. The proposed model SCM-DLA-SFP exhibits the performance of the average values of 88.01%, 79.83%, and 73.3% for AUC measure, accuracy criteria and F-measure, respectively. The comparison shows that proposed model is better on average than the state-of-the-art DL-based SFP methods by 16.28%, 19.61%, and 18.45% over AUC, accuracy and F-measure, respectively."
pub.1018958160,Comparison of M5’ Model Tree with MLR in the Development of Fault Prediction Models Involving Interaction Between Metrics,"Amongst the critical actions needed to be undertaken before system testing, software fault prediction is imperative. Prediction models are used to identify fault-prone classes and contribute considerably to reduce the testing time, project risks, and resource and infrastructure costs. In the development of a prediction model, the interaction of metrics results in an improved predictive capability, accruing to the fact that metrics are often correlated and do not have a strict additive effect in a regression model.Even though the interaction amongst metrics results in the model’s improved prediction capability, it also gives rise to a large number of predictors. This leads to Multiple Linear Regression (MLR) exhibiting a reduced level of performance, since a single predictive formula occupies the entire data space. The M5’ model tree has an edge over MLR in managing such interactions, by partitioning the data space into smaller regions.The resulting hypothesis empirically establish that the M5’ model tree, when applied to these interactions, provides a greater degree of accuracy and robustness of the model as a whole when compared with MLR models."
pub.1100857480,Software defect prediction techniques using metrics based on neural network classifier,"Software industries strive for software quality improvement by consistent bug prediction, bug removal and prediction of fault-prone module. This area has attracted researchers due to its significant involvement in software industries. Various techniques have been presented for software defect prediction. Recent researches have recommended data-mining using machine learning as an important paradigm for software bug prediction. state-of-art software defect prediction task suffer from various issues such as classification accuracy. However, software defect datasets are imbalanced in nature and known fault prone due to its huge dimension. To address this issue, here we present a combined approach for software defect prediction and prediction of software bugs. Proposed approach delivers a concept of feature reduction and artificial intelligence where feature reduction is carried out by well-known principle component analysis (PCA) scheme which is further improved by incorporating maximum-likelihood estimation for error reduction in PCA data reconstruction. Finally, neural network based classification technique is applied which shows prediction results. A framework is formulated and implemented on NASA software dataset where four datasets i.e., KC1, PC3, PC4 and JM1 are considered for performance analysis using MATLAB simulation tool. An extensive experimental study is performed where confusion, precision, recall, classification accuracy etc. parameters are computed and compared with existing software defect prediction techniques. Experimental study shows that proposed approach can provide better performance for software defect prediction."
pub.1095370130,Predicting fault detection effectiveness,"Regression methods are used to model software fault detection effectiveness in terms of several product and testing process measures. The relative importance of these product/process measures for predicting fault detection effectiveness is assessed for a specific data set. A substantial family of models is considered, specifically, the family of quadratic response surface models with two way interaction. Model selection is based on ""leave one out at a time"" cross validation using the predicted residual sum of squares (PRESS) criterion. Prediction intervals for fault detection effectiveness are used to generate prediction intervals for the number of residual faults conditioned on the observed number of discovered faults. High levels of assurance about measures like fault detection effectiveness (residual faults) require more than just high (low) predicted values, they also require that the prediction intervals have high lower (low upper) bounds."
pub.1036652340,Software Quality Prediction based on Defect Severity,"Most of the software fault prediction studies focused on the binary classification model that predicts whether an input entity has faults or not. However the ability to predict entity fault-proneness in various severity categories is more useful because not all faults have the same severity. In this paper, we propose fault prediction models at different severity levels of faults using traditional size and complexity metrics. They are ternary classification models and use four machine learning algorithms for their training. Empirical analysis is performed using two NASA public data sets and a performance measure, accuracy. The evaluation results show that backpropagation neural network model outperforms other models on both data sets, with about 81% and 88% in terms of accuracy score respectively."
pub.1031331254,Empirical validation of object-oriented metrics for predicting fault proneness at different severity levels using support vector machines,"Empirical validation of software metrics to predict quality using machine learning methods is important to ensure their practical relevance in the software organizations. It would also be interesting to know the relationship between object-oriented metrics and fault proneness at different severity levels. In this paper, we build a Support vector machine (SVM) model to find the relationship between object-oriented metrics given by Chidamber and Kemerer and fault proneness, at different severity levels. The proposed models at different severity levels are empirically evaluated using public domain NASA data set. The performance of the SVM method was evaluated by receiver operating characteristic (ROC) analysis. Based on these results, it is reasonable to claim that such models could help for planning and performing testing by focusing resources on fault-prone parts of the design and code. The performance of the model predicted using high severity faults is low as compared to performance of the model predicted with respect to medium and low severity faults. Thus, the study shows that SVM method may also be used in constructing software quality models. However, similar types of studies are required to be carried out in order to establish the acceptability of the model."
pub.1094254989,Automated Software Fault-Proneness Prediction Based on Fuzzy Inference System,"The identification of a module's fault-proneness is very important for minimizing cost and improving the effectiveness of the software development process. How to obtain the correlation between inspection metrics and module's fault-proneness, hiding in the observed data, has been focused by very researches. In this paper, we propose the use of a fuzzy inference system for this purpose. In order to empirically evaluate the effectiveness of proposed approach, we apply it on empirical data published by Ebenau and NASA's Metrics Data Program data repository, respectively. Experiments results confirm that proposed approach is very effective for establishing relationship between inspection metrics and fault-proneness, and that its implementation don't require neither extra cost nor expert's knowledge, and it is completely automated. Novel approach can provide software project managers with reasonably suggestion and much-needed insights."
pub.1093487737,Comparing Fault-Proneness Estimation Models,"Over the last years, software quality has become one of the niost important requirement in the development of systems. Fault-proneness estimation could play a key role in quality control of software products. In this area. much effort has been spent in defining nietrics and identifying models for system assessment Using these nietrics to assess which parts of the system are more fault-proneness is of primary importance. This paper reports a research study begun with the analysis of more than 100 metrics and aimed at. producing suitable models for fault-proneness estimation and prediction of software modules/files. The objective has been to find a compromise between the fault-proneness estimation rate and the size of the estimation model in terms of number of metrics used in the model itself To this end, two different methodologies have been used. compared, and some synergies exploited. The methodologies were the logistic regression and the discriminant analyses The corresponding models produced for fault-proneness estimation and prediction have been based on nietrics addressing different aspects of computer programming The comparison has produced satisfactory results in terms of fault-proneness prediction The produced models hate been cross validated by using data sets derived from source codes provided by two application scenarios"
pub.1172852209,WSO-KELM: War Strategy Optimization-Based Kernel Extreme Learning Machine for Automatic Software Fault Prediction Model,"The software development projects’ testing part is usually expensive and complex, but it is essential to gauge the effectiveness of the developed software. Software Fault Prediction (SFP) primarily serves to detect faults within software components. The scale of software projects is getting larger, making it impossible and time-consuming to analyze the flaws manually. Artificial Intelligence (AI) techniques are mainly incorporated to solve this problem. The massive data retrieved from the software repositories helps in identifying the features that are highly correlated with fault prediction and the features that are not. This paper introduces a Kernel Extreme Learning Machine (KELM) for SFP. To optimize the hyperparameters of the classifier and also enhance the classification accuracy, the War Strategy Optimization (WSO) algorithm is employed here. The experimental evaluations are conducted using different baseline actual-world datasets of software programs such as Java-coded open-source and PROMISE datasets. The experimental outcomes are conducted using different performance metrics that include sensitivity, Accuracy, and F1-score with values of 0.96%, 0.97%, and 0.96%, respectively. The results show that KELM is beneficial, and the optimization provided by the WSO algorithm also helps us obtain higher classification accuracy for the SFP problem and improve the fault detection process."
pub.1047001644,Experience in Predicting Fault-Prone Software Modules Using Complexity Metrics,"Complexity metrics have been intensively studied in predicting fault-prone software modules. However, little work is done in studying how to effectively use the complexity metrics and the prediction models under realistic conditions. In this paper, we present a study showing how to utilize the prediction models generated from existing projects to improve the fault detection on other projects. The binary logistic regression method is used in studying publicly available data of five commercial products. Our study shows (1) models generated using more datasets can improve the prediction accuracy but not the recall rate; (2) lowering the cut-off value can improve the recall rate, but the number of false positives will be increased, which will result in higher maintenance effort. We further suggest that in order to improve model prediction efficiency, the selection of source datasets and the determination of cut-off values should be based on specific properties of a project. So far, there are no general rules that have been found and reported to follow."
pub.1165283047,Software fault prediction with imbalanced datasets using SMOTE-Tomek sampling technique and Genetic Algorithm models,"Over the years, there has been a considerable discussion regarding machine learning (ML) techniques to forecast software faults. It can be challenging to choose a suitable machine learning technique for fault prediction modelling because of variations in the prediction performance of machine learning techniques for software systems. The evaluation of previously presented software fault prediction (SFP) approaches revealed that single machine learning-based models that did not deliver the best accuracy and F1-Score in any context, emphasizing the need to use multiple techniques, such as sampling and selection, in addition to the application of machine learning models. In order to address this issue, we present and discuss a method for predicting software faults that rely on choosing the most suitable machine learning and deep learning techniques from a pool of accurate and competitive learning techniques in order to construct a fault prediction model. The presented approach chooses the best features using Mutual Information feature selection technique. Using a hybrid sampling (SMOTE-Tomek) techniques, the issue of class imbalance (CI) is addressed. Then finally a Genetic Algorithm based machine learning (GA-DT) and a deep learning model (ANN-DT) are developed for the purpose for predicting faults in a software. For empirical evaluation, Eclipse version dataset (2.0, 2.1, and 3.0) is considered. Precision, recall, accuracy, and f1-Score are the performance metrics we used to evaluate the effectiveness of the proposed approach. The results demonstrated that the proposed approach (GA-DT and ANN-DT) effectively predicted the software's faults with ANN-DT providing best accuracies for all the three versions of Eclipse dataset."
pub.1018239827,An Empirical Study of the Effect of Power Law Distribution on the Interpretation of OO Metrics,"
                    Context
                    . Software metrics are surrogates of software quality. Software metrics can be used to find possible problems or chances for improvements in software quality. However, software metrics are numbers that are not easy to interpret. Previous analysis of software metrics has shown fat tails in the distribution. The skewness and fat tails of such data are properties of many statistical distributions and more importantly the phenomena of the power law. These statistical properties affect the interpretation of software quality metrics.
                    Objectives
                    . The objective of this research is to validate the effect of power laws on the interpretation of software metrics.
                    Method
                    . To investigate the effect of power law properties on software quality, we study five open-source systems to investigate the distribution and their effect on fault prediction models.
                    Results
                    . Study shows that power law behavior has an effect on the interpretation and usage of software metrics and in particular the CK metrics. Many metrics have shown a power law behavior. Threshold values are derived from the properties of the power law distribution when applied to open-source systems.
                    Conclusion
                    . The properties of a power law distribution can be effective in improving the fault-proneness models by setting reasonable threshold values.
                  "
pub.1015177486,Prediction of Run-Time Failures Using Static Product Quality Metrics,"A study is presented in which it is determined whether software product metrics gathered statically from designs or source code may be helpful in predicting the number of run-time faults that will be encountered during execution. Metrics examined include intermodule metrics such as fan-in and fan-out, as well as intramodule metrics such as cyclomatic complexity and size. Our study indicates that it may be possible, with certain classes of software products, to predict the run-time behaviour using well-known static intermodule metrics."
pub.1165276961,Software Reliability Prediction using Correlation Constrained Multi-Objective Evolutionary Optimization Algorithm,"Software reliability frameworks are extremely effective for estimating the probability of software failure over time. Numerous approaches for predicting software dependability were presented, but neither of those has shown to be effective. Predicting the number of software faults throughout the research and testing phases is a serious problem. As there are several software metrics such as object-oriented design metrics, public and private attributes, methods, previous bug metrics, and software change metrics. Many researchers have identified and performed predictions of software reliability on these metrics. But none of them contributed to identifying relations among these metrics and exploring the most optimal metrics. Therefore, this paper proposed a correlation- constrained multi-objective evolutionary optimization algorithm (CCMOEO) for software reliability prediction. CCMOEO is an effective optimization approach for estimating the variables of popular growth models which consists of reliability. To obtain the highest classification effectiveness, the suggested CCMOEO approach overcomes modeling uncertainties by integrating various metrics with multiple objective functions. The hypothesized models were formulated using evaluation results on five distinct datasets in this research. The prediction was evaluated on seven different machine learning algorithms i.e., linear support vector machine (LSVM), radial support vector machine (RSVM), decision tree, random forest, gradient boosting, k-nearest neighbor, and linear regression. The result analysis shows that random forest achieved better performance."
pub.1114352478,Using Tri-Relation Networks for Effective Software Fault-Proneness Prediction,"Software modules and developers are two core elements during the process of software development. Previous studies have shown that analyzing relations between 1) software modules; (2) developers; and (3) modules and developers, is critical to understand how they interact with each other, which ultimately affects software quality. Specifically, relations such as developer contribution relation, module dependency relation, and developer collaboration relation have been used independently or in pairs to build networks for software fault-proneness prediction. However, none of them investigate the joint effort of these three relations. Bearing this in mind, in this paper, we propose a tri-relation network, a weighted network that integrates developer contribution, module dependency, and developer collaboration relations to study their combined impact on software quality. Four network node centrality metrics are further derived from the proposed network to predict the fault-proneness of a given software module at the file level. Moreover, we have explored a mechanism to refine current networks in order to further improve the effectiveness of software fault-proneness prediction."
pub.1160028176,Predictive software maintenance utilizing cross-project data,"To improve the software quality and reduce the maintenance cost, cross-project fault prediction (CPFP) identifies faulty software components in a particular project (aka target project) using the historical fault data of other projects (aka source/reference projects). Although several diverse approaches/models have been proposed in the past, there exists room for improvement in the prediction performance. Further, they did not consider effort-based evaluation metrics (EBEMs), which are important to ensure the model’s application in the industry, undertaking a realistic constraint of having a limited inspection effort. Besides, they validated their respective approaches using a limited number of datasets. Addressing these issues, we propose an improved CPFP model with its validation on a large corpus of data containing 62 datasets in terms of EBEMs (PIM@20%, Cost-effectiveness@20%, and IFA) and other machine learning-based evaluation metrics (MLBEMs) like PF, G-measure, and MCC. The reference data and the target data are first normalized to reduce the distribution divergence between them and then the relevant training data is selected from the reference data using the KNN algorithm. Seeing the experimental and statistical test results, we claim the efficacy of our proposed model over state-of-the-art CPFP models namely the Turhan-Filter and Cruz model comprehensively. Thus, the proposed CPFP model provides an effective solution for predicting faulty software components, enabling practitioners in developing quality software with lesser maintenance cost."
pub.1142575981,Just-in-time software defect prediction using deep temporal convolutional networks,"Software maintenance and evolution can introduce defects in software systems. For this reason, there is a great interest to identify defect prediction and estimation techniques. Recent research proposes just-in-time techniques to predict defective changes just at the commit level allowing the developers to fix the defect when it is introduced. However, the performance of existing just-in-time defect prediction models still requires to be improved. This paper proposes a new approach based on a large feature set containing product and process software metrics extracted from commits of software projects along with their evolution. The approach also introduces a deep temporal convolutional networks variant based on hierarchical attention layers to perform the fault prediction. The proposed approach is evaluated on a large dataset, composed of data gathered from six Java open-source systems. The obtained results show the effectiveness of the proposed approach in timely predicting defect proneness of code components."
pub.1151644941,A Bibliometric Analysis of Fault Prediction System using Machine Learning Techniques,"Fault prediction in software is an important aspect to be considered in software development because it ensures reliability and the quality of a software product. A high-quality software product consists of a few numbers of faults and failures. Software fault prediction (SFP) is crucial for the software quality assurance process as it examines the vulnerability of software products towards failures. Fault detection is a significant aspect of cost estimation in the initial stage, and hence, a fault predictor model is required to lower the expenses used during the development and maintenance phase. SFP is applied to identify the faulty modules of the software in order to complement the development as well as the testing process. Software metric based fault prediction reflects several aspects of the software. Several Machine Learning (ML) techniques have been implemented to eliminate faulty and unnecessary data from faulty modules. This chapter gives a brief introduction to SFP and includes a bibliometric analysis. The objective of the bibliometric analysis is to analyze research trends of ML techniques that are used for predicting software faults. This chapter uses the VOSviewer software and Biblioshiny tool to visually analyze 1623 papers fetched from the Scopus database for the past twenty years. It explores the distribution of publications over the years, top-rated publishers, contributing authors, funding agencies, cited papers and citations per paper. The collaboration of countries and cooccurrence analysis as well as over the year’s trend of author keywords are also explored. This chapter can be beneficial for young researchers to locate attractive and relevant research insights within SFP."
pub.1004373061,An Integrated Approach to Detect Fault-Prone Modules Using Complexity and Text Feature Metrics,"Early detection of fault-prone products is necessary to assure the quality of software product. Therefore, fault-prone module detection is one of the major and traditional area of software engineering. Although there are many approaches to detect fault-prone modules, they have their own pros and cons. Consequently, it is recommended to use appropriate approach on the various situations. This paper tries to show an integrated approach using two different fault-prone module detection approaches.To do so, we prepare two approaches of fault-prone module detection: a text feature metrics based approach using naive Bayes classifier and a complexity metrics based approach using logistic regression. The former one is proposed by us and the latter one is widely used approach. For the data for application, we used data obtained from Eclipse, which is publicly available.From the result of pre-experiment, we find that each approach has the pros and cons. That is, the text feature based approach has high recall, and complexity metrics based approach has high precision. In order to use their merits effectively, we proposed an integrated approach to apply these two approaches for fault-prone module detection. The result of experiment shows that the proposed approach shows better accuracy than each approach."
pub.1169514273,Developing a Machine Learning-Based Software Fault Prediction Model Using the Improved Whale Optimization Algorithm †,"Software fault prediction (SFP) is vital for ensuring software system reliability by detecting and mitigating faults. Machine learning has proven effective in addressing SFP challenges. However, extensive fault data from historical repositories often lead to dimensionality issues due to numerous metrics. Feature selection (FS) helps mitigate this problem by identifying key features. This research enhances the Whale Optimization Algorithm (WOA) by combining truncation selection with a single-point crossover method to enhance exploration and avoid local optima. Evaluating the enhancement on 14 SFP datasets from the PROMISE repository reveals its superiority over the original WOA and other variants, demonstrating its potential for improved SFP."
pub.1094878684,An Investigation of the Effect of Discretization on Defect Prediction Using Static Measures,"Software repositories with defect logs are main resource for defect prediction. In recent years, researchers have used the vast amount of data that is contained by software repositories to predict the location of defect in the code that caused problems. In this paper we evaluate the effectiveness of software fault prediction with Naive-Bayes classifiers and J48 classifier by integrating with supervised discretization algorithm developed by Fayyad and Irani. Public datasets from the promise repository have been explored for this purpose. The repository contains software metric data and error data at the function/method level. Our experiment shows that integration of discretization method improves the software fault prediction accuracy when integrated with Naive-Bayes and J48 classifiers."
pub.1094487309,Fault Prediction Model for Software Using Soft Computing Techniques,"Faulty modules of any software can be problematic in terms of accuracy, hence may encounter more costly redevelopment efforts in later phases. These problems could be addressed by incorporating the ability of accurate prediction of fault prone modules in the development process. Such ability of the software enables developers to reduce the faults in the whole life cycle of software development, at the same time it benefits automation process, and reduces the overall cost and efforts of the software maintenance. In this paper, we propose to design fault prediction model by using a set of code and design metrics; applying various machine learning (ML) classifiers; also used transformation techniques for feature reduction and dealing class imbalance data to improve fault prediction model. The data sets were obtained from publicly available PROMISE repositories. The results of the study revealed that there was no significant impact on the ability to accurately predict the fault-proneness of modules by applying PCA in reducing the dimensions; the results were improved after balancing data by SMOTE, Resample techniques, and by applying PCA with Resample in combination. It has also been seen that Random Forest, Random Tree, Logistic Regression, and Kstar machine learning classifiers have relatively better consistency in prediction accuracy as compared to other techniques."
pub.1086171208,Software reliability prediction for large and complex telecommunication systems,"The problem of predicting the number of remaining faults in a software system are studied. Seven software projects are analyzed using a number of software structure metrices and reliability growth models. The following conclusions are drawn: there is no single model that can always be used, irrespective of the project conditions; software structure metrics (mainly size) do correlate with the number of faults; the assumptions of reliability growth models do not apply when the testing is structured and well organized; and sufficient data has to be collected from different projects to create a basis for predictions.<>"
pub.1142644909,Software Fault-Proneness Analysis based on Composite Developer-Module Networks,"Existing software fault-proneness analysis and prediction models can be categorized into software metrics and visualized approaches. However, the studies of the software metrics solely rely on the quantified data, while the latter fails to reflect the human aspect, which is proven to be a main cause of many failures in various domains. In this paper, we proposed a new analysis model with an improved software network called Composite Developer-Module Network. The network is composed of the linkage of both developers to software modules and software modules to modules to reflect the characteristics and interaction between developers. After the networks of the research objects are built, several different sub-graphs in the networks are derived from analyzing the structures of the sub-graphs that are more fault-prone and further determine whether the software development is in a bad structure, thus predicting the fault-proneness. Our research shows that the different sub-structures are not only a factor in fault-proneness, but also that the complexity of the sub-structure can affect the production of bugs."
pub.1091552979,On the Use of Software Metrics as a Predictor of Software Security Problems,"Relying on one validation and verification (V&V) alone cannot detect all of the security problems of a software system. Each class of V&V effort detects different class(s) of faults in software. Even composing a series of V&V efforts, one can never be completely sure that all faults have been detected. Additionally, security-related V&V efforts must continuously be updated to handle the newest forms of exploits of underlying vulnerabilities in software. The alerts produced by automated static analysis (ASA) tools and other static metrics have been shown to be an effective estimator of the actual reliability in a software system. Predictions of defect density and high-risk components can be identified using static analyzers early in the development phase. Our research hypothesis is the actual number of security vulnerabilities in a software system can be predicted based upon the number of security-related alerts reported by one or more static analyzers and by other static metrics. We built and evaluated statistical prediction model are used to predict the actual overall security of a system."
pub.1105141731,A Mahalanobis distance based algorithm for assigning rank to the predicted fault prone software modules,"This article proposes a methodology based on Artificial Neural Network(ANN) and type-2 fuzzy logic system (FLS) for detecting the fault prone software modules at early development phase. The present research concentrates on software metrics from requirement analysis and design phase of software life cycle. A new approach has been developed to sort out degree of fault proneness (DFP) of the software modules through type-2 FLS. ANN is used to prepare the rule base for inference engine. Furthermore, the proposed model has induced an order relation among the fault prone modules (FPMs) with the help of Mahalanobis distance (MD) metric. During software development process, a project manager needs to recognize the fault prone software modules with their DFP. Hence, the present study is of great importance to the project personnel to develop more cost-effective and reliable software. KC2 dataset of NASA has been applied for validating the model. Performance analysis clearly indicates the better prediction capability of the proposed model compared to some existing similar models."
pub.1045886079,A Software Quality Prediction Model Without Training Data Set,"Criticality prediction models that determine whether a design entity is fault-prone or non fault-prone are used for identifying trouble spots of software system in analysis or design phases. Many criticality prediction models for identifying fault-prone modules using complexity metrics have been suggested. But most of them need training data set. Unfortunately very few organizations have their own training data. To solve this problem, this paper builds a new prediction model, KSM, based on Kohonen SOM neural networks. KSM is implemented and compared with a well-known prediction model, BackPropagation neural network Model (BPM), considering internal characteristics, utilization cost and accuracy of prediction. As a result, this paper shows that KSM has comparative performance with BPM."
pub.1049822140,Comparing design and code metrics for software quality prediction,"The prediction of fault-prone modules continues to attract interest due to the significant impact it has on software quality assurance. One of the most important goals of such techniques is to accurately predict the modules where faults are likely to hide as early as possible in the development lifecycle. Design, code, and most recently, requirements metrics have been successfully used for predicting fault-prone modules. The goal of this paper is to compare the performance of predictive models which use design-level metrics with those that use code-level metrics and those that use both. We analyze thirteen datasets from NASA Metrics Data Program which offer design as well as code metrics. Using a range of modeling techniques and statistical significance tests, we confirmed that models built from code metrics typically outperform design metrics based models. However, both types of models prove to be useful as they can be constructed in different project phases. Code-based models can be used to increase the performance of design-level models and, thus, increase the efficiency of assigning verification and validation activities late in the development lifecycle. We also conclude that models that utilize a combination of design and code level metrics outperform models which use either one or the other metric set."
pub.1036326182,Transfer function modelling in software reliability,This paper demonstrates the applicability of transfer function model in the field of software reliability. Here a stepwise procedure for fitting a transfer function model has been described and then the prediction of remaining faults in software has been done using the built in model. Some real life data have been used for illustration purpose.
pub.1141966595,Software Defect-Based Prediction Using Logistic Regression: Review and Challenges,"Software analysis and prediction system development is the significant and much-needed field of software testing in software engineering. The automatic software predictors analyze, predict, and classify a variety of errors, faults, and defects using different learning-based methods. Many research contributions have evolved in this direction. In recent years, however, they have faced the challenges of software validation, non-balanced and unequal data, classifier selection, code size, code dependence, resources, accuracy, and performance. There is, therefore, a great need for an effective and automated software defect-based prediction system that uses machine learning techniques, with great efficiency. In this paper, a variety of such studies and systems are discussed and compared. Their measurement methods such as metrics, features, parameters, classifiers, accuracy, and data sets are found and discriminated. In addition to this, their challenges, threats, and limitations are also stated to demonstrate their system’s effectiveness. Therefore, it was discovered that such systems accounted for 44% use of the NASA’s PROMISE data samples, 68.18% metrics use of software, and also 16% use of the Logistic Regression method."
pub.1035090489,An in-depth study of the potentially confounding effect of class size in fault prediction," Background . The extent of the potentially confounding effect of class size in the fault prediction context is not clear, nor is the method to remove the potentially confounding effect, or the influence of this removal on the performance of fault-proneness prediction models. Objective . We aim to provide an in-depth understanding of the effect of class size on the true associations between object-oriented metrics and fault-proneness. Method . We first employ statistical methods to examine the extent of the potentially confounding effect of class size in the fault prediction context. After that, we propose a linear regression-based method to remove the potentially confounding effect. Finally, we empirically investigate whether this removal could improve the prediction performance of fault-proneness prediction models. Results . Based on open-source software systems, we found: (a) the confounding effect of class size on the associations between object-oriented metrics and fault-proneness in general exists; (b) the proposed linear regression-based method can effectively remove the confounding effect; and (c) after removing the confounding effect, the prediction performance of fault prediction models with respect to both ranking and classification can in general be significantly improved. Conclusion . We should remove the confounding effect of class size when building fault prediction models. "
pub.1011919853,Prediction of software development faults in PL/SQL files using neural network models,"Database application constitutes one of the largest and most important software domains in the world. Some classes or modules in such applications are responsible for database operations. Structured Query Language (SQL) is used to communicate with database middleware in these classes or modules. It can be issued interactively or embedded in a host language. This paper aims to predict the software development faults in PL/SQL files using SQL metrics. Based on actual project defect data, the SQL metrics are empirically validated by analyzing their relationship with the probability of fault detection across PL/SQL files. SQL metrics were extracted from Oracle PL/SQL code of a warehouse management database application system. The faults were collected from the journal files that contain the documentation of all changes in source files. The result demonstrates that these measures may be useful in predicting the fault concerning with database accesses. In our study, General Regression Neural Network and Ward Neural Network are used to evaluate the capability of this set of SQL metrics in predicting the number of faults in database applications."
pub.1172662866,The untold impact of learning approaches on software fault-proneness predictions: an analysis of temporal aspects,"This paper aims to improve software fault-proneness prediction by investigating the unexplored effects on classification performance of the temporal decisions made by practitioners and researchers regarding (i) the interval for which they will collect longitudinal features (software metrics data), and (ii) the interval for which they will predict software bugs (the target variable). We call these specifics of the data used for training and of the target variable being predicted the learning approach, and explore the impact of the two most common learning approaches on the performance of software fault-proneness prediction, both within a single release of a software product and across releases. The paper presents empirical results from a study based on data extracted from 64 releases of twelve open-source projects. Results show that the learning approach has a substantial, and typically unacknowledged, impact on classification performance. Specifically, we show that one learning approach leads to significantly better performance than the other, both within-release and across-releases. Furthermore, this paper uncovers that, for within-release predictions, the difference in classification performance is due to different levels of class imbalance in the two learning approaches. Our findings show that improved specification of the learning approach is essential to understanding and explaining the performance of fault-proneness prediction models, as well as to avoiding misleading comparisons among them. The paper concludes with some practical recommendations and research directions based on our findings toward improved software fault-proneness prediction."
pub.1092148579,A New Data Mining-Based Framework to Test Case Prioritization Using Software Defect Prediction,"Test cases do not have the same importance when used to detect faults in software; therefore, it is more efficient to test the system with the test cases that have the ability to detect the faults. This research proposes a new framework that combines data mining techniques to prioritize the test cases. It enhances fault prediction and detection using two different techniques: 1) the data mining regression classifier that depends on software metrics to predict defective modules, and 2) the k-means clustering technique that is used to select and prioritize test cases to identify the fault early. Our approach of test case prioritization yields good results in comparison with other studies. The authors used the Average Percentage of Faults Detection (APFD) metric to evaluate the proposed framework, which results in 19.9% for all system modules and 25.7% for defective ones. Our results give us an indication that it is effective to start the testing process with the most defective modules instead of testing all modules arbitrary arbitrarily."
pub.1000727060,Predicting Bugs in Large Industrial Software Systems,"This chapter is a survey of close to ten years of software fault prediction research performed by our group. We describe our initial motivation, the variables used to make predictions, provide a description of our standard model based on Negative Binomial Regression, and summarize the results of using this model to make predictions for nine large industrial software systems. The systems range in size from hundreds of thousands to millions of lines of code. All have been in the field for multiple years and many releases, and continue to be maintained and enhanced, usually at 3 month intervals.Effectiveness of the fault predictions is assessed using two different metrics. We compare the effectiveness of the standard model to augmented models that include variables related to developer counts, to inter-file calling structure, and to information about specific developers who modified the code.We also evaluate alternate prediction models based on different training algorithms, including Recursive Partitioning, Bayesian Additive Regression Trees, and Random Forests."
pub.1093563277,Applying Swarm Ensemble Clustering Technique for Fault Prediction Using Software Metrics,"Number of defects remaining in a system provides an insight into the quality of the system. Defect detection systems predict defects by using software metrics and data mining techniques. Clustering analysis is adopted to build the software defect prediction models. Cluster ensembles have emerged as a prominent method for improving robustness, stability and accuracy of clustering solutions. The clustering ensembles combine multiple partitions generated by different clustering algorithms into a single clustering solution. In this paper, the clustering ensemble using Particle Swarm Optimization algorithm (PSO) solution is proposed to improve the prediction quality. An empirical study shows that the PSO can be a good choice to build defect prediction software models."
pub.1061788513,Empirical Analysis of Object-Oriented Design Metrics for Predicting High and Low Severity Faults,"In the last decade, empirical studies on object-oriented design metrics have shown some of them to be useful for predicting the fault-proneness of classes in object-oriented software systems. This research did not, however, distinguish among faults according to the severity of impact. It would be valuable to know how object-oriented design metrics and class fault-proneness are related when fault severity is taken into account. In this paper, we use logistic regression and machine learning methods to empirically investigate the usefulness of object-oriented design metrics, specifically, a subset of the Chidamber and Kemerer suite, in predicting fault-proneness when taking fault severity into account. Our results, based on a public domain NASA data set, indicate that 1) most of these design metrics are statistically related to fault-proneness of classes across fault severity, and 2) the prediction capabilities of the investigated metrics greatly depend on the severity of faults. More specifically, these design metrics are able to predict low severity faults in fault-prone classes better than high severity faults in fault-prone classes"
pub.1004379434,Fault density analysis of object-oriented classes in presence of code clones,"Code cloning has been a typical practice during software development, by which code fragments are reused with or without changes by copying and pasting. It has been a questionable issue whether cloning has a destructive impact or not on software development and the quality of the delivered software. This paper empirically investigates the relationship between code clones and fault density of object-oriented classes. More than 3000 classes from five open source software systems were analyzed. The results suggest that classes that have clones were less fault dense on average than the classes that do not have clones. However, there was no association between intra/inter-class clone fragments within a class and its fault density. The results also indicate that among the groups of classes that have only one type of clones, the group of classes with Type III clones was the least fault dense. Minor, although statistically significant, correlations were observed between many code clone metrics and class fault density. Furthermore, the fault density predictive powers of these metrics were found to be almost the same. However, no improvement in the accuracy of fault density prediction models was observed when these metrics were used as inputs."
pub.1101062867,Software Reliability Modeling and Analysis via Kernel-Based Approach,"Traditional software reliability analysis utilizes only the fault count data observed in testing phase, and is done independently of the source code itself. Recently, it is known that utilization of software metrics in software reliability modeling and analysis can lead to more accurate reliability estimation and fault prediction through many empirical studies. However, such a metrics-based modeling also requires a careful selection of software metrics and their measurement, which are often troublesome and cost-consuming in practice. In this paper, we propose a kernel-based approach to estimate the quantitative software reliability, where two cases are considered; multiple software metrics are used and not. In the former case, we combine the kernel regression with the well-known non-homogeneous Poisson process-based software reliability growth model (SRGM), and propose a new metrics-based SRGM. In the latter case, we perform a similarity-based analysis through a source code transformation algorithm and try to estimate the quantitative software reliability from the source code directly without measuring multiple software metrics. Numerical examples with real application programs are presented to validate our kernel-based approach in the above two cases."
pub.1020318348,Machine Learning and Its Application in Software Fault Prediction with Similarity Measures,"Nowadays, the challenge is how to exactly understand and apply various techniques to discover fault from the software module. Machine learning is the process of automatically discovering useful information in knowledgebase. It also provides capabilities to predict the outcome of future solutions. Case-based reasoning is a tool or method to predict error level with respect to LOC and development time in software module. This paper presents some new ideas about process and product metrics to improve software quality prediction. At the outset, it deals with the possibilities of using lines of code and development time from any language may be compared and be used as a uniform metric. The system predicts the error level with respect to LOC and development time, and both are responsible for checking the developer’s ability or efficiency of the developer. Prediction is based on the analogy. We have used different similarity measures to find the best method that increases the correctness. The present work is also credited through introduction of some new terms such as coefficient of efficiency, i.e., developer’s ability and normalizer. In order to obtain the result, we have used indigenous tool."
pub.1124434359,Proposed approach to predict software faults detection using Entropy,"The major challenge is to validate software failure dataset by finding unknown model parameters used. For software assurance, previously many attempts were made based using classical classifiers as Decision Tree, Naïve Bayes, and k-NN for software fault prediction. But the accuracy of fault prediction is very low as defect prone modules are very small as compared to defect-free modules. So, for solving modules fault classification problems and enhancing reliability accuracy, a hybrid algorithm proposed on particle swarm optimization and modified genetic algorithm for feature selection and bagging for effective classification of defective or non-defective modules in a dataset. This paper presents an empirical study on NASA metric data program datasets, using the proposed hybrid algorithm and results showed that our proposed hybrid approach enhances the classification accuracy compared with existing methods."
pub.1143242429,Using Metrics for Risk Prediction in Object-Oriented Software: A Cross-Version Validation,"This work aims to investigate the potential, from different perspectives, of a risk model to support Cross-Version Fault and Severity Prediction (CVFSP) in object-oriented software. The risk of a class is addressed from the perspective of two particular factors: the number of faults it can contain and their severity. We used various object-oriented metrics to capture the two risk factors. The risk of a class is modeled using the concept of Euclidean distance. We used a dataset collected from five successive versions of an open-source Java software system (ANT). We investigated different variants of the considered risk model, based on various combinations of object-oriented metrics pairs. We used different machine learning algorithms for building the prediction models: Naive Bayes (NB), J48, Random Forest (RF), Support Vector Machines (SVM) and Multilayer Perceptron (ANN). We investigated the effectiveness of the prediction models for Cross-Version Fault and Severity Prediction (CVFSP), using data of prior versions of the considered system. We also investigated if the considered risk model can give as output the Empirical Risk (ER) of a class, a continuous value considering both the number of faults and their different levels of severity. We used different techniques for building the prediction models: Linear Regression (LR), Gaussian Process (GP), Random forest (RF) and M5P (two decision trees algorithms), SmoReg and Artificial Neural Network (ANN). The considered risk model achieves acceptable results for both cross-version binary fault prediction (a g-mean of 0.714, an AUC of 0.725) and cross-version multi-classification of levels of severity (a g-mean of 0.758, an AUC of 0.771). The model also achieves good results in the estimation of the empirical risk of a class by considering both the number of faults and their levels of severity (intra-version analysis with a correlation coefficient of 0.659, cross-version analysis with a correlation coefficient of 0.486)."
pub.1094411374,Using classification trees for software quality models: lessons learned,"High software reliability is an important attribute of high-assurance systems. Software quality models yield timely predictions of reliability indicators on a module-by-module basis, enabling one to focus on finding faults early in development. This paper introduces the CART (Classification And Regression Trees) algorithm to practitioners in high-assurance systems engineering. This paper presents practical lessons learned in building classification trees for software quality modeling, including an innovative way to control the balance between misclassification rates. A case study of a very large telecommunications system used CART to build software quality models. The models predicted whether or not modules would have faults discovered by customers, based on various sets of software product and process metrics as independent variables. We found that a model based on two software product metrics had an accuracy that was comparable to a model based on 40 product and process metrics."
pub.1062960178,USING CLASSIFICATION TREES FOR SOFTWARE QUALITY MODELS: LESSONS LEARNED,"High software reliability is an important attribute of high-assurance systems. Software quality models yield timely predictions of quality indicators on a module-by-module basis, enabling one to focus on finding faults early in development. This paper introduces the Classification And Regression Trees (CART) a algorithm to practitioners in high-assurance systems engineering. This paper presents practical lessons learned on building classification trees for software quality modeling, including an innovative way to control the balance between misclassification rates. A case study of a very large telecommunications system used CART to build software quality models. The models predicted whether or not modules would have faults discovered by customers, based on various sets of software product and process metrics as independent variables. We found that a model based on two software product metrics had comparable accuracy to a model based on forty product and process metrics."
pub.1027263666,Empirical Assessment of a Software Metric: The Information Content of Operators,"This paper presents an empirical case study that predicted faults in modules based on the total information content of the operators. This metric is closely related to Harrison's average information content classification (AICC), which is the entropy of the operators. Most information theory-based metrics proposed in the literature have not been subjected to empirical predictive studies of real-world software systems. In contrast, this study shows that a simple information theory-based metric can be more useful for prediction of software quality than comparable metrics based on counts in the context of a commercial software development organization.Three models were considered, all based on operators as an abstraction of software. The model based on information content of the operators made more accurate predictions than two similar models based on the number of operators and the number of unique operators. The purpose of this paper is a fair comparison of the three metrics, rather than developing an optimal model. We have long advocated multivariate models for industrial use. The case study considered three large commercial systems, written in assembly language, and developed consecutively by professional programmers. The first system was used to estimate parameters of the models. The subsequent two were used to evaluate the accuracy of model predictions."
pub.1107475436,"Applying Machine Learning to Predict Software Fault Proneness Using Change Metrics, Static Code Metrics, and a Combination of Them","Predicting software fault proneness is very important as the process of fixing these faults after the release is very costly and time-consuming. In order to predict software fault proneness, many machine learning algorithms (e.g., Logistic regression, Naive Bayes, and J48) were used on several datasets, using different metrics as features. The question is what algorithm is the best under which circumstance and what metrics should be applied. Related works suggested that using change metrics leads to the highest accuracy in prediction. In addition, some algorithms perform better than others in certain circumstances. In this work, we use three machine learning algorithms (i.e., logistic regression, Naive Bayes, and J48) on three Eclipse releases (i.e., 2.0, 2.1, 3.0). The results showed that accuracy is slightly better and false positive rates are lower, when we use the reduced set of metrics compared to all change metrics set. However, the recall and the G score are better when we use the complete set of change metrics. Furthermore, J48 outperformed the other classifiers with respect to the G score for the reduced set of change metrics, as well as in almost all cases when the complete set of change metrics, static code metrics, and the combination of both were used."
pub.1129124385,Fault Prediction in SOA-Based Systems Using Deep Learning Techniques,"Fault prediction in Service Oriented Architecture (SOA) based systems is one of the important tasks to minimize the computation cost and time of the software system development. Predicting the faults and discovering their locations in the early stage of the system development lifecycle makes maintenance processes easy and improves the resource utilization. In this paper, the authors proposed the fault prediction model for SOA-based systems by utilizing the deep learning techniques. Twenty-one source code metrics are applied to different web services projects. The web services datasets are constructed by injecting the faults into it, and metrics are extracted for both faulty and nonfaulty data for training and testing purpose. Moreover, different deep learning techniques are inspected for fault prediction of web services and performance of different methods are compared by using standard performance measures. From the experimental results, it is observed that deep learning techniques provide effective results and applicable to the real-world SOA-based systems."
pub.1114818762,不具合予測に関するメトリクスについての研究論文の系統的レビュー,"This paper provides a systematic review of studies related to software fault prediction with a specific focus on types of metrics. The research questions on this paper are: what types of metrics are used for studies related to faults, and is there trend in proposal of fault-related metrics. The review uses 63 papers in 2 journals and 5 conference proceedings published in 2000–2010. According to the review results, we found that coderelated and process-related historical metrics had been used mainly since 2005, and organization-related and geographic metrics had been used since 2008."
pub.1101406227,Cost-effective and fault-resilient reusability prediction model by using adaptive genetic algorithm based neural network for web-of-service applications,"The exponential rise in software technologies and its significances has demanded academia-industries to ensure low cost software solution with assured service quality and reliability. A low cost and fault-resilient software design is must, where to achieve low cost design the developers or programmers prefer exploiting source or function reuse. However, excessive reusability makes software vulnerable to get faulty due to increased complexity and aging proneness. Non-deniably assessing reusability of a class of function in software can enable avoiding any unexpected fault or failure. To achieve it developing a robust and efficient reusability estimation or prediction model is of utmost significance. On the other hand, the aftermath consequences of excess reusability caused faults might lead significant losses. Hence assessing cost effectiveness and efficacy of a reusability prediction model is must for software design optimization. In this paper, we have examined different reusability prediction models for their cost effectiveness and prediction efficiency over object-oriented software design. At first to examine the reusability of a class, three key object oriented software metrics (OO-SM); cohesion, coupling and complexity of the software components are used. Furthermore, our proposed cost-efficient reusability prediction model incorporates Min–Max normalization, outlier detection, reusability threshold estimation; T test analysis based feature selection and various classification algorithms. Different classifiers including decision tree (DT), Naïve Bayes (NB), artificial neural network (ANN) algorithms, extreme learning machine (ELM), regression algorithms, multivariate adaptive regression spline (MARS) and adaptive genetic algorithm (AGA) based ANN are used for reusability prediction. Additionally, the cost effectiveness of each reusability prediction model is estimated, where the overall results have revealed that AGA based ANN as classifier in conjunction with OO-SM, normalization, T test analysis based feature selection outperforms other state-of-art techniques in terms of both accuracy as well as cost-effectiveness."
pub.1047773569,Prediction = Power,"An argument is made that predictive metrics provide a very powerful means for organizations to assess characteristics of their software systems and allow them to make critical decisions based on the value computed. Five different predictors are discussed aimed at different stages of the software lifecycle ranging from a metric that is based on an architecture review which is done at the earliest stages of development, before even low-level design has begun, to one designed to predict the risk of releasing a system in its current form. Other predictors discussed include the identification of characteristics of files that are likely to be particularly fault-prone, a metric to help a tester charged with regression testing to determine whether or not a particular selective regression testing algorithm is likely to be cost effective to run on a given software system and test suite, and a metric to help determine whether a system is likely to be able to handle a significantly increased workload while maintaining acceptable performance levels."
pub.1094121219,An empirical study of pre-release software faults in an industrial product line,"There is a lack of published studies providing empirical support for the assumption at the heart of product line development, namely, that through structured reuse later products will be less fault-prone. This paper presents results from an empirical study of pre-release fault and change proneness from four products in an industrial software product line. The objectives of the study are (1) to determine the association between various software metrics, as well as their correlation with the number of faults at the component level; (2) to characterize the fault and change proneness at various degrees of reuse; and (3) to determine how existing products in the software product line affect the quality of subsequently developed products and our ability to make predictions. The research results confirm, in a software product line setting, the findings of others that faults are more highly correlated to change metrics than to static code metrics. Further, the results show that variation components unique to individual products have the highest fault density and are the most prone to change. The longitudinal aspect of our research indicates that new products in this software product line benefit from the development and testing of previous products. For this case study, the number of faults in variation components of new products is predicted accurately using a linear model built on data from the previous products."
pub.1029268625,Suitability of KNN Regression in the Development of Interaction based Software Fault Prediction Models,"Accurate fault prediction is an indispensable step, to the extent of being a critical activity in software engineering. In fault prediction model development research, combination of metrics significantly improves the prediction capability of the model, but it also gives rise to the issue of handling an increased number of predictors and evolved nonlinearity due to complex interaction among metrics.Ordinary least square (OLS) based parametric regression techniques cannot effectively model such nonlinearity with a large number of predictors because the global parametric function to fit the data is not known beforehand. In our previous studies[1–3], we showed the impact of interaction in the combined metrics approach of fault prediction and statistically established the simultaneous increment in the predictive accuracy of the model with interaction.In this study we use K-Nearest Neighbor (KNN) regression as an example of nonparametric regression technique, otherwise well known for classification tasks in the data mining community. Through the results derived here, we empirically establish and validate the hypothesis that the performance of KNN regression remains ordinarily unaffected with increasing number of interacting predictors and simultaneously provides superior performance over widely used multiple linear regression (MLR)."
pub.1093598494,Towards Assessing Representativeness of Fault Injection-Generated Failure Data for Online Failure Prediction,"Online Failure Prediction allows improving system dependability by foreseeing incoming failures at runtime, enabling mitigation actions to be taken in advance, though prediction systems' learning and assessing is hard due to the scarcity of failure data. Realistic software fault injection has been identified as a valid solution for addressing the scarcity of failure data, as injecting software faults (the most occurring on computer systems) increases the probability of a system to fail, hence allowing the collection of failure-related data in short time. Moreover, realistic injection permits the emulation of software faults likely to exist in the target system after its deployment. However, besides the representativeness of the software faults injected is recognized as a necessary condition for generating valid failure data, studies on the representativeness of generated failure-related data has still not been addressed. In this work we present a preliminary study towards the assessment the representativeness of failurerelated data by using G-SWFIT realistic software fault injection technique. We here address the definition of concepts and metrics for the representativeness estimation and assessment."
pub.1170329700,Ensemble Learning Applications in Software Fault Prediction,"Software fault prediction (SFP) plays a crucial role in the software engineering field by allocating testing resources reasonably, reducing testing costs, and adhering to software quality standards. This paper explores the applications of Ensemble learning algorithms and techniques in SFP. The paper presents a three-stage framework that incorporates random forest, bagging, AdaBoost, LogitBoost, Gradient Boosting, XGBoost, and CatBoost individually, as well as an ensemble of all EL algorithms, applying both soft and hard voting combination rules. Additionally, this paper investigates the impact of SMOTE oversampling with ensemble learning algorithms and techniques based on experiments performed on five (JM1, KC, MC2, KC3, and PC5 NASA MDP) cleaned datasets. The performance of the proposed framework was evaluated using metrics such as Accuracy, F1-measure, Matthew’s correlation coefficient (MCC), area under the curve (AUC), and precision. Our findings, consistent with previous research, reveal that the effectiveness of various Ensemble Learning algorithms fluctuates depending on the specific dataset, with random forest often delivering superior performance. Finally, the results also suggest that ensemble learning has a positive effect on SFP models, provided it is carefully orchestrated."
pub.1095504771,Can Lexicon Bad Smells improve fault prediction?,"In software development, early identification of fault-prone classes can save a considerable amount of resources. In the literature, source code structural metrics have been widely investigated as one of the factors that can be used to identify faulty classes. Structural metrics measure code complexity, one aspect of the source code quality. Complexity might affect program understanding and hence increase the likelihood of inserting errors in a class. Besides the structural metrics, we believe that the quality of the identifiers used in the code may also affect program understanding and thus increase the likelihood of error insertion. In this study, we measure the quality of identifiers using the number of Lexicon Bad Smells (LBS) they contain. We investigate whether using LBS in addition to structural metrics improves fault prediction. To conduct the investigation, we assess the prediction capability of a model while using i) only structural metrics, and ii) structural metrics and LBS. The results on three open source systems, ArgoUML, Rhino, and Eclipse, indicate that there is an improvement in the majority of the cases."
pub.1033734532,Comparative analysis of J48 with statistical and machine learning methods in predicting fault-prone classes using object-oriented systems,"There are available metrics for predicting fault prone classes, which May help software organizations for planning and performing testing activities. This May be possible due to proper allocation of resources on fault prone parts of the design and code of the software. Hence, importance and usefulness of such metrics is understandable, but empirical validation of these metrics is always a great challenge. J48 decision tree algorithm has been successfully applied for solving classification problems in many applications. This paper evaluates the capability of algorithm and compares its performance with nine statistical and machine learning methods in predicting fault prone software classes using publicly available NASA data set. The results indicate that the prediction performance of J48 is generally better than other statistical and machine learning models. However, similar types of studies are required to be carried out in order to establish the acceptability of the J48 model."
pub.1112059250,A fuzzy-filtered neuro-fuzzy framework for software fault prediction for inter-version and inter-project evaluation,"Fault Prediction is the most required measure to estimate the software quality and reliability. Several methods, measures, aspects and testing methodologies are available to evaluate the software fault. In this paper, a fuzzy-filtered neuro-fuzzy framework is introduced to predict the software faults for internal and external software projects. The suggested framework is split into three primary phases. At the earlier phase, the effective metrics or measures are identified, which can derive the accurate decision on prediction of software fault. In this phase, the composite analytical observation of each software attribute is calculated using Information Gain and Gain Ratio measures. In the second phase, these fuzzy rules are applied on these measures for selection of effective and high-impact features. In the last phase, the Neuro-fuzzy classifier is applied on fuzzy-filtered training and testing sets. The proposed framework is applied to identify the software faults based on inter-version and inter-project evaluation. In this framework, the earlier projects or project-versions are considered as training sets and the new projects or versions are taken as testing sets. The experimentation is conducted on nine open source projects taken from PROMISE repository as well as on PDE and JDT projects. The approximation is applied on internal version-specific fault prediction and external software projects evaluation. The comparative analysis is performed against Decision Tree, Random Tree, Random Forest, Naive Bayes and Multilevel Perceptron classifiers. This prediction result signifies that the proposed framework has gained the higher accuracy, lesser error rate and significant AUC and GM for inter-project and inter-version evaluations."
pub.1094034911,An Analysis of Software Correctness Prediction Methods,"Reliability is one of the most important aspects of software systems of any kind. Software development is a complex and complicated process in which software faults are inserted into the code by mistakes during the development process or maintenance. It has been shown that the pattern of the faults insertion phenomena is related to measurable attributes of the software. In the paper we will introduce some methods for reliability prediction based on software metrics, present the results of using these methods in the particular industrial software environment for which we have a large database of modules in C language. Finally we will compare the results and methods and give some directions and ideas for future work."
pub.1007399188,Fault prediction considering threshold effects of object‐oriented metrics,"Abstract Software product quality can be enhanced significantly if we have a good knowledge and understanding of the potential faults therein. This paper describes a study to build predictive models to identify parts of the software that have high probability of occurrence of fault. We have considered the effect of thresholds of object‐oriented metrics on fault proneness and built predictive models based on the threshold values of the metrics used. Prediction of fault prone classes in earlier phases of software development life cycle will help software developers in allocating the resources efficiently. In this paper, we have used a statistical model derived from logistic regression to calculate the threshold values of object oriented, Chidamber and Kemerer metrics. Thresholds help developers to alarm the classes that fall outside a specified risk level. In this way, using the threshold values, we can divide the classes into two levels of risk – low risk and high risk. We have shown threshold effects at various risk levels and validated the use of these thresholds on a public domain, proprietary dataset, KC1 obtained from NASA and two open source, Promise datasets, IVY and JEdit using various machine learning methods and data mining classifiers. Interproject validation has also been carried out on three different open source datasets, Ant and Tomcat and Sakura. This will provide practitioners and researchers with well formed theories and generalised results. The results concluded that the proposed threshold methodology works well for the projects of similar nature or having similar characteristics."
pub.1128980380,Prediction Of Accuracy On Open Source Java Projects Using Class Level Refactoring,"The refactoring approach is used to restructure the software system without altering its external functionalities. Our research objective is to analyze the accuracy of the software metrics using machine learning classifiers. After predicting the accuracy we can refactor the inaccurate source metrics by using different refactoring tools and machine learning algorithms. We have considered 30 code metrics from 3 open source java projects by using different framework like antlr4,junit and oryx at the class level and predict its accuracy using different machine learning classifiers. We have used Gaussian, Bernoulli and Multinomial classifiers to predict the accuracy of the software metrics. Statistical significant test reveals the mean accuracy for the above sources are 33.33%,39%,48.33% respectively. As per the prediction analysis we can correct the fault and improve the performance of our source metrics by conducting unit level testing which leads to software refactoring"
pub.1010802275,11 Metrics in practice,"This chapter summarizes the use of software metrics as an indicator of product reliability during software development. The problems of interpreting software metrics data in terms of future reliability are also discussed in the chapter. Metrics related to errors and faults, size and complexity and software evolution are described and their use illustrated using examples from ICL's VME Operating System Production Group. VME as a whole comprises about 8000 modules, a module in this instance being the smallest unit that can be independently compiled. Enhancements, improvements and the introduction of new facilities to the system run at an overall rate of approximately 30,000 lines of code. Side-effect metrics are illustrated by fault counts. As a result of the checking activities that take place during the development process such as reviews, inspections, unit testing, and system testing, various defects are uncovered. It is suggested that although software metrics are available and are useful for monitoring development, their direct relationship to reliability prediction has yet not been established."
pub.1032930758,Uncertain Classification of Fault-Prone Software Modules,"Many development organizations try to minimize faults in software as a means for improving customer satisfaction. Assuring high software quality often entails time-consuming and costly development processes. A software quality model based on software metrics can be used to guide enhancement efforts by predicting which modules are fault-prone. This paper presents statistical techniques to determine which predictions by a classification tree should be considered uncertain. We conducted a case study of a large legacy telecommunications system. One release was the basis for the training dataset, and the subsequent release was the basis for the evaluation dataset. We built a classification tree using the TREEDISC algorithm, which is based on χ2 tests of contingency tables. The model predicted whether a module was likely to have faults discovered by customers, or not, based on software product, process, and execution metrics. We simulated practical use of the model by classifying the modules in the evaluation dataset. The model achieved useful accuracy, in spite of the very small proportion of fault-prone modules in the system. We assessed whether the classes assigned to the leaves were appropriate by statistical tests, and found sizable subsets of modules with uncertain classification. Discovering which modules have uncertain classifications allows sophisticated enhancement strategies to resolve uncertainties. Moreover, TREEDISC is especially well suited to identifying uncertain classifications."
pub.1004341743,So You Need More Method Level Datasets for Your Software Defect Prediction?,"Context: Defect prediction research is based on a small number of defect datasets and most are at class not method level. Consequently our knowledge of defects is limited. Identifying defect datasets for prediction is not easy and extracting quality data from identified datasets is even more difficult. Goal: Identify open source Java systems suitable for defect prediction and extract high quality fault data from these datasets. Method: We used the Boa to identify candidate open source systems. We reduce 50,000 potential candidates down to 23 suitable for defect prediction using a selection criteria based on the system's software repository and its defect tracking system. We use an enhanced SZZ algorithm to extract fault information and calculate metrics using JHawk. Result: We have produced 138 fault and metrics datasets for the 23 identified systems. We make these datasets (the ELFF datasets) and our data extraction tools freely available to future researchers. Conclusions: The data we provide enables future studies to proceed with minimal effort. Our datasets significantly increase the pool of systems currently being used in defect analysis studies."
pub.1009165244,Software Quality Classification Model using Virtual Training Data,"Criticality prediction models to identify most fault-prone modules in the system early in the software development process help in allocation of resources and foster software quality improvement. Many models for identifying fault-prone modules using design complexity metrics have been suggested, but most of them are training models that need training data set. Most organizations cannot use these models because very few organizations have their own training data. This paper builds a prediction model based on a well-known supervised learning model, error backpropagation neural net, using design metrics quantifying SDL system specifications. To solve the problem of other models, this model is trained by generated virtual training data set. Some simulation studies have been performed to investigate feasibility of this model, and the results show that suggested model can be an alternative for the organizations without real training data to predict their software qualities."
pub.1093707298,Using Faults-Slip-Through Metric As A Predictor of Fault-Proneness,"Background: The majority of software faults are present in small number of modules, therefore accurate prediction of fault-prone modules helps improve software quality by focusing testing efforts on a subset of modules. Aims: This paper evaluates the use of the faults-slip-through (FST) metric as a potential predictor of fault-prone modules. Rather than predicting the fault-prone modules for the complete test phase, the prediction is done at the specific test levels of integration and system test. Method: We applied eight classification techniques, to the task of identifying fault-prone modules, representing a variety of approaches, including a standard statistical technique for classification (logistic regression), tree-structured classifiers (C4.5 and random forests), a Bayesian technique (Naive Bayes), machine-learning techniques (support vector machines and back-propagation artificial neural networks) and search-based techniques (genetic programming and artificial immune recognition systems) on FST data collected from two large industrial projects from the telecommunication domain. Results: Using area under the receiver operating characteristic (ROC) curve and the location of (PF, PD) pairs in the ROC space, the faults-slip-through metric showed impressive results with the majority of the techniques for predicting fault-prone modules at both integration and system test levels. There were, however, no statistically significant differences between the performance of different techniques based on AUC, even though certain techniques were more consistent in the classification performance at the two test levels. Conclusions: We can conclude that the faults-slip-through metric is a potentially strong predictor of fault-proneness at integration and system test levels. The faults-slip-through measurements interact in ways that is conveniently accounted for by majority of the data mining techniques."
pub.1072379772,Comparing Fault Prediction Models Using Change Request Data for a Telecommunication System,"Many studies in the software reliability have attempted to develop a model for predicting the faults of a software module because the application of good prediction models provides the optimal resource allocation during the development period. In this paper, we consider the change request data collected from the field test of a large‐scale software system and develop statistical models of the software module that incorporate a functional relation between the faults and some software metrics. To this end, we discuss the general aspect of regression method, the problem of multicollinearity and the measures of model evaluation. We consider four possible regression models including two stepwise regression models and two nonlinear models. Four developed models are evaluated with respect to the predictive quality."
pub.1124277926,Proposed software faults detection using hybrid approach,"Abstract The major challenge is to validate software failure dataset by finding unknown model parameters used. For software assurance, previously many attempts were made based using classical classifiers as decision tree, Naïve Bayes, and k‐nearest neighbor for software fault prediction. But the accuracy of fault prediction is very low as defect prone modules are very small as compared to defect‐free modules. So, for solving modules fault classification problems and enhancing reliability accuracy, a hybrid algorithm proposed on particle swarm optimization and modified genetic algorithm for feature selection and bagging for effective classification of defective or nondefective modules in a dataset. This paper presents an empirical study on National Aeronautics and Space Administration Metric Data Program datasets, using the proposed hybrid algorithm and results showed that our proposed hybrid approach enhances the classification accuracy compared with existing methods."
pub.1151953032,An Improved Software Reliability Prediction Model by Using Feature Selection and Extreme Learning Machine,"The unpredictability of developers’ actions can prompt designing issues, such as a rise in software flaws throughout development. As a result, software practitioners will require sophisticated ways to detect software faults to improve software systems. Predicting software defects in a new software project using past data from another project is referred to as cross-system defect expectation. For within project problem prediction, numerous analysts have effectively created models utilizing traditional machine learning and statistical techniques. In addition, some researchers offered cross-project defect prediction methods. On various datasets, however, the performance of these imperfection expectation models appears to decline. These models are insufficiently complete. We looked into using an extreme learning machine (ELM) to predict software reliability. In addition, the usage of ELM in feature selection for defect prediction is investigated in this article. For testing, we used NASA Metrics Data Program datasets are used. The presented elm with feature selection model gives superior prediction accuracy than conventional elm defect prediction models, according to experimental and analysis results."
pub.1165249898,Variance of ML-based software fault predictors: are we really improving fault prediction?,"Software quality assurance activities become increasingly difficult as
software systems become more and more complex and continuously grow in size.
Moreover, testing becomes even more expensive when dealing with large-scale
systems. Thus, to effectively allocate quality assurance resources, researchers
have proposed fault prediction (FP) which utilizes machine learning (ML) to
predict fault-prone code areas. However, ML algorithms typically make use of
stochastic elements to increase the prediction models' generalizability and
efficiency of the training process. These stochastic elements, also known as
nondeterminism-introducing (NI) factors, lead to variance in the training
process and as a result, lead to variance in prediction accuracy and training
time. This variance poses a challenge for reproducibility in research. More
importantly, while fault prediction models may have shown good performance in
the lab (e.g., often-times involving multiple runs and averaging outcomes),
high variance of results can pose the risk that these models show low
performance when applied in practice. In this work, we experimentally analyze
the variance of a state-of-the-art fault prediction approach. Our experimental
results indicate that NI factors can indeed cause considerable variance in the
fault prediction models' accuracy. We observed a maximum variance of 10.10% in
terms of the per-class accuracy metric. We thus, also discuss how to deal with
such variance."
pub.1167576022,Variance of ML-based software fault predictors: are we really improving fault prediction?,"Assuring high software quality becomes increasingly difficult as software systems become more and more complex and continuously grow in size. Moreover, testing becomes even more expensive when dealing with large-scale systems. Thus, to effectively allocate quality assurance resources, researchers have proposed fault prediction (FP) which utilizes machine learning (ML) to predict fault-prone code areas. However, ML algorithms typically make use of stochastic elements to increase the prediction models’ generalizability and efficiency of the training process. These stochastic elements, also known as nondeterminism-introducing (NI) factors, lead to variance in the training process and as a result, lead to variance in prediction accuracy and training time. This variance poses a challenge for reproducing research results. More importantly, while fault prediction models may have shown good performance in the lab (e.g., often-times involving multiple runs and averaging outcomes), high variance of results can pose the risk that these models show low performance when applied in practice. In this work, we experimentally analyze the variance of a state-of-the-art fault prediction approach. Our experimental results indicate that NI factors can indeed cause considerable variance in the fault prediction models’ accuracy. We observed a maximum variance of 10.10% in terms of the per-class accuracy metric. We thus, also discuss how to deal with such variance."
pub.1071884292,Fault-Prone Module Prediction Approaches Using Identifiers in Source Code,"<p>Prediction of fault-prone modules is an important area of software engineering. The authors assumed that the occurrence of faults is related to the semantics in the source code modules. Semantics in a software module can be extracted from identifiers in the module. Identifiers such as variable names and function names in source code are thus essential information to understand code. The naming for identifiers affects on code understandability; thus, the authors expect that they affect software quality. In this study, the authors examine the relationship between the length of identifiers and existence of software faults in a software module. Furthermore, the authors analyze the relationship between occurrence of “words” in identifiers and the existence of faults. From the experiments using the data from open source software, the authors modeled the relationship between the fault occurrence and the length of identifiers, and the relationship between the fault occurrence and the word in identifiers by the random forest technique. The result of the experiment showed that the length of identifiers can predict the fault-proneness of the software modules. Also, the result showed that the word occurrence model is as good a measure as traditional CK and LOC metrics models.</p>"
pub.1062959351,DETECTING FAULT MODULES USING BIOINFORMATICS TECHNIQUES,"Many software reliability studies attempt to develop a model for predicting the faults of a software module because the application of good prediction models provides important information on significant metrics that should be observed in the early stages of implementation during software development. In this article we propose a new method inspired by a multi-agent based system that was initially used for classification and attribute selection in microarray analysis. Best classifying gene subset selection is a common problem in the field of bioinformatics. If we regard the software metrics measurement values of a software module as a genome of that module, and the real world dynamic characteristic of that module as its phenotype (i.e. failures as disease symptoms) we can borrow the established bioinformatics methods in the manner first to predict the module behavior and second to data mine the relations between metrics and failures."
pub.1110837042,Improvement in Software Defect Prediction Outcome Using Principal Component Analysis and Ensemble Machine Learning Algorithms,"Improving customer experience is the focus of IT Industry. It is no longer about customer satisfaction, but it is about creating memorable experiences which will help build loyal customers. Hence it is extremely critical to release defect free software. While machine learning techniques were widely used for prediction modelling, creating a reliable predictor which can perform satisfactorily is always a challenge. In this paper, we have proposed a framework using PCA for feature selection and ensemble machine learning algorithms with stratified 10-fold cross validation for building the classification model. The proposed model is tested using 5 projects from NASA Metrics Data program and 4 ensemble machine learning algorithms. Our results show that the prediction accuracy is improved by 0.6% when the reduced dataset is used for classification than using the whole dataset. In comparison with previous research studies, our framework has shown an average of 4.2% increase in performance."
pub.1110638196,A Phase-Wise Fault Prediction Using Soft Computing,"Software testing is performed to increase quality of the software and also increase the customer satisfaction. In today’s scenario, most of the work is dependent upon software and need of quality software in minimum time. If the fault is not found in the early development phase is having more chance of failure rate in a later phase. Since the failure data or test data are not available in requirement, design, coding and testing phase. For this goal, the phase-wise approach is proposed using soft computing to find the fault in software development life cycle (SDLC) phase. In proposed approach, top reliability-based software metrics/quality attributes for fault prediction is selected from the phases of SDLC. In the proposed approach, four fuzzy inference systems are designed for SDLC phases. The given result from the proposed approach is validated with ten real software datasets from promise datasets. The predicted fault results are near to actual dataset fault. The result from proposed approach is useful for a software developer team, design team, and testing team to plan and take decision for their respective phases of development."
pub.1013471128,Comparing the effectiveness of several modeling methods for fault prediction,"We compare the effectiveness of four modeling methods—negative binomial regression, recursive partitioning, random forests and Bayesian additive regression trees—for predicting the files likely to contain the most faults for 28 to 35 releases of three large industrial software systems. Predictor variables included lines of code, file age, faults in the previous release, changes in the previous two releases, and programming language. To compare the effectiveness of the different models, we use two metrics—the percent of faults contained in the top 20% of files identified by the model, and a new, more general metric, the fault-percentile-average. The negative binomial regression and random forests models performed significantly better than recursive partitioning and Bayesian additive regression trees, as assessed by either of the metrics. For each of the three systems, the negative binomial and random forests models identified 20% of the files in each release that contained an average of 76% to 94% of the faults."
pub.1001022026,Empirical comparison of three metrics suites for fault prediction in packages of object-oriented systems: A case study of Eclipse,"Packages are important high-level organizational units for large object-oriented systems. Package-level metrics characterize the attributes of packages such as size, complexity, and coupling. There is a need for empirical evidence to support the collection of these metrics and using them as early indicators of some important external software quality attributes. In this paper, three suites of package-level metrics (Martin, MOOD and CK) are evaluated and compared empirically in predicting the number of pre-release faults and the number of post-release faults in packages. Eclipse, one of the largest open source systems, is used as a case study. The results indicate that the prediction models that are based on Martin suite are more accurate than those that are based on MOOD and CK suites across releases of Eclipse."
pub.1143905564,Prediction of Aging-Related Bugs Using Software Code Metrics,"The increasing complexity of software systems causes the occurrence of the number of software faults which can drastically affect industrial benefits and reputation. Ongoing software systems sometimes result in degrading the execution and ultimately fail because of the growth of errors in the system state. This phenomenon is known as software aging, in which software bugs can be unreleased file descriptors, memory leaks, stale threads, data corruption, unreleased locks, round-off error accumulation, and divide by zero error. These software bugs are aging-related bugs (ARB). Predictive analysis is performed to locate the ARB in complex software. The approach is evaluated on the open-source dataset to gather data about ARBs. Then software code metrics are extracted from the project used as predictor variables, and feature selection techniques and machine learning (ML) algorithms are then applied to build fault prediction models which identify aging prone files. From the results, it is concluded that the Naïve Bayes algorithm outperforms the other five ML algorithms, achieving the value of 54.4 for the Balance performance measure."
pub.1095075544,Fault Prediction Capability of Program File's Logical-Coupling Metrics,"Frequent changes in logically coupled source files induced bugs in software. Metrics have been used to identify source files which are logically coupled. In this paper, we propose an approach to compute a set of eight metrics, which measure logical-couplings among source files. We compute these metrics using the historical data of software changes which are related to the fixing of post release bugs. To validate that our propose set of metrics is highly correlated with the number bugs and are more capable to construct a bug prediction model, we performed an experiment. Our experimental results show that our propose set of metrics is highly correlated with the number of bugs, and hence can be used to construct a bug prediction model. In our experiment, the obtained accuracy of our bug predictor model is 97%."
pub.1093175249,The design of a software fault prone application using evolutionary algorithm,"Most of the current project management software's are utilizing resources on developing areas in software projects. This is considerably essential in view of the meaningful impact towards time and cost-effective development. One of the major areas is the fault proneness prediction, which is used to find out the impact areas by using several approaches, techniques and applications. Software fault proneness application is an application based on computer aided approach to predict the probability that the software contains faults. The application will uses object oriented metrics and count metrics values from open source software as input values to the genetic algorithm for generation of the rules to classify the software modules in the categories of Faulty and Non Faulty modules. At the end of the process, the result will be visualized using genetic algorithm applet, bar and pie chart. This paper will discussed the detail design of software fault proneness application by using genetic algorithm based on the object oriented approach and will be presented using the Unified Modeling Language (UML). The aim of the proposed design is to develop an automated tool for software development group to discover the most likely software modules to be high problematic in the future."
pub.1042524665,Object oriented software quality prediction using general regression neural networks,"This paper discusses the application of General Regression Neural Network (GRNN) for predicting the software quality attribute -- fault ratio. This study is carried out using static Object-Oriented (OO) measures (64 in total) as the independent variables and fault ratio as the dependent variable. Software metrics used include those concerning inheritance, size, cohesion and coupling. Prediction models are designed using 15 possible combinations of the four categories of the measures. We also tested the goodness of fit of the neural network model with the standard parameters. Our study is conducted in an academic institution with the software developed by students of Undergraduate/Graduate courses."
pub.1114989550,バグモジュール予測を用いたテスト工数割り当て戦略のシミュレーション,"To date, various techniques for predicting fault-prone modules have been proposed; however, test strategies, which assign a certain amount of test effort to each module, have been rarely studied. This paper proposes a simulation model of software testing that can evaluate various test strategies. The simulation model estimates the number of discoverable faults with respect to the given test resources, the test strategy, complexity metrics of a set of modules to be tested, and the fault prediction results. Based on a case study of simulation applying fault prediction to two open source software (Eclipse and Mylyn), we show the relationship between the available test effort and the effective test strategy."
pub.1015766516,Choosing software metrics for defect prediction: an investigation on feature selection techniques,"Abstract The selection of software metrics for building software quality prediction models is a search‐based software engineering problem. An exhaustive search for such metrics is usually not feasible due to limited project resources, especially if the number of available metrics is large. Defect prediction models are necessary in aiding project managers for better utilizing valuable project resources for software quality improvement. The efficacy and usefulness of a fault‐proneness prediction model is only as good as the quality of the software measurement data. This study focuses on the problem of attribute selection in the context of software quality estimation. A comparative investigation is presented for evaluating our proposed hybrid attribute selection approach, in which feature ranking is first used to reduce the search space, followed by a feature subset selection. A total of seven different feature ranking techniques are evaluated, while four different feature subset selection approaches are considered. The models are trained using five commonly used classification algorithms. The case study is based on software metrics and defect data collected from multiple releases of a large real‐world software system. The results demonstrate that while some feature ranking techniques performed similarly, the automatic hybrid search algorithm performed the best among the feature subset selection methods. Moreover, performances of the defect prediction models either improved or remained unchanged when over 85were eliminated. Copyright © 2011 John Wiley & Sons, Ltd."
pub.1095174030,Methods to Predict the Number of Software Faults Using Weibull Distribution,"Quality improvement and control of software is an important agenda for software development firms and, thus, many companies has been conducting measurement and prediction of quality using metrics. As a method to predict the quality based on a history of removed faults of relevant project, there is the Rayleigh model. This model uses the fact that the rate of removed faults per unit of time generally follows the distribution of Rayleigh. However, in the Rayleigh model, the rate of removed faults of some projects do not follow the Rayleigh distribution, thus the gap between the predicted value and performance value becomes significant. Therefore, this study aims to develop a method of predicting numbers of faults that can also predict the quality, by using the quality standard value which shows the Weibull distribution and the knowledge level for software development. Additionally, the evaluation result shows that this method has better prediction accuracy than the Rayleigh model."
pub.1124940676,Software Fault Prediction Based on Fault Probability and Impact,"Nowadays, software tests prioritization is a crucial task. Indeed, testing exhaustively the whole software system can be very difficult, and heavily time and resources consuming. Using machine learning algorithms to predict which parts of a software system are fault-prone can help testers to focus on high-risk parts of the code and improve resources allocation. This paper aims to investigate the potential of a risk-based model to predict fault-prone classes. The risk of classes is evaluated based on two factors: the probability that a class is fault-prone and its impact on the rest of the system. We used object-oriented metrics to capture the two risk factors. The risk of a class is modeled using the Euclidean distance. We built various variants of the riskbased model using a data-set from five versions of the ANT system. We used different machine learning algorithms (Naive Bayes, J48, Random Forest, Support Vector Machines, Multilayer Perceptron and Logistic Regression) to construct various models for fault and level of severity prediction. The objective was to distinguish between classes containing trivial and high severity faults. The considered model achieves good results for binary fault prediction. In addition, the overall multi-classification of severity levels is more than acceptable."
pub.1047638192,Empirical analysis of network measures for effort-aware fault-proneness prediction,"ContextRecently, network measures have been proposed to predict fault-prone modules. Leveraging the dependency relationships between software entities, network measures describe the structural features of software systems. However, there is no consensus about their effectiveness for fault-proneness prediction. Specifically, the predictive ability of network measures in effort-aware context has not been addressed.ObjectiveWe aim to provide a comprehensive evaluation on the predictive effectiveness of network measures with the effort needed to inspect the code taken into consideration.MethodWe first constructed software source code networks of 11 open-source projects by extracting the data and call dependencies between modules. We then employed univariate logistic regression to investigate how each single network measure was correlated with fault-proneness. Finally, we built multivariate prediction models to examine the usefulness of network measures under three prediction settings: cross-validation, across-release, and inter-project predictions. In particular, we used the effort-aware performance indicators to compare their predictive ability against the commonly used code metrics in both ranking and classification scenarios.ResultsBased on the 11 open-source software systems, our results show that: (1) most network measures are significantly positively related to fault-proneness; (2) the performance of network measures varies under different prediction settings; (3) network measures have inconsistent effects on various projects.ConclusionNetwork measures are of practical value in the context of effort-aware fault-proneness prediction, but researchers and practitioners should be careful of choosing whether and when to use network measures in practice."
pub.1095310052,A Semi-Supervised Approach to Software Defect Prediction,"Accurate detection of software components that need to be exposed to additional verification and validation offers the path to high quality products while minimizing non essential software assurance expenditures. In this type of quality modeling we assume that software modules with known fault content developed in similar environment are available. Supervised learning algorithms are the traditional methods of choice for training on existing modules. The models are then used to predict fault content for newly developed software components prior to product release. However, one needs to realize that establishing whether a module contains a fault or not, only to be used for model training, can be expensive. The basic idea behind semi-supervised learning is to learn from a small number of software modules with known fault content and supplement model training with modules for which the fault information is not available, thus reducing the overall cost of quality assurance. In this study, we investigate the performance of semi-supervised learning for software fault prediction. A preprocessing strategy, multidimensional scaling, is embedded in the approach to reduce the dimensional complexity of software metrics used for prediction. Our results show that the dimension-reduction with semi-supervised learning algorithm preforms significantly better than one of the best performing supervised learning algorithm-random forest-in situations when few modules with known fault content are available. We compare our results with the published benchmarks and clearly demonstrate performance benefits."
pub.1156067590,Software Defect Prediction Survey Introducing Innovations with Multiple Techniques,"The software is applied in various areas, so that the quality of the software is very important. The software defect prediction (SDP) is used to solve the issues in the software and enhance the quality. Even if SDP is very helpful in testing, predicting the defective modules is not always easy. Different problems impede smooth performance and use of model defect prediction. The prediction of software defects was an interest of investigation, as early stage prediction of defects improves software quality with reduced cost and effective managing of software. Researchers from different fields help to propose different approaches that help effectively and efficiently. A number of approaches, frameworks, methods, and modeling were proposed using different data sets, metrics, and assessment strategies, in order to remove unnecessary and erroneous details from defect-prone modules. Defects in software systems are common and may cause software users various problems. During the development of different methods, the most probable defect location in large code bases was quickly predicted. Prediction of software faults is an important and beneficial way of improving software quality and reliability. The ability to predict which components in a large software system will contain the most faults in the next release contributes to better management projects, including an early estimation of possible release delays, and a “correcting guide for improving the software’s quality. The identification of bugs/defects at the early stages of the software life cycle reduces the software development effort needed. A lot of research in software fault prediction using machine learning methods has been advanced. There are mainly two problems in the prediction of software defects, dimensional reduction, and imbalances of class."
pub.1125948815,A new Ensemble approach for Software Fault Prediction,"Software Fault prediction is about prediction of faulty modules in the software systems. This prediction is done using different metrics such as lines of code, depth of inheritance tree etc. The fault prediction is carried out during early stages of development, as it decreases the maintenance costs and improve the software quality. Though software engineering research community have employed certain approaches to build an effective fault prediction model by using machine learning techniques, but the resampling techniques are used as an explicit activity in their studies. There is no study which reports the impact of discriminative power of resampling technique with classifiers. The main objective is to utilize the best combination of classifier with resampling technique in the model averaging method. In this study, we have investigated and compared the effect of different ensemble methods in improving the performance of prediction model. We have benchmarked the model averaging method using existing ensemble methods such as voting and stacking. The class imbalance problem is tackled with the use of different resampling techniques such as SMOTE, random under sampling and random over sampling. Five classifiers have been employed in this study due to their wide acceptance in fault prediction context which includes decision trees, logistic regression, Naive bayes, multinomial naive bayes and K nearest neighbor. The model is tested on 4 publicly available datasets from the PROMISE repository. In order to evaluate the performance of fault prediction model, F-measure is used. In order to avoid the sample randomness and biasness, the results are cross validated using k-fold ($\mathrm{k}=10$) cross validation. The experimental results showed that model averaging method outperformed when compared with other ensembles."
pub.1139826858,Vulnerability severity prediction model for software based on Markov chain,"Software vulnerabilities primarily constitute security risks. Commonalities between faults and vulnerabilities prompt developers to utilise traditional fault prediction models and metrics for vulnerability prediction. Although traditional models can predict the number of vulnerabilities and their occurrence time, they fail to accurately determine the seriousness of vulnerabilities, impacts, and severity level. To address these deficits, we propose a method for predicting software vulnerabilities based on a Markov chain model, which offers a more comprehensive descriptive model with the potential to accurately predict vulnerability type, i.e., the seriousness of the vulnerabilities. The experiments are performed using real vulnerability data of three types of popular software: Windows 10, Adobe Flash Player and Firefox. Our model is shown to produce accurate predictive results."
pub.1166609995,Improved software fault prediction using new code metrics and machine learning algorithms,"Many code metrics exist for bug prediction. However, these metrics are based on the trivial count of code properties and are not sufficient. This research article proposes three new code metrics based on class complexity, coupling, and cohesion to fill the gap. The Promise repository metrics suite's complexity, coupling, and cohesion metrics are replaced by the proposed metrics, and a new metric suite is generated. Experiments show that the proposed metrics suite gives more than 2 % improvement in AUC and precision and approximately 1.5 % in f1-score and recall with fewer code metrics than the existing metrics suite."
pub.1021796001,Empirical study of Software Quality estimation,"Software Quality is an important nonfunctional requirement which is not satisfied by many software products. Prediction models using object oriented metrics can be used to identify the faulty classes. In this paper, we will empirically study the relationship between object oriented metrics and fault proneness of an open source project Emma. Twelve machine Learning classifiers have been used. Univariate and Multivariate analysis of Emma shows that Random Forest provides optimum values for accuracy, precision, sensitivity and specificity."
pub.1094096543,Temporal complexity and software faults,"Software developers use complexity metrics to predict development costs before embarking on a project and to estimate the likelihood of faults once the system is built. Traditional measures, however, were designed principally for sequential programs, providing little insight into the added complexity of concurrent systems or increased demands of real-time systems. For the purpose of predicting cost and effort of development, the CoCoMo model considers factors such as real-time and other performance requirements; for fault prediction, however, most complexity metrics are silent on concurrency. An outline for developing a measure of what we term temporal complexity, including significant and encouraging results of preliminary validation, is presented. 13 standard measures of software complexity are shown to define only two distinct domains of variance in module characteristics. Two new domains of variance are uncovered through 6 out of 10 proposed measures of temporal complexity. The new domains are shown to have predictive value in the modeling of software faults.<>"
pub.1147007944,Software Defect Prediction and Software Quality Assessment Using Dlr-Lvq and Fuzzy Rules,"Recently, Software development has been considerably grown. Fault in the software causes fault and interrupts the output. Characteristics like these make it much challenging to avert software flaws. Spontaneously forecasting the amount of flaws within the software modules is essential and also can assist developers to proficiently allot restricted resources. Recently, numerous Software Defect Prediction (SDP) techniques are developed. But, the accuracy and time consuming challenges still remain to be solved. Also, a few top-notch techniques don't properly classify the software whereas it is a needed metric to ensure quality standards. This work proffers a novel Decaying Learning Rate – Learning vector Quantization (DLR-LVQ) classifier to forecast the software defect. The proposed methods consist of the following steps: redundant data removal, feature extraction (FE), feature oversampling, data normalization, defect prediction (DP), and quality prediction. The proposed DLR-LVQ’s attained outcome is assessed with the existent methodologies. The outcomes exhibit that the methodology proposed attains efficient classification outcomes are examined. Keywords: Software Defect Prediction (SDP), Non defective software quality prediction, BM-SMOTE, Decaying Learning Rate, Learning Vector Quantization, Fuzzy rules, HDFS and Map Reduce."
pub.1131850041,Feature-oriented defect prediction,"Software errors are a major nuisance in software development and can lead not only to reputation damages, but also to considerable financial losses for companies. Therefore, numerous techniques for predicting software defects, largely based on machine learning methods, have been developed over the past decades. These techniques usually rely on code and process metrics in order to predict defects at the granularity of typical software assets, such as subsystems, components, and files. In this paper, we present the first systematic investigation of feature-oriented defect prediction: the prediction of defects at the granularity of features---domain-oriented entities abstractly representing (and often cross-cutting) typical software assets. Feature-oriented prediction can be beneficial, since: (i) particular features might be more error-prone than others, (ii) characteristics of features known as defective might be useful to predict other error-prone features, (iii) feature-specific code might be especially prone to faults arising from feature interactions. We present a dataset derived from 12 software projects and introduce two metric sets for feature-oriented defect prediction. We evaluated seven machine learning classifiers with three different attribute sets each, using our two new metric sets as well as an existing metric set from the literature. We observe precision and recall values of around 85% and better robustness when more diverse metrics sets with richer feature information are used."
pub.1120919254,Incremental Feature Selection Method for Software Defect Prediction,"Software defect prediction models are essential for understanding quality attributes relevant for software organization to deliver better software reliability. This paper focuses mainly based on the selection of attributes in the perspective of software quality estimation for incremental database. A new dimensionality reduction method Wilk’s Lambda Average Threshold (WLAT) is presented for selection of optimal features which are used for classifying modules as fault prone or not. This paper uses software metrics and defect data collected from benchmark data sets. The comparative results confirm that the statistical search algorithm (WLAT) outperforms the other relevant feature selection methods for most classifiers. The main advantage of the proposed WLAT method is: The selected features can be reused when there is increase or decrease in database size, without the need of extracting features afresh. In addition, performances of the defect prediction models either remains unchanged or improved even after eliminating 85% of the software metrics."
pub.1165721052,Prediction of Faults in Embedded Software Using Machine Learning Approaches,"Software industry owns the most modern technological developments in this era. A software should be working perfectly without any error before handed over to the customer. The process of this quality assurance should be cost effective, less time-consuming, and reliable. But in practical scenario, it takes time to predict, detect and rectify the faults in a software. There are many models to predict the faults of software but no single model can claim to be perfect. This paper studied seven Machine Learning (ML) algorithms: Ada-Boost, CatBoost, LightGBM, Random Forest, XGBoost, Ensemble using Stacking and Voting to predict faults for an embedded software. Experiments were carried out with six datasets and eight performance metrics: accuracy, sensitivity, specificity, F-measure, balance, AUC, MAE, and precision to observe the performance of the algorithms. Random Forest showed the best results for accuracy, precision and specificity for 35%, 25% and 20% test data ratio with prediction of 0.995, 1 and 0.996 respectively. On the other hand, Ensemble (Stacking) showed the best result for specificity for 35% test ratio with prediction of 0.996. These results proved the suggested model better than the previous ones with acceptable outcome."
pub.1025797954,Fault Prediction Using Statistical and Machine Learning Methods for Improving Software Quality,"An understanding of quality attributes is relevant for the software organization to deliver high software reliability. An empirical assessment of metrics to predict the quality attributes is essential in order to gain insight about the quality of software in the early phases of software development and to ensure corrective actions. In this paper, we predict a model to estimate fault proneness using Object Oriented CK metrics and QMOOD metrics. We apply one statistical method and six machine learning methods to predict the models. The proposed models are validated using dataset collected from Open Source software. The results are analyzed using Area Under the Curve (AUC) obtained from Receiver Operating Characteristics (ROC) analysis. The results show that the model predicted using the random forest and bagging methods outperformed all the other models. Hence, based on these results it is reasonable to claim that quality models have a significant relevance with Object Oriented metrics and that machine learning methods have a comparable performance with statistical methods."
pub.1144237366,A Novel Software Fault Prediction Approach To Predict Error-type Proneness in the Java Programs Using Stream X-Machine and Machine Learning,"Software fault prediction makes software quality assurance process more efficient and economic. Most of the works related to software fault prediction have mainly focused on classifying software modules as faulty or not, which does not produce sufficient information for developers and testers. In this paper, we explore a novel approach using a streamlined process linking Stream X-Machine and machine learning techniques to predict if software modules are prone to having a particular type of runtime error in Java programs. In particular, Stream X-Machine is used to model and generate test cases for different types of Java runtime errors, which will be employed to extract error-type data from the source codes. This data is subsequently added to the collected software metrics to form new training data sets. We then explore the capabilities of three machine learning techniques (Support Vector Machine, Decision Tree, and Multi-layer Perceptron) for error-type proneness prediction. The experimental results showed that the new data sets could significantly improve the performances of machine learning models in terms of predicting error-type proneness."
pub.1008659494,An Analysis of Faulty and Fault-Free C++ Classes Using an Object-Oriented Metrics Suite,"In this paper, we analyze a dataset freely provided through the PROMISE repository containing data on object-oriented (OO) class features and associated faults. We used a set of metrics provided with the dataset, based loosely on the Chidamber & Kemerer (C&K) metrics for our analysis; in particular, we compared and contrasted the characteristics of classes containing faults with those containing zero faults as a mechanism for establishing their causes and a hypothesis-based approach was adopted to this end. Several key results emerged from our analysis. Firstly, coupling seems to be a key factor influencing fault-proneness; the likelihood of at least one fault is greater when there is relatively high coupling. Secondly, class size ‘does matter’ - the more methods in a class, the more faults the class tends to contain. Finally, cross-correlation of the five metrics revealed an interesting trait related to inheritance and a previous study into C++ friends."
pub.1094939271,The impact of costs of misclassification on software quality modeling,"A software quality model can make timely predictions of the class of a module, such as not fault prone or fault prone. These enable one to improve software development processes by targeting reliability improvement techniques more effectively and efficiently. Published software quality classification models generally minimize the number of misclassifications. The contribution of the paper is empirical evidence, supported by theoretical considerations, that such models can significantly benefit from minimizing the expected cost of misclassifications, rather than just the number of misclassifications. This is necessary when misclassification costs for not fault prone modules are quite different from those of fault prone modules. We illustrate the principles with a case study using nonparametric discriminant analysis. The case study examined a large subsystem of the Joint Surveillance Target Attack Radar System, JS-TARS, which is an embedded, real time, military application. Measures of the process history of each module were independent variables. Models with equal costs of misclassification were unacceptable, due to high misclassification rates for fault prone modules, but cost weighted models had acceptable, balanced misclassification rates."
pub.1061154645,Quantitative analysis of faults and failures in a complex software system,"The authors describe a number of results from a quantitative study of faults and failures in two releases of a major commercial software system. They tested a range of basic software engineering hypotheses relating to: the Pareto principle of distribution of faults and failures; the use of early fault data to predict later fault and failure data; metrics for fault prediction; and benchmarking fault data. For example, we found strong evidence that a small number of modules contain most of the faults discovered in prerelease testing and that a very small number of modules contain most of the faults discovered in operation. We found no evidence to support previous claims relating module size to fault density nor did we find evidence that popular complexity metrics are good predictors of either fault-prone or failure-prone modules. We confirmed that the number of faults discovered in prerelease testing is an order of magnitude greater than the number discovered in 12 months of operational use. The most important result was strong evidence of a counter-intuitive relationship between pre- and postrelease faults; those modules which are the most fault-prone prerelease are among the least fault-prone postrelease, while conversely, the modules which are most fault-prone postrelease are among the least fault-prone prerelease. This observation has serious ramifications for the commonly used fault density measure. Our results provide data-points in building up an empirical picture of the software development process."
pub.1110454119,A fuzzy rule-based generation algorithm in interval type-2 fuzzy logic system for fault prediction in the early phase of software development,"Reliability, a measure of software, deals in total number of faults count up to a certain period of time. The present study aims at estimating the total number of software faults during the early phase of software life cycle. Such estimation helps in producing more reliable software as there may be a scope to take necessary corrective actions for improving the reliability within optimum time and cost by the software developers. The proposed interval type-2 fuzzy logic-based model considers reliability-relevant software metric and earlier project data as model inputs. Type-2 fuzzy sets have been used to reduce uncertainties in the vague linguistic values of the software metrics. A rule formation algorithm has been developed to overcome inconsistency in the consequent parts of large number of rules. Twenty-six software project data help to validate the model, and a comparison has been provided to analyse the proposed model’s performance."
pub.1094080721,Investigating Object-Oriented Design Metrics to Predict Fault-Proneness of Software Modules,"This paper empirically investigates the relationship of class design level object-oriented metrics with fault proneness of object-oriented software system. The aim of this study is to evaluate the capability of the design attributes related to coupling, cohesion, complexity, inheritance and size with their corresponding metrics in predicting fault proneness both in independent and combine basis. In this paper, we conducted two set of systematic investigations using publicly available project datasets over its multiple subsequent releases to performed our investigation and four machine learning techniques to validated our results. The first set of investigation consisted of applying the univariate logistic regression (ULR), Spearman's correlation and AUC (Area under ROC curve) analysis on four PROMISE datasets. This investigation evaluated the capability of each metric to predict fault proneness, when used in isolation. The second set of experiments consisted of applying the four machine learning techniques on the next two subsequent versions of the same project datasets to validate the effectiveness of the metrics. Based on the results of individual performance of metrics, we used only those metrics that are found significant, to build multivariate prediction models. Next, we evaluated the significant metrics related to design attributes both in isolation and in combination to validated their capability of predicting fault proneness. Our results suggested that models built on coupling and complexity metrics are better and more accurate than those built on using the rest of metrics."
pub.1146826956,CIAFP,"<p>Object-oriented (OO) code has many dependencies among the classes and different types of changes that often have an impact during the maintenance of the software.  In this paper, we proposed a technique for change impact analysis (CIA) with fault prediction (FP) using machine learning techniques for OO software. In proposed method an intermediate OO program representation is proposed using a graph which detects the difference between the original program and the modified program.  For fault prediction, class level metrics are extracted from KC1 data set and 14 machine learning algorithms are trained on dataset. The genetic algorithm (GA) and correlation are used to extract significant features from the dataset. Trained prediction models are evaluated using classification accuracy (Acc). Our proposed approach consider various types of changes possible in the program, and test cases are selected to test  the modified code during regression testing and finds the fault in classes. Among the 14 machine learning algorithms random forest (RF) giving best accuracy than other algorithms.</p>"
pub.1129852362,Imbalanced metric learning for crashing fault residence prediction,"As the software crash usually does great harm, locating the fault causing the crash (i.e., the crashing fault) has always been a hot research topic. As the stack trace in the crash reports usually contains abundant information related the crash, it is helpful to find the root cause of the crash. Recently, researchers extracted features of the crash, then constructed the classification model on the features to predict whether the crashing fault resides in the stack trace. This process can accelerate the debugging process and save debugging efforts. In this work, we apply a state-of-the-art metric learning method called IML to crash data for crashing fault residence prediction. This method uses Mahalanobis distance based metric learning to learn high-quality feature representation by reducing the distance between crash instances with the same label and increasing the distance between crash instances with different labels. In addition, this method designs a new loss function that includes four types of losses with different weights to cope with the class imbalanced issue of crash data. The experiments on seven open source software projects show that our IML method performs significantly better than nine sampling based and five ensemble based imbalanced learning methods in terms of three performance indicators."
pub.1165321599,A Novel Developed Supervised Machine Learning System For Classification And Prediction of Software Faults Using NASA Dataset,"The software systems of modern computers are extremely complex and versatile. Therefore, it is essential to regularly detect and correct software design faults. In order to devote resources effectively towards the creation of trustworthy software, software companies are increasingly engaging in the practise of predicting fault-prone modules in advance of testing. These software fault prediction methods rely on the thoroughness with which prior software versions' fault as well as related code has been retrievedTime, energy, and money are all saved as a result. Increases the company's initial success and bottom line greatly by satisfying its clientele. Numerous academics have poured into this area throughout the years in an effort to raise the bar for all software. Nowadays, The most often used approaches in this field are those based on machine learning (ML). The field of ML seeks to perfect software capable of evolving as well as adapting in response to fresh data. This paper introduces a fresh approach for doing ML by bringing together a number of different expert systems. In order to reach agreement on which aspects of a software system need to be tested, the proposed multi-classifier model pools the strengths of the most effective classifiers. Several top-performing classifiers for defect prediction are put through their paces in an experiential evaluation. We test our method on 16 publicly available datasets from the NASA Metric Data Programme (MDP) repository at the promise repository. Parameters of confusion, recall, precision, recognition accuracy, etc., are evaluated and contrasted with existing schemes in a software analysis performed with the help of the python simulation tool with findings. The experimental outcomes demonstrate that by combining LGBM, XGBoost, and Voting classifiers, using a multi classifier approach, we are capable to significantly improve software fault prediction performance. The results of the investigation show that the suggested method will lead to better practical outcomes in the prediction of device failures."
pub.1170374156,CSOFS: Feature Selection Using Cuckoo Search Optimization Algorithm for Software Fault Detection,"The method of identifying and predicting software flaws or problems in software systems involves using historical data. Software fault prediction is a crucial topic of research in the field of software engineering because it enables developers to find probable flaws early on, which can save money and enhance the quality of the programme produced. The study’s objective is to determine how well the Cuckoo Search Optimization Algorithm can extract the features that are most important for correctly predicting software flaws. The prediction models were tested and trained using a dataset of software metrics, and the dataset was subjected to a variety of feature selection algorithms. We have performed an analysis by comparing the efficiency of various optimization algorithms namely evolutionary based Genetic Algorithm Feature Selection (GAFS), Differential Evolution Feature Selection (DEFS), and swarm based algorithms like Ant Colony Optimization Feature Selection (ACOFS) and Particle Swarm Optimization Feature Selection (PSOFS) with respect to Cuckoo Search Optimization Algorithm (CSOFS). The results from the output tables for various metrics prove that feature selection using CSO can significantly increase the accuracy of the predictive model, as well as reduce the complexity of the models. This study’s findings have crucial implications for developing a software failure prediction models that is more accurate and efficient."
pub.1095772554,Reliability and risk analysis for software that must be safe,"Remaining failures, total failures, test time required to attain a given fraction of remaining failures, and time to next failure are useful reliability metrics for: providing confidence that the software has achieved reliability goals; rationalizing how long to test a piece of software; and analyzing the risk of not achieving remaining failure and time to next failure goals. Having predictions of the extent that the software is not fault free (remaining failures) and whether it is likely to survive a mission (time to next failure) provide criteria for assessing the risk of deploying the software. Furthermore, the fraction of remaining failures can be used as both a program quality goal in predicting test time requirements and, conversely as an indicator of program quality as a function of test time expended. We show how these software reliability predictions can increase confidence in the reliability of safety critical software such as the NASA Space Shuttle Primary Avionics Software."
pub.1042971595,An empirical evaluation of classification algorithms for fault prediction in open source projects," Creating software with high quality has become difficult these days with the fact that size and complexity of the developed software is high. Predicting the quality of software in early phases helps to reduce testing resources. Various statistical and machine learning techniques are used for prediction of the quality of the software. In this paper, six machine learning models have been used for software quality prediction on five open source software. Varieties of metrics have been evaluated for the software including C & K, Henderson & Sellers, McCabe etc. Results show that Random Forest and Bagging produce good results while Naïve Bayes is least preferable for prediction."
pub.1086072080,Evolutionary Computation-Based Techniques Over Multiple Data Sets: An Empirical Assessment,"In the realm of software testing various organizations wish to predict the faults in their software systems prior to their deployment. This improves the delivered quality and also reduces the maintenance effort. A multitude of software metrics and statistical models have been developed to solve this problem and one such method is called defect prediction. Defect prediction is the process of identifying the defects in the software program prior to its deployment. In recent times, a class of learners called evolutionary computation (EC) techniques has emerged. These EC techniques apply the Darwinian principle of ‘survival of the fittest’. This study performs an empirical assessment of the performance of various EC techniques in the prediction of software defects over multiple data sets. An empirical assessment compares and assesses the performance capability of 16 EC techniques for evaluating the relationship between object-oriented metrics and defect prediction. The developed models are validated using 7 data sets obtained from open source software systems developed by the Software Foundation. On investigating their predictive capabilities and comparative performance, it was found that a majority of EC techniques proved to be highly effective. DTG (a hybridized algorithm) was observed to be the best performing technique. The work done in the current study shows that EC techniques are very effective and can be highly beneficial to testers in the realm of defect prediction in the future."
pub.1048213696,Empirical Assessment of LR- and ANN-Based Fault Prediction Techniques,"At the present time, because of our reliance on software systems, there is a need for dynamic dependability assessment to ensure that these systems will perform as specified under various conditions. One approach to achieving this is to dynamically assess the modules for software fault predictions. Software fault prediction, as well as inspection and testing, are still the prevalent methods of assuring the quality of software. Software metrics-based approaches to build quality models can predict whether a software module will be fault-prone or not. The application of these models can assist to focus quality improvement efforts on modules that are likely to be faulty during operations, thereby cost-effectively utilizing the software quality testing and enhancement resources. In the present paper, the statistical model, such as logistic regression (LR), and the machine learning approaches, such as artificial neural networks (ANN), have been investigated for predicting fault proneness. We evaluate the two predictor models on three main components: a single data sample, a common evaluation parameter, and cross validations. The study shows that ANN techniques perform better than LR; but that LR, being a simpler technique, is also a good quality indicator technique."
pub.1085635239,Enhancing Software Maintenance via Early Prediction of Fault-Prone Object-Oriented Classes,"Object-oriented software (OOS) is dominating the software development world today and thus, has to be of high quality and maintainable. However, their recent size and complexity affects the delivering of software products with high quality as well as their maintenance. In the perspective of software maintenance, software change impact analysis (SCIA) is used to avoid performing change in the “dark”. Unfortunately, OOS classes are not without faults and the existing SCIA techniques only predict impact set. The intuition is that, if a class is faulty and change is implemented on it, it will increase the risk of software failure. To balance these, maintenance should incorporate both impact and fault-proneness (FP) predictions. Therefore, this paper propose an extended approach of SCIA that incorporates both activities. The goal is to provide important information that can be used to focus verification and validation efforts on the high risk classes that would probably cause severe failures when changes are made. This will in turn increase maintenance, testing efficiency and preserve software quality. This study constructed a prediction model using software metrics and faults data from NASA data set in the public domain. The results obtained were analyzed and presented. Additionally, a tool called Class Change Recommender (CCRecommender) was developed to assist software engineers compute the risks associated with making change to any OOS class in the impact set."
pub.1062959706,A SYSTEMATIC REVIEW OF THE EMPIRICAL VALIDATION OF OBJECT-ORIENTED METRICS TOWARDS FAULT-PRONENESS PREDICTION,"Object-oriented (OO) approaches of software development promised better maintainable and reusable systems, but the complexity resulting from its features usually introduce some faults that are difficult to detect or anticipate during software change process. Thus, the earlier they are detected, found and fixed, the lesser the maintenance costs. Several OO metrics have been proposed for assessing the quality of OO design and code and several empirical studies have been undertaken to validate the impact of OO metrics on fault proneness (FP). The question now is which metrics are useful in measuring the FP of OO classes? Consequently, we investigate the existing empirical validation of CK + SLOC metrics based on their state of significance, validation and usefulness. We used systematic literature review (SLR) methodology over a number of relevant article sources, and our results show the existence of 29 relevant empirical studies. Further analysis indicates that coupling, complexity and size measures have strong impact on FP of OO classes. Based on the results, we therefore conclude that these metrics can be used as good predictors for building quality fault models when that could assist in focusing resources on high risk components that are liable to cause system failures, when only CK + SLOC metrics are used."
pub.1014190940,A hybrid one-class rule learning approach based on swarm intelligence for software fault prediction,"Software testing is a fundamental activity in the software development process aimed to determine the quality of software. To reduce the effort and cost of this process, defect prediction methods can be used to determine fault-prone software modules through software metrics to focus testing activities on them. Because of model interpretation and easily used by programmers and testers some recent studies presented classification rules to make prediction models. This study presents a rule-based prediction approach based on kernel k-means clustering algorithm and Distance based Multi-objective Particle Swarm Optimization (DSMOPSO). Because of discrete search space, we modified this algorithm and named it DSMOPSO-D. We prevent best global rules to dominate local rules by dividing the search space with kernel k-means algorithm and by taking different approaches for imbalanced and balanced clusters, we solved imbalanced data set problem. The presented model performance was evaluated by four publicly available data sets from the PROMISE repository and compared with other machine learning and rule learning algorithms. The obtained results demonstrate that our model presents very good performance, especially in large data sets."
pub.1167040571,Analysis of Feature Selection Methods in Software Defect Prediction Models,"Improving software quality by proactively detecting potential defects during development is a major goal of software engineering. Software defect prediction plays a central role in achieving this goal. The power of data analytics and machine learning allows us to focus our efforts where they are needed most. A key factor in the success of software fault prediction is selecting relevant features and reducing data dimensionality. Feature selection methods contribute by filtering out the most critical attributes from a plethora of potential features. These methods have the potential to significantly improve the accuracy and efficiency of fault prediction models. However, the field of feature selection in the context of software fault prediction is vast and constantly evolving, with a variety of techniques and tools available. Based on these considerations, our systematic literature review conducts a comprehensive investigation of feature selection methods used in the context of software fault prediction. The research uses a refined search strategy involving four reputable digital libraries, including IEEE Explore, Science Direct, ACM Digital Library, and Springer Link, to provide a comprehensive and exhaustive review through a rigorous analysis of 49 selected primary studies from 2014. The results highlight several important issues. First, there is a prevalence of filtering and hybrid feature selection methods. Second, single classifiers such as Naïve Bayes, Support Vector Machine, and Decision Tree, as well as ensemble classifiers such as Random Forest, Bagging, and AdaBoost are commonly used. Third, evaluation metrics such as area under the curve, accuracy, and F-measure are commonly used for performance evaluation. Finally, there is a clear preference for tools such as WEKA, MATLAB, and Python. By providing insights into current trends and practices in the field, this study offers valuable guidance to researchers and practitioners to make informed decisions to improve software fault prediction models and contribute to the overall improvement of software quality."
pub.1144445603,Fuzzy Cognitive Maps for Software Fault Prediction,"Detection of faulty modules in the early stages of the software development life cycle is crucial for the testing procedures. Several software metrics are collected during and end of the development process to represent software modules. By utilizing these collections of module representation, machine learning methods are utilized to predict the fault-prone modules. However, these methods lack interpretability and generalization utilities. In other words, these solutions are highly dependent on the underlying dataset since they aim to discover the hidden relationship between the input to the output in one direction. Addressing these issues, a fuzzy cognitive map has been first proposed to both provide interpretability and to eliminate data dependency for software fault prediction. The proposed cognitive map was learned from experts without the need or dependency on a prior project dataset. In addition to the input-output relations, the relations between inputs were jointly considered. Basing two Mamdani fuzzy inference systems' prediction performance, the proposed map could provide more plausible and accurate decisions in predicting the faulty modules."
pub.1171507325,An Improved and Optimized Random Forest Based Approach to Predict the Software Faults,"Effective software fault prediction is crucial for minimizing errors during software development and preventing subsequent failures. This research introduces an enhanced Random Forest-based approach for predicting software faults, specifically focusing on the NASA JM1 dataset. The dataset comprises 21 software metrics indicating the presence or absence of faults in a module, and it is utilized to evaluate the proposed approach. The study delves into the intricacies of the NASA dataset, detailing the cleaning process and addressing class imbalance through Synthetic Minority Over-sampling Technique (SMOTE). The core of our approach involves the implementation and fine-tuning of the Random Forest classifier, with a specific focus on optimizing hyperparameters to enhance predictive accuracy. In comparative evaluations with standard machine learning models, our proposed approach demonstrated superior performance, achieving an accuracy of 82.96% and an F1 score of 89.53%. Notably, we emphasize the significance of software defects and their potential to cause failures and crashes during software development, leading to substantial organizational losses. The paper provides a comprehensive examination of different aspects of the machine learning model, offering detailed insights, examples, and illustrative figures to enhance the understanding of our proposed approach."
pub.1095050891,An Empirical Analysis of the Impact of Comment Statements on Fault-Proneness of Small-Size Module,"Code size metrics are commonly useful in predicting fault-prone modules, and the larger module tends to be more faulty. In other words, small-size modules are considered to have lower risks of fault. However, since the majority of modules in a software are often small-size, many “small but faulty” modules have been found in the real world. Hence, another fault-prone module prediction method, intended for small-size module, is also required. Such a new method for small-size module should use metrics other than code size since all modules are small size. This paper focuses on “comments” written in the source code from a novel perspective of size-independent metrics; comments have not been drawn much attention in the field of fault prone module prediction. The empirical study collects 11, 512 small-size modules, whose LOC are less than the median, from three major open source software, and analyzes the relationship between the lines of comments and the fault-proneness in the set of small-size modules. The empirical results show the followings: 1) A module in which some comments are written is more likely to be faulty than non-commented ones; the fault rate of commented modules is about 1.8-3.5 times higher than that of non-commented ones. 2) Writing one to four lines of comments would be thresholds of the above tendency."
pub.1043759093,Genetic Feature Selection for Software Defect Prediction,"Recently, software defect prediction is an important research topic in the software engineering field. The accurate prediction of defect prone software modules can help the software testing effort, reduce costs, and improve the software testing process by focusing on fault-prone module. Software defect data sets have an imbalanced nature with very few defective modules compared to defect-free ones. The software defect prediction performance also decreases significantly because the dataset contains noisy attributes. In this research, we propose the combination of genetic algorithm and bagging technique for improving the performance of the software defect prediction. Genetic algorithm is applied to deal with the feature selection, and bagging technique is employed to deal with the class imbalance problem. The proposed method is evaluated using the data sets from NASA metric data repository. Results have indicated that the proposed method makes an impressive improvement in prediction performance for most classifiers."
pub.1095780578,Incorporating code coverage in the reliability estimation for fault-tolerant software,"Presents a technique that uses coverage measures in reliability estimation for fault-tolerant programs, particularly N-version software. This technique exploits both coverage and time measures collected during testing phases for the individual program versions and the N-version software system for reliability prediction. The application of this technique to single-version software was presented in our previous research (IEEE 3rd Int. Symp. on Software Metrics, Berlin, Germany, March 1996). In this paper, we extend this technique and apply it on the N-version programs. The results obtained from the experiment conducted on an industrial project demonstrate that our technique significantly reduces the hazard of reliability overestimation for both single-version and multi-version fault-tolerant software systems."
pub.1094952844,Getting a handle on the fault injection process: validation of measurement tools,"In any manufacturing environment, the fault injection rate might be considered one of the most meaningful criterion to evaluate the goodness of the development process. In our field, the estimates of such a rate are often oversimplified or misunderstood generating unrealistic expectations on their prediction power. The computation of fault injection rates in software development requires accurate and consistent measurement, which translates into demanding parallel efforts for the development organization. This paper presents the techniques and mechanisms that can be implemented in a software development organization to provide a consistent method of anticipating fault content and structural evolution across multiple projects over time. The initial estimates of fault insertion rates can serve as a baseline against which future projects can be compared to determine whether progress is being made in reducing the fault insertion rate, and to identify those development techniques that seem to provide the greatest reduction."
pub.1024397398,An approach for early prediction of software reliability,"In the early stages of development, failure information is not available to quantitatively measure reliability of a software product. In this context, we propose an approach to predict software reliability early in the product development stages from design metrics. First we predict reliabilities of the components of a system. For this, we categorize the different kinds of faults that can occur in a component during its development and identify the design metrics that correlate to these faults. We construct a Bayesian Belief Network (BBN) model to predict reliabilities of the components using the identified design metrics. Based on predicted reliabilities and usage frequencies of the components of a system, we determine the reliability of the system. The applicability of our proposed model is illustrated through a case study. Results obtained from our case study indicate the effectiveness of our approach"
pub.1143541471,A Comprehensive Evaluation for Burr-Type NHPP-based Software Reliability Models,"In this paper, we summarize the so-called Burr-type software reliability models (SRMs) based on the non-homogeneous Poisson process (NHPP) and comprehensively evaluate the model performances by comparing with the existing NHPP-based SRMs. Two kinds of software fault count data are considered; fault-detection time-domain data and fault-detection time-interval data (group data). For 8 data sets in each fault count type, we estimate the model parameters by means of the maximum likelihood estimation and evaluate the performance metrics in terms of goodness-of-fit and prediction. It is shown that the Burr-type NHPP-based SRMs could show the better performances than the existing NHPP-based SRMs in many cases."
pub.1094581627,A Scenario-Based Approach to Predicting Software Defects Using Compressed C4.5 Model,"Defect prediction approaches use software metrics and fault data to learn which software properties are associated with what kinds of software faults in programs. One trend of existing techniques is to predict the software defects in a program construct (file, class, method, and so on) rather than in a specific function scenario, while the latter is important for assessing software quality and tracking the defects in software functionalities. However, it still remains a challenge in that how a functional scenario is derived and how a defect prediction technique should be applied to a scenario. In this paper, we propose a scenario-based approach to defect prediction using compressed C4.5 model. The essential idea of this approach is to use a k-medoids algorithm to cluster functions followed by deriving functional scenarios, and then to use the C4.5 model to predict the fault in the scenarios. We have also conducted an experiment to evaluate the scenario-based approach and compared it with a file-based prediction approach. The experimental results show that the scenario-based approach provides with high performance by reducing the size of the decision tree by 52.65% on average and also slightly increasing the accuracy."
pub.1125947973,Theoretical Evaluation of Software Coupling Metrics,"Software module coupling is an important design parameter that can be used in various studies including fault prediction, impact analysis, re-modularization assessment, software vulnerabilities assessment, etc. However, two couplings can vary in important coupling factors' coverage. This paper aims to evaluate the coupling metrics to their coverage of important coupling factors'. We perform a thorough survey of coupling metrics, that ends up with the collection of numerous coupling metrics. After that, we evaluate these metrics by their coverage of important coupling factors. The mapping of coupling metrics with the coupling factors shows that the coupling levels been considered by many metrics. Yet, the difference between these levels has been ignored by most of the metrics. Moreover, the broadness, hiddenness, and rigidness of data flow are ignored by most coupling metrics. Apart from that, the combined effect of these aspects is ignored by all the metrics."
pub.1182015138,Cross-project software defect prediction based on the reduction and hybridization of software metrics,"Cross-project defect prediction (CPDP) plays an essential role in identifying potential defects in target projects, especially those with limited historical data, using relevant information from similar source projects. The current studies focused on three main types of software metrics for CPDP: static metrics, code-change metrics, and semantic features. However, these existing CPDP studies encounter two primary challenges: class overlap due to reduced feature dimensions and multicollinearity from integrating various software metrics. To address these challenges, we propose a CPDP model based on both reduction and hybridization techniques (RH-CPDP). The proposed model uses hybrid deep neural networks as a hybridization technique to combine the essential metrics from all metric categories, addressing the issue of class overlap to enhance prediction model efficiency. Principal component analysis (PCA) was used as a reduction method to keep the number of metrics used small, focusing on influential relationships among metrics and fault proneness and avoiding the multicollinearity problem. The experimental analysis conducted using nine open-source projects from the PROMISE dataset demonstrates that RH-CPDP surpasses current CPDP methods (TCSBoost, TPTL, DA-KTSVMO, DBN, and 3SW-MSTL) regarding area under the curve (AUC) and F1-measure. These findings highlight the effectiveness of RH-CPDP in improving the performance of CPDP techniques."
pub.1124826920,Boosted Relief Feature Subset Selection and Heterogeneous Cross Project Defect Prediction using Firefly Particle Swarm Optimization,"The exponential growth in the field of information technology, need for quality-based software development is highly demanded. The important factor to be focused during the software development is software defect detection in earlier stages. Failure to detect hidden faults will affect the effectiveness and quality of the software usage and its maintenance. In traditional software defect prediction models, projects with same metrics are involved in prediction process. In recent years, active topic is dealing with Cross Project Defect Prediction (CPDP) to predict defects on software project from other software projects dataset. Still, traditional cross project defect prediction approaches also require common metrics among the dataset of two projects for constructing the defect prediction techniques. Suppose if cross project dataset with different metrics has to be used for defect prediction then these methods become infeasible. To overcome the issues in software defect prediction using Heterogeneous cross projects dataset, this paper introduced a Boosted Relief Feature Subset Selection (BRFSS) to handle the two different projects with Heterogeneous feature sets. BRFSS employs the mapping approach to embed the data from two different domains into a comparable feature space with a lower dimension. Based on the similarity measure the difference among the mapped domains of dataset are used for prediction process. This work used five different software groups with six different datasets to perform heterogeneous cross project defect prediction using firefly particle swarm optimization. To produce optimal defect prediction in the Heterogeneous environment, the knowledge of particle swarm optimization by inducing firefly algorithm. The simulation result is compared with other standard models, the outcome of the result proved the efficiency of the prediction process while using firefly enabled particle swarm optimization."
pub.1151581713,Software Fault Prediction Using Deep Learning Techniques,"Software fault prediction (SFP) techniques are used to identify faults at the early stages of the software development life cycle (SDLC). We find machine learning techniques as commonly used techniques for SFP as compared to deep learning methods which can produce more accurate results. Deep learning offers exceptional results in a variety of domains such as computer vision, natural language processing, speech recognition, etc. In this study, we use three deep learning methods, namely, Long Short Term Memory (LSTM), Bidirectional LSTM (BILSTM), and Radial Basis Function Network (RBFN) to predict software faults and compare our results with existing models to show how our results are more accurate. In our study, we use Chidamber and Kemerer (C&K) metrics-based datasets to conduct experiments and test our proposed algorithm. We conclude that LSTM and BILSTM perform better whereas RBFN is faster in producing the required results. We use k-fold cross validation to do the model evaluation. Our proposed models provide a more accurate and efficient SFP mechanism to software developers."
pub.1171392361,Coverage-enhanced fault diagnosis for Deep Learning programs: A learning-based approach with hybrid metrics,"Context: Given the data-driven paradigm inherent to Deep Learning (DL), it is inevitable that DL software will exhibit incorrect behavior in real-world applications. DL programs have been identified as a primary source of DL faults. To tackle this, researchers have devised a unique framework that approaches fault diagnosis as a learning task, which leverages runtime data as metrics to construct predictive models, enabling effective fault diagnosis. Object: In this paper, we aim to propose new metrics, especially from the coverage view, to enhance the performance of fault diagnosis models. Method: We combine coverage criteria and statistical operators to propose 80 coverage metrics, which summarize the trend of coverage values in the model training procedure. We construct hybrid prediction models by combining our new coverage metrics and existing runtime metrics under four widely used classifiers. Results: To examine whether adding our new coverage metrics performs well in DL program fault diagnosis, we conduct our experiments on six widely used datasets under four indicators (i.e., accuracy, F1 score, AUC, and MCC). Through the experiments, we observe that (a) coverage metrics are not redundant with respect to the original runtime metrics, and (b) adding extra coverage metrics can significantly enhance the performance of fault diagnosis models. Conclusions: Our study shows that our proposed coverage metrics are helpful in constructing effective fault diagnosis models for DL programs."
pub.1068093467,Mining Co-location Relationships among Bug Reports to Localize Fault-Prone Modules,"Automated bug localization is an important issue in software engineering. In the last few decades, various proactive and reactive localization approaches have been proposed to predict the fault-prone software modules. However, most proactive or reactive approaches need source code information or software complexity metrics to perform localization. In this paper, we propose a reactive approach which considers only bug report information and historical revision logs. In our approach, the co-location relationships among bug reports are explored to improve the prediction accuracy of a state-of-the-art learning method. Studies on three open source projects reveal that the proposed scheme can consistently improve the prediction accuracy in all three software projects by nearly 11.6% on average."
pub.1094352735,Supplementing Object-Oriented Software Change Impact Analysis with Fault-Proneness Prediction,"Software changes are inevitable during maintenance, Object-oriented software (OOS) in particular. For change not to be performed in the “dark”, software change impact analysis (SCIA) is used. However, due to the exponential growth in the size and complexity of OOS, classes are not without faults and the existing SCIA techniques only predict change impact set. This means that a change implemented on a faulty class could increase the likelihood for software failure. To avoid this issue, maintenance has to incorporate both change impact and fault-proneness (FP) prediction. Therefore, this paper proposes an extended approach for SCIA that integrates both activities. The goal is to assist software engineers with the necessary information of focusing verification and validation activities on the high risk components that would probably cause severe failures which in turn can boost maintenance and testing efficiency. This study built a model for predicting FP using software metrics and faults data from NASA data set in the public domain. The results obtained were analyzed and presented. Additionally, a class change recommender (CCRecommender) tool was developed to assist in computing the risks associated with making change to any component in the impact set."
pub.1153922976,Software Defect Prediction using Deep Learning by Correlation Clustering of Testing Metrics,"The software industry has made significant efforts in recent years to enhance software quality in businesses. The use of proactively defect prediction in the software will assist programmers and white box testing in detecting issues early, saving time and money. Conventional software defect prediction methods focus on traditional source code metrics such as code complexities, lines of code, and so on. These capabilities, unfortunately, are unable to retrieve the semantics of source code. In this paper, we have presented a novel Correlation Clustering fine-tuned CNN (CCFT-CNN) model based on testing Metrics. CCFT-CNN can predict the regions of source code that contain faults, errors, and bugs. Abstract Syntax Tree (AST) tokens are extracted as testing Metrics vectors from the source code. The correlation among AST testing Metrics is performed and clustered as a more relevant feature vector and fed into Convolutional Neural Network (CNN). Then, to enhance the accuracy of defect prediction, fine-tuning of the CNN model is performed by applying hyperparameters. The result analysis is performed on the PROMISE dataset that contains samples of open-source Java applications such as Camel Dataset, Jedit dataset, Poi dataset, Synapse dataset, Xerces dataset, and Xalan dataset. The result findings show that the CCFT- CNN model increases the average F-measure by 2% when compared to the baseline model."
pub.1042261595,A comparative study of feature-ranking and feature-subset selection techniques for improved fault prediction,"The quality of a fault prediction model depends on the software metrics that are used to build the prediction model. Feature selection represents a process of selecting a subset of relevant features that may lead to build improved prediction models. Feature selection techniques can be broadly categorized into two subcategories: feature-ranking and feature-subset selection. In this paper, we present a comparative investigation of seven feature-ranking techniques and eight feature-subset selection techniques for improved fault prediction. The performance of these feature selection techniques is evaluated using two popular machine-learning classifiers: Naive Bayes and Random Forest, over fourteen software project's fault-datasets obtained from the PROMISE data repository. The performances were measured using F-measure and AUC values. Our results demonstrated that feature-ranking techniques produced better results compared to feature-subset selection techniques. Among, the feature-ranking techniques used in the study, InfoGain and PCA techniques provided the best performance over all the datasets, while for feature-subset selection techniques ClassifierSubsetEval and Logistic Regression produced better results against their peers."
pub.1004699968,Class noise detection based on software metrics and ROC curves,"Noise detection for software measurement datasets is a topic of growing interest. The presence of class and attribute noise in software measurement datasets degrades the performance of machine learning-based classifiers, and the identification of these noisy modules improves the overall performance. In this study, we propose a noise detection algorithm based on software metrics threshold values. The threshold values are obtained from the Receiver Operating Characteristic (ROC) analysis. This paper focuses on case studies of five public NASA datasets and details the construction of Naive Bayes-based software fault prediction models both before and after applying the proposed noise detection algorithm. Experimental results show that this noise detection approach is very effective for detecting the class noise and that the performance of fault predictors using a Naive Bayes algorithm with a logNum filter improves if the class labels of identified noisy modules are corrected."
pub.1171150752,Ensemble feature ranking approach for software fault prediction,"Software fault prediction, which aims to find and fix probable flaws before they appear in real-world settings, is an essential component of software quality assurance. This article provides a thorough analysis of the use of feature ranking algorithms for successful software failure prediction. In order to choose and prioritise the software metrics or qualities most important to fault prediction models, feature ranking approaches are essential. The proposed focus on applying an ensemble feature ranking algorithm to a specific software fault dataset, addressing the challenge posed by the dataset’s high dimensionality. In this extensive study, we examined the effectiveness of multiple machine learning classifiers on six different software projects: jedit, ivy, prop, xerces, tomcat, and poi, utilising feature selection strategies. In order to evaluate classifier performance under two scenarios—one with the top 10 features and another with the top 15 features—our study sought to determine the most relevant features for each project. SVM consistently performed well across the six datasets, achieving noteworthy results like 98.74% accuracy on “jedit” (top 10 features) and 91.88% on “tomcat” (top 10 features). Random Forest achieving 89.20% accuracy on the top 15 features, on “ivy.” In contrast, NB repeatedly recording the lowest accuracy rates, such as 51.58% on “poi” and 50.45% on “xerces” (the top 15 features). These findings highlight SVM and RF as the top performers, whereas NB was consistently the least successful classifier. The findings suggest that the choice of feature ranking algorithm has a substantial impact on the fault prediction models’ predictive accuracy and effectiveness. When using various ranking systems, the research also analyses the trade-offs between computing complexity and forecast accuracy."
pub.1124557761,Early Reliability Prediction Model Integrating Halstead’s Metrics and Fuzzy Usage,"Software reliability is one of the main quality parameters. Accurately, predicting software reliability helps in estimating resource planning and fixing failures. Halstead’s software science can be extended to predict the faults before the testing phase for component-based system faults. In component-based software, the desired reusability can be achieved if components are reliable. As the usage of faulty component increases, the overall reliability of the software decreases. Further, as front-end and back-end components have different faults and different levels of usage, and hence, one needs to understand the functionality separately. A novel fuzzy model is proposed to predict the reliability of the component-based system. The independent study of faults of each component and errors occurred in six months is observed. The proposed model was validated statistically by comparing the predicted and estimated value of reliability."
pub.1132865871,An Empirical Framework to Investigate the Impact of Bug Fixing on Internal Quality Attributes,"Software testing is the process of fixing bugs by changing the design of the software or simple logic of the software. Researchers have proposed many tools and methods using machine learning techniques to assist practitioners in decision making and automating software engineering tasks. These tools help to find the faulty classes at the starting phase of the software development life cycle. After finding faulty classes using these tools, testers used different techniques to find and fix these faults. The early identification of the faults or bugs fixing process helps to improves the quality of software and reduces the cost required to fix these faults or bugs. The primary objective of this work is to understand whether faults present in code elements are indicators of problems in the design of the software or not. This work investigates the impact of bug fixing operation on four popular internal quality attributes such as complexity, cohesion, inheritance, and coupling. The above investigation has been validated using thirteen different projects. Furthermore, we have also investigated the possibility of prediction models for predicting changes in internal quality attributes. These prediction models are trained using five different classifiers on balance data as well as original data and validated using fivefold cross-validation. The experimental results show that the predictive power of models using LSSVM with the polynomial kernel is better as compared to other techniques. The experimental results also show that the bugs are present in the class having at least one critical attribute in more than 80% of cases. Furthermore, the consistent value of AUC reveals that the prediction of changes in the internal quality attribute is possible using source code metrics."
pub.1122331868,Effect of Feature Selection in Software Fault Detection,"Abstract
The quality of software is enormously affected by the faults associated with it. Detection of faults at a proper stage in software development is a challenging task and plays a vital role in the quality of the software. Machine learning is, now a days, a commonly used technique for fault detection and prediction. However, the effectiveness of the fault detection mechanism is impacted by the number of attributes in the publicly available datasets. Feature selection is the process of selecting a subset of all the features that are most influential to the classification and it is a challenging task. This paper thoroughly investigates the effect of various feature selection techniques on software fault classification by using NASA’s some benchmark publicly available datasets. Various metrics are used to analyze the performance of the feature selection techniques. The experiment discovers that the most important and relevant features can be selected by the adopted feature selection techniques without sacrificing the performance of fault detection."
pub.1031838681,Identification of Error Prone Classes for Fault Prediction Using Object Oriented Metrics,Various studies have found that software metrics can predict class error proneness. However their study is focused on the relationship between class error proneness and software metrics during the development phase of software projects not in system’s post-release evolution. This study is focused on the three releases of Javassist- open source java based software. This paper describes how we calculated the object-oriented metrics to illustrate errorproneness detection. Using Findbugs we collected errors in the post-release system and applied logistic regression to find that some metrics can predict the class error proneness in post release evolution of system. We also calculated model’s accuracy by applying one model on other version’s data.
pub.1093532802,Reducing Corrective Maintenance Effort Considering Module's History,"A software package evolves in time through various maintenance release steps whose effectiveness depends mainly on the number of faults left In the modules. The testing phase is therefore critical to discover these faults. The purpose of this paper is to show a criterion to estimate an optimal repartition of available testing time among software modules: in a maintenance release. In order to achieve this objective we have used fault prediction techniques based both on classical complexity metrics and an additional, innovative factor related to the module's age in terms of release. This method can actually diminish corrective maintenance effort, while assuring a high reliability for the delivered software."
pub.1062959598,AN EMPIRICAL STUDY OF FEATURE RANKING TECHNIQUES FOR SOFTWARE QUALITY PREDICTION,"The primary goal of software quality engineering is to produce a high quality software product through the use of some specific techniques and processes. One strategy is applying data mining techniques to software metric and defect data collected during the software development process to identify potential low-quality program modules. In this paper, we investigate the use of feature selection in the context of software quality estimation (also referred to as software defect prediction), where a classification model is used to predict whether program modules (instances) are fault-prone or not-fault-prone. Seven filter-based feature ranking techniques are examined. Among them, six are commonly used, and the other one, named signal to noise ratio (SNR), is rarely employed. The objective of the paper is to compare these seven techniques for various software data sets and assess their effectiveness for software quality modeling. A case study is performed on 16 software data sets, and classification models are built with five different learners and evaluated with two performance metrics. Our experimental results are summarized based on statistical tests for significance. The main conclusion is that the SNR technique performs as well as the best performer of the six commonly used techniques."
pub.1144519990,EkmEx - an extended framework for labeling an unlabeled fault dataset,"Software fault prediction (SFP) is a quality assurance process that identifies if certain modules are fault-prone (FP) or not-fault-prone (NFP). Hence, it minimizes the testing efforts incurred in terms of cost and time. Supervised machine learning techniques have capacity to spot-out the FP modules. However, such techniques require fault information from previous versions of software product. Such information, accumulated over the life-cycle of software, may neither be readily available nor reliable. Currently, clustering with experts’ opinions is a prudent choice for labeling the modules without any fault information. However, the asserted technique may not fully comprehend important aspects such as selection of experts, conflict in expert opinions, catering the diverse expertise of domain experts etc. In this paper, we propose a comprehensive framework named EkmEx that extends the conventional fault prediction approaches while providing mathematical foundation through aspects not addressed so far. The EkmEx guides in selection of experts, furnishes an objective solution for resolve of verdict-conflicts and manages the problem of diversity in expertise of domain experts. We performed expert-assisted module labeling through EkmEx and conventional clustering on seven public datasets of NASA. The empirical outcomes of research exhibit significant potential of the proposed framework in identifying FP modules across all seven datasets."
pub.1031677378,Fault detection and prediction in an open-source software project,"Software maintenance continues to be a time and resource intensive activity. Any efforts that help to address the maintenance bottleneck within the software lifecycle are welcome. One area where such efforts are useful is in the identification of the parts of the source-code of a software system that are most likely to contain faults and thus require changes. We have carried out an empirical study where we have merged information from the CVS repository and the Bugzilla database for an open-source software project to investigate whether or not parts of the source-code are faulty, the number and severity of faults and the number and types of changes associated with parts of the system. We present an analysis of this information, showing that Pareto's Law holds and we evaluate the usefulness of the Chidamber and Kemerer metrics for identifying the fault-prone classes in the system analysed."
pub.1117877625,Software Fault Proneness Prediction with Group Lasso Regression: On Factors that Affect Classification Performance,"Machine learning algorithms have been used extensively for software fault proneness prediction. This paper presents the first application of Group Lasso Regression (G-Lasso) for software fault proneness classification and compares its performance to six widely used machine learning algorithms. Furthermore, we explore the effects of two factors on the prediction performance: the effect of imbalance treatment using the Synthetic Minority Over-sampling Technique (SMOTE), and the effect of datasets used in building the prediction models. Our experimental results are based on 22 datasets extracted from open source projects. The main findings include: (1) G-Lasso is robust to imbalanced data and significantly outperforms the other machine learning algorithms with respect to the Recall and G-Score, i.e., the harmonic mean of Recall and (1- False Positive Rate). (2) Even though SMOTE improved the performance of all learners, it did not have statistically significant effect on G-Lasso’s Recall and G-Score. Random Forest was in the top performing group of learners for all performance metrics, while Naive Bayes performed the worst of all learners. (3) When using the same change metrics as features, the choice of the dataset had no effect on the performance of most learners, including G-Lasso. Naive Bayes was the most affected, especially when balanced datasets were used."
pub.1138509292,A Classification Model for Software Bug Prediction Based on Ensemble Deep Learning Approach Boosted with SMOTE Technique,"Thaher, ThaerKhamayseh, FaisalIn the software development process, the testing phase plays a vital role in assessing software quality. Limited resources pose a challenge in achieving this purpose efficiently. Therefore, early stage procedures such as software fault prediction (SFP) are utilized to facilitate the testing process in an optimal way. SFP aims to predict fault-prone components early based on some software metrics (features). Machine learning (ML) techniques have proven superior performance in tackling this problem. However, there is no best classifier to handle all possible classification problems. Thus, building a reliable SFP model is still a research challenge. The purpose of this paper is to introduce an efficient classification framework to improve the performance of the SFP. For this purpose, an ensemble of multi-layer perceptron (MLP) deep learning algorithm boosted with synthetic minority oversampling technique (SMOTE) is proposed. The proposed model is benchmarked and assessed using sixteen real-world software projects selected from the PROMISE software engineering repository. The comparative study revealed that ensemble MLP achieved promising prediction quality on the majority of datasets compared to other traditional classifiers as well as those in preceding works."
pub.1019749240,Analogy-Based Practical Classification Rules for Software Quality Estimation,"Software metrics-based quality estimation models can be effective tools for identifying which modules are likely to be fault-prone or not fault-prone. The use of such models prior to system deployment can considerably reduce the likelihood of faults discovered during operations, hence improving system reliability. A software quality classification model is calibrated using metrics from a past release or similar project, and is then applied to modules currently under development. Subsequently, a timely prediction of which modules are likely to have faults can be obtained. However, software quality classification models used in practice may not provide a useful balance between the two misclassification rates, especially when there are very few faulty modules in the system being modeled.This paper presents, in the context of case-based reasoning, two practical classification rules that allow appropriate emphasis on each type of misclassification as per the project requirements. The suggested techniques are especially useful for high-assurance systems where faulty modules are rare. The proposed generalized classification methods emphasize on the costs of misclassifications, and the unbalanced distribution of the faulty program modules. We illustrate the proposed techniques with a case study that consists of software measurements and fault data collected over multiple releases of a large-scale legacy telecommunication system. In addition to investigating the two classification methods, a brief relative comparison of the techniques is also presented. It is indicated that the level of classification accuracy and model-robustness observed for the case study would be beneficial in achieving high software reliability of its subsequent system releases. Similar observations are made from our empirical studies with other case studies."
pub.1094644860,Predicting Fault Proneness of Classes Trough a Multiobjective Particle Swarm Optimization Algorithm,"Software testing is a fundamental software engineering activity for quality assurance that is also traditionally very expensive. To reduce efforts of testing strategies, some design metrics have been used to predict the fault-proneness of a software class or module. Recent works have explored the use of Machine Learning (ML) techniques for fault prediction. However most used ML techniques can not deal with unbalanced data and their results usually have a difficult interpretation. Because of this, this paper introduces a Multi-Objective Particle Swarm Optimization (MOPSO) algorithm for fault prediction. It allows the creation of classifiers composed by rules with specific properties by exploring Pareto dominance concepts. These rules are more intuitive and easier to understand because they can be interpreted independently one of each other. Furthermore, an experiment using the approach is presented and the results are compared to the other techniques explored in the area."
pub.1150402106,A Study of Filter-Based Feature Selection in Software Fault Prediction,"Software fault prediction (SFP) assists developers in diagnosing the potential defects in the early stage. In SFP, software metrics have strong influence on the performance of a predictive model. However, high dimensional data impacts negatively on the predictive accuracy. As a solution, feature selection provides a process of selecting the optimal features that combine with machine learning techniques to build SFP models. For feature selection, filter selection is a way of addressing the high dimensionality, reducing computation time and improving prediction performance. In this research, we investigate a comparative analysis to review how different of nine filter feature selection methods on both datasets in PROMISE repository, namely CM1 and KC1. The experimental results show that the performances of classifiers are varying on different datasets, especially, in the CM1 dataset, Gain Ratio and Relief based on XGBoost (XGB) and Extra Trees (ET) achieved the highest accuracy and AUC values. In KC1, Gain Ratio and Mutual Information presented the greatest performance among nine methods."
pub.1146561964,Survey on Innovative Techniques to Predict Software Defects,"Among the most important activities of the SDLC testing phase is the software defect prediction (SDP). The modules are identified that are vulnerable to defects and require extensive testing. The test resources can be efficiently utilized without infringing the limitations. Even if SDP is very helpful in testing, predicting the defective modules is not always easy. Different problems impede smooth performance and use of model defect prediction. The prediction of software defects was an interest of investigation, as early-stage prediction of defects improves software quality with reduced cost and effective managing of software. Researchers from different fields help to provide different techniques for software defect predction. A number of approaches, frameworks, methods and modeling were proposed using different data sets, metrics and assessment strategies, in order to remove unnecessary and erroneous details from defect-prone modules. Defects in software systems are common and may cause software users various problems. During the development of different methods, the most probable defect location in large code bases was quickly predicted. Prediction of software faults is a vital and beneficial way of improving software quality and reliability. The ability to predict which components in a large software system will contain more faults in the next release contributes to the better management of projects, including an early estimation of possible release delays, and a “correcting guide for improving the software’s quality”. The identification of bugs/defects at the early stages of the software life cycle reduces the software development effort needed. A lot of research in software fault prediction using machine learning methods has been advanced. There are mainly two problems in the prediction of software defects, dimensional reduction and imbalances of class."
pub.1105920790,Investigating Implications of Metric Based Predictive Data Mining Approaches towards Software Fault Predictions,"Context: Since 1990, various researches have been working in the area of software fault prediction but yet it is difficult to assess the impacts and progressive path of this research field. Objective: In this research work, author’s major objective is to investigate the context and dimensions of research studies performed by different researchers in the area of software fault prediction. This work also focuses on presenting a well defined systematic view of their findings and suggestions after a critical examination of all major approaches applied in this key research area. Method: This research work includes 112 total manuscripts published between 2009 and 2014. These studies are gathered from a pool of total 587 manuscripts. The selection criteria for these manuscripts are title, keywords and citation of that paper. Result: The results of this investigation shows that most of the research work related to software fault prediction have been performed on available data set from NASA repository. Most of the research work performed is basically confined to analysis or comparative study of various machine learning techniques based on their classification accuracy. Various research work published doesn’t exhibit clearer representation of any specific prediction model. Conclusion: Still after years of development, there is a huge gap between the industry requirement and the research being performed by different researchers in the field of Software fault prediction. A better collaboration between industry academia is still required. This research work represents a critical investigative approach towards finding the exact gaps to be filled and explored more authentic future research areas in this field. All result finding have been critically examined and compared with existing literature work for better understanding and deep insight over identifying the major strengths of chosen research field. "
pub.1136786143,Software Fault Prediction Using Machine Learning Models and Comparative Analysis,"Software Testing is an important phase of Software Development Life cycle. Effective software testing helps in identifying faulty modules, but this process becomes very time consuming, especially for large /complex software. Moreover early identification of error prone modules can be useful in producing better quality software. Hence software fault prediction has gained significant attention of the researchers in the recent years. Mainly two types of techniques are being used for it: statistical methods and Machine learning models, out of which recent trend is more inclined towards machine Learning based techniques. Identification of faulty modules is a binary classification problem and machine learning models such as Decision Tree and its variants, Random Forest and Support Vector Machine, are best suited for the fault prediction. This paper attempts to predict software faults using four different classification models. Further, the performance evaluation of these models is also carried out in this paper using accuracy, Precision, Recall, F1-Score and execution time of over 12 datasets, extracted from one of the most commonly used PROMISE repository. Based on these performance metrics comparison of applied four models is done and our comparative analysis indicates that in most of the cases Support Vector Machine model is able to predict software faults more efficiently than the rest in terms of accuracy as well as execution time"
pub.1110901279,Iterated feature selection algorithms with layered recurrent neural network for software fault prediction,"Software fault prediction (SFP) is typically used to predict faults in software components. Machine learning techniques (e.g., classification) are widely used to tackle this problem. With the availability of the huge amount of data that can be obtained from mining software historical repositories, it becomes possible to have some features (metrics) that are not correlated with the faults, which consequently mislead the learning algorithm and thus decrease its performance. One possible solution to eliminate those metrics is Feature Selection (FS). In this paper, a novel FS approach is proposed to enhance the performance of a layered recurrent neural network (L-RNN), which is used as a classification technique for the SFP problem. Three different wrapper FS algorithms (i.e, Binary Genetic Algorithm (BGA), Binary Particle Swarm Optimization (BPSO), and Binary Ant Colony Optimization (BACO)) were employed iteratively. To assess the performance of the proposed approach, 19 real-world software projects from PROMISE repository are investigated and the experimental results are discussed. Receiver operating characteristic - area under the curve (ROC-AUC) is used as a performance measure. The results are compared with other state-of-art approaches including Naïve Bayes (NB), Artificial Neural Network (ANN), logistic regression (LR), the k-nearest neighbors (k-NN) and C4.5 decision trees, in terms of area under the curve (AUC). Our results have demonstrated that the proposed approach can outperform other existing methods."
pub.1039545806,Software quality estimation with limited fault data: a semi-supervised learning perspective,"We addresses the important problem of software quality analysis when there is limited software fault or fault-proneness data. A software quality model is typically trained using software measurement and fault data obtained from a previous release or similar project. Such an approach assumes that fault data is available for all the training modules. Various issues in software development may limit the availability of fault-proneness data for all the training modules. Consequently, the available labeled training dataset is such that the trained software quality model may not provide predictions. More specifically, the small set of modules with known fault-proneness labels is not sufficient for capturing the software quality trends of the project. We investigate semi-supervised learning with the Expectation Maximization (EM) algorithm for software quality estimation with limited fault-proneness data. The hypothesis is that knowledge stored in software attributes of the unlabeled program modules will aid in improving software quality estimation. Software data collected from a large NASA software project is used during the semi-supervised learning process. The software quality model is evaluated with multiple test datasets collected from other NASA software projects. Compared to software quality models trained only with the available set of labeled program modules, the EM-based semi-supervised learning scheme improves generalization performance of the software quality models."
pub.1119159959,The Impact of Feature Selection on Predicting the Number of Bugs,"Bug prediction is the process of training a machine learning model on
software metrics and fault information to predict bugs in software entities.
While feature selection is an important step in building a robust prediction
model, there is insufficient evidence about its impact on predicting the number
of bugs in software systems. We study the impact of both correlation-based
feature selection (CFS) filter methods and wrapper feature selection methods on
five widely-used prediction models and demonstrate how these models perform
with or without feature selection to predict the number of bugs in five
different open source Java software systems. Our results show that wrappers
outperform the CFS filter; they improve prediction accuracy by up to 33% while
eliminating more than half of the features. We also observe that though the
same feature selection method chooses different feature subsets in different
projects, this subset always contains a mix of source code and change metrics."
pub.1061154197,Predicting fault-prone software modules in telephone switches,"An empirical study was carried out at Ericsson Telecom AB to investigate the relationship between several design metrics and the number of function test failure reports associated with software modules. A tool, ERIMET, was developed to analyze the design documents automatically. Preliminary results from the study of 130 modules showed that: based on fault and design data one can satisfactorily build, before coding has started, a prediction model for identifying the most fault-prone modules. The data analyzed show that 20 percent of the most fault-prone modules account for 60 percent of all faults. The prediction model built in this paper would have identified 20 percent of the modules accounting for 47 percent of all faults. At least four design measures can alternatively be used as predictors with equivalent performance. The size (with respect to the number of lines of code) used in a previous prediction model was not significantly better than these four measures. The Alberg diagram introduced in this paper offers a way of assessing a predictor based on historical data, which is a valuable complement to linear regression when prediction data is ordinal. Applying the method described in this paper makes it possible to use measures at the design phase to predict the most fault-prone modules."
pub.1093208187,An Ensemble Approach of Simple Regression Models to Cross-Project Fault Prediction,"In software development, prediction of fault-prone modules is an important challenge for effective software testing. However, high prediction accuracy may not be achieved in cross-project prediction, since there is a large difference in distribution of predictor variables between the base project (for building prediction model) and the target project (for applying prediction model.) In this paper we propose an prediction technique called “an ensemble of simple regression models” to improve the prediction accuracy of cross-project prediction. The proposed method uses weighted sum of outputs of simple (e.g. l-predictor variable) logistic regression models to improve the generalization ability of logistic models. To evaluate the performance of the proposed method, we conducted 132 combinations of cross-project prediction using datasets of 12 projects from NASA IV&V Facility Metrics Data Program. As a result, the proposed method outperformed conventional logistic regression models in terms of AUC of the Alberg diagram."
pub.1120975001,Multi-gene Genetic Programming Based Defect-Ranking Software Modules,"Most software defect prediction models aim at predicting the number of defects in a given software. However, it is very difficult to predict the precise number of defects in a module because of the presence of noise data. Another type of frequently used approach is ranking the software modules according to the relative number of defects, according to which software defect prediction can guide the testers to allocate the limited resources preferentially to modules with a greater number of defects. Owing to the redundant metrics in software defect data-sets, researchers always need to reduce the dimensions of the metrics before constructing defect prediction models. However a reduction in the number of dimensions may lead to some useful information being deleted too early, and consequently, the performance of the prediction model will decrease. In this paper, we propose an approach using multi-gene genetic programming (MGGP) to build a defect rank model. We compared the MGGP-based model with other optimized methods over 11 publicly available defect data-sets consisting of several software systems. The fault-percentile-average (FPA) is used to evaluate the performance of the MGGP and other methods. The results show that the models for different test objects that are built based on the MGGP approach perform better those based on other nonlinear prediction approaches when constructing the defect rank. In addition, the correlation between the software metrics will not affect the prediction performance. This means that, by using the MGGP method, we can use the original features to construct a prediction model without considering the influence of the correlation between the software module features."
pub.1149727221,Data Analytics: Predicting Software Bugs in Industrial Products,"Achieving high software reliability in products is a costly process. Faults found late in the development cycle are the costliest to fix. Defect prediction models are developed prior to and during various stages of testing to predict the faults remaining or to predict which software modules are more prone to failures. Increasingly machine learning models are used for this purpose, using various code metrics and defect data. In this paper we will review the need for targeted testing and various machine learning approaches for defect prediction. Additionally, we will present a new methodology for improving software reliability during product development based on the results from the analytics models, which we demonstrate with a small case study."
pub.1048920469,An Empirical Study of Predictive Modeling Techniques of Software Quality,"The primary goal of software quality engineering is to apply various techniques and processes to produce a high quality software product. One strategy is applying data mining techniques to software metrics and defect data collected during the software development process to identify the potential low-quality program modules. In this paper, we investigate the use of feature selection in the context of software quality estimation (also referred to as software defect prediction), where a classification model is used to predict program modules (instances) as fault-prone or not-fault-prone. Seven filter-based feature ranking techniques are examined. Among them, six are commonly used, and the other one, named signal to noise ratio (SNR), is rarely employed. The objective of the paper is to compare these seven techniques for various software data sets and assess their effectiveness for software quality modeling. A case study is performed on 16 software data sets and classification models are built with five different learners. Our experimental results are summarized based on statistical tests for significance. The main conclusion is that the SNR technique performs better than or similar to the best performer of the six commonly used techniques."
pub.1035147843,Bayesian Prediction of Fault-Proneness of Agile-Developed Object-Oriented System,"Logistic regression (LR) and naïve Bayes (NB) extensively used for prediction of fault-proneness assume linear addition and independence that often cannot hold in practice. Hence, we propose a Bayesian network (BN) model with incorporation of data mining techniques as an integrative approach. Compared with LR and NB, BN provides a flexible modeling framework, thus avoiding the corresponding assumptions. Using the static metrics such as Chidamber and Kemerer’s (C-K) suite and complexity as predictors, the differences in performance between LR, NB and BN models were examined for fault-proneness prediction at the class level in continual releases (five versions) of Rhino, an open-source implementation of JavaScript, developed using the agile process. By cross validation and independent test of continual versions, we conclude that the proposed BN can achieve a better prediction than LR and NB for the agile software due to its flexible modeling framework and incorporation of multiple sophisticated learning algorithms."
pub.1094706570,Modeling Class Cohesion as Mixtures of Latent Topics,"The paper proposes a new measure for the cohesion of classes in Object-Oriented software systems. It is based on the analysis of latent topics embedded in comments and identifiers in source code. The measure, named as Maximal Weighted Entropy, utilizes the Latent Dirichlet Allocation technique and information entropy measures to quantitatively evaluate the cohesion of classes in software. This paper presents the principles and the technology that stand behind the proposed measure. Two case studies on a large open source software system are presented. They compare the new measure with an extensive set of existing metrics and use them to construct models that predict software faults. The case studies indicate that the novel measure captures different aspects of class cohesion compared to the existing cohesion measures and improves fault prediction for most metrics, which are combined with Maximal Weighted Entropy."
pub.1148737410,Coupling and Cohesion Metrics-based Fault Predictions using Machine learning Algorithm,"Malware affects the software system and may lead to server failure. It is required to detect the malicious software accurately to avoid the time and cost wastage. Various research works has been introduced earlier for the detection of malicious software. In the existing work, Support Vector Machine (SVM) is introduced for malicious software detection, which cannot perform well where there are error modules in software. It is addressed in this suggested study by developing the Coupling and Cohesion Metrics based Fault Detection (CCMFD). A high - quality service has a low coupling and a high cohesiveness. In this research work, structural measures are mainly examined which comes under group of cohesion measures and comprises deficient of no cohesion in methods and CCBO approaches. Failure situations measures relating to information flow which are used in other techniques. These extracted features will be given as input to the Modified Convolutional Neural Network for software mistake forecasting. The complete analysis of the study is implementing in Java simulator."
pub.1094157102,Towards Logistic Regression Models for Predicting Fault-prone Code across Software Projects,"In this paper, we discuss the challenge of making logistic regression models able to predict fault-prone object-oriented classes across software projects. Several studies have obtained successful results in using design-complexity metrics for such a purpose. However, our data exploration indicates that the distribution of these metrics varies from project to project, making the task of predicting across projects difficult to achieve. As a first attempt to solve this problem, we employed simple log transformations for making design-complexity measures more comparable among projects. We found these transformations useful in projects which data is not as spread as the data usedfor building the prediction model."
pub.1138584824,Software aging prediction and rejuvenation in cloud computing environment: a new approach,"Service availability is one of the major requirements for user satisfaction. Several researches were conducted in recent years to find suitable infrastructure to enhance the availability. Even though both hardware and software are to be in good condition, in recent years, software faults are the major concern for service availability. Software aging is a type of software fault. Software aging occurs as a result of errors accumulation in the internal environment of the system leading to performance degradation. To manage software aging, technique used is software rejuvenation. There exist two kinds of approaches for studying software aging and deriving optimal software rejuvenation schedules. The two approaches are measurement based and model based. In model based approach, analytic models are built for capturing system degradation and rejuvenation process. In measurement based approach, attributes are periodically monitored and that may indicate signs of software aging. In this work, a prototype of measurement based model has been developed. The model captures the aging indicator metrics from cloud environment and rejuvenates once the system reaches aged status. The proposed model uses platform independent, non-intrusive technique for capturing metrics. The rejuvenation carried out after analysing the captured metrics, increases the availability of the service."
pub.1095768229,An Exploratory Analysis on Software Developers' Bug-introducing Tendency Over Time,"Understanding how software developers' erroneous tendency changes across time has significant implications for building fault-proneness prediction models and guiding software evolution testing. This paper initiates the investigation on software developers' bug-introducing tendency through an exploratory analysis. Five metrics are proposed to capture software developers' bug-introducing tendency and its correlated factors. A total of 76 software developers, working in four widely used software programs from GitHub, have been analyzed. The initial findings are presented."
pub.1134895410,Boosted Whale Optimization Algorithm With Natural Selection Operators for Software Fault Prediction,"Software fault prediction (SFP) is a challenging process that any successful software should go through it to make sure that all software components are free of faults. In general, soft computing and machine learning methods are useful in tackling this problem. The size of fault data is usually huge since it is obtained from mining software historical repositories. This data consists of a large number of features (metrics). Determining the most valuable features (i.e., Feature Selection (FS) is an excellent solution to reduce data dimensionality. In this paper, we proposed an enhanced version of the Whale Optimization Algorithm (WOA) by combining it with a single point crossover method. The proposed enhancement helps the WOA to escape from local optima by enhancing the exploration process. Five different selection methods are employed: Tournament, Roulette wheel, Linear rank, Stochastic universal sampling, and random-based. To evaluate the performance of the proposed enhancement, 17 available SFP datasets are adopted from the PROMISE repository. The deep analysis shows that the proposed approach outperformed the original WOA and the other six state-of-the-art methods, as well as enhanced the overall performance of the machine learning classifier."
pub.1019957149,Software measurement data reduction using ensemble techniques,"Software defect prediction models are used to identify program modules that are high-risk, or likely to have a high number of faults. These models are built using software metrics which are collected during the software development process. Various techniques and approaches have been created for improving fault predictions. One of these is feature (metric) selection. Choosing the most important features is important to improve the effectiveness of defect predictors. However, using a single feature subset selection method may generate local optima. Ensembles of feature selection methods attempt to combine multiple feature selection methods instead of using a single one. In this paper, we present a comprehensive empirical study examining 17 different ensembles of feature ranking techniques (rankers) including six commonly used feature ranking techniques, the signal-to-noise filter technique, and 11 threshold-based feature ranking techniques. This study utilized 16 real-world software measurement data sets of different sizes and built 54,400 classification models using four well known classifiers. The main conclusion is that ensembles of very few rankers are very effective and even better than ensembles of many or all rankers."
pub.1044728625,Comparative analysis of statistical and machine learning methods for predicting faulty modules,"The demand for development of good quality software has seen rapid growth in the last few years. This is leading to increase in the use of the machine learning methods for analyzing and assessing public domain data sets. These methods can be used in developing models for estimating software quality attributes such as fault proneness, maintenance effort, testing effort. Software fault prediction in the early phases of software development can help and guide software practitioners to focus the available testing resources on the weaker areas during the software development. This paper analyses and compares the statistical and six machine learning methods for fault prediction. These methods (Decision Tree, Artificial Neural Network, Cascade Correlation Network, Support Vector Machine, Group Method of Data Handling Method, and Gene Expression Programming) are empirically validated to find the relationship between the static code metrics and the fault proneness of a module. In order to assess and compare the models predicted using the regression and the machine learning methods we used two publicly available data sets AR1 and AR6. We compared the predictive capability of the models using the Area Under the Curve (measured from the Receiver Operating Characteristic (ROC) analysis). The study confirms the predictive capability of the machine learning methods for software fault prediction. The results show that the Area Under the Curve of model predicted using the Decision Tree method is 0.8 and 0.9 (for AR1 and AR6 data sets, respectively) and is a better model than the model predicted using the logistic regression and other machine learning methods."
pub.1107392773,Automatically identifying code features for software defect prediction: Using AST N-grams," Context: Identifying defects in code early is important. A wide range of static code metrics have been evaluated as potential defect indicators. Most of these metrics offer only high level insights and focus on particular pre-selected features of the code. None of the currently used metrics clearly performs best in defect prediction. Objective: We use Abstract Syntax Tree (AST) n-grams to identify features of defective Java code that improve defect prediction performance. Method: Our approach is bottom-up and does not rely on pre-selecting any specific features of code. We use non-parametric testing to determine relationships between AST n-grams and faults in both open source and commercial systems. We build defect prediction models using three machine learning techniques. Results: We show that AST n-grams are very significantly related to faults in some systems, with very large effect sizes. The occurrence of some frequently occurring AST n-grams in a method can mean that the method is up to three times more likely to contain a fault. AST n-grams can have a large effect on the performance of defect prediction models. Conclusions: We suggest that AST n-grams offer developers a promising approach to identifying potentially defective code."
pub.1121525071,Machine Learning based Test Case Prioritization in Object Oriented Testing,"Software maintenance is one of the most expensive activities in software life cycle. It costs nearly 70% of the total cost of the software. Either to adopt the new requirement or to correct the functionality, software undergoes maintenance. As a consequent of maintenance activities, software undergoes many reforms. Newly added software components may affect the working of existing components and also may introduce faults in existing components. The regression testing tries to reveal the faults that might have been introduced due to these reformations. Running all the prior existing test cases may not be feasible due to constraints like time, cost and resources. Test case prioritization may help in ordered execution of test cases. Running a faulty or fault prone component early in testing process may help in revealing more faults per unit of time. And hence may reduce the testing time. There have been many different criteria for assigning the priority to test cases. But none of the approaches so far have considered the object oriented design metrics for determining the priority of test cases. Object oriented design metrics have been empirically studied for their impact of software maintainability, reliability, testability and quality but usage of these metrics in test case prioritization is still an open area of research. The research reported in this paper evaluates subset of CK metrics. Metrics considered from CK suite include Coupling between objects (CBO), Depth of Inheritance tree (DIT), weighted methods per class (WMC), Number of children (NOC), and Response for a class (RFC). Study also considers four other metrics namely publically inherited methods (PIM), weighted attributes per class (WAC), number of methods inherited (NMI) and number of methods overridden. A model is built based on these metrics for the prediction of software quality and based on the quality measures software modules are classified with the help of Support Vector Machine (SVM) algorithm. The proposed approach is implemented in WEKA tool and analysed on experimental data extracted from open source software. Proposed work would firstly help the tester in identifying the low quality modules and then prioritize the test cases based on quality centric approach. The work also attempts to automate test case prioritization in object oriented testing. The results obtained are encouraging."
pub.1124549063,Prediction Priority of Defective Modules for Testing Resource Allocation,"Software development is a complex process, and extensive software systems developed by integrating the smaller modules that are tested independently during the testing phase. The testing phase is tedious and provided with limited time and resources to produce the software on time. To distribute the proportionate allocation of software testing resources for cost reduction using software defect prediction has drawn notable attention. Although there have been lots of studies on using software product metrics to identify defect-prone modules, the priority of defective modules for testing resource allocation is still unexplored. It is not easy to assess the appropriate amount of workforce for the exact software module testing concerning its number of faults present. There is much work done in the prediction of the fault-proneness of the software systems, which predicts either a module is faulty or not. However, it is the priority that needs to be identified in terms of low, medium, and high, which will decide the resources and the order in which the defect should resolve. The most-faulty module matters more for a developer and needs immediate attention. Therefore, in this study, the prioritization of faulty modules in low, medium, and high categories for software defect dataset is performed. A new infrastructure, software defect prediction model, based on categorized data is developed, and extensive study with benchmark machine learning algorithms is designed and conducted for different software fault datasets. The main impact of this work is to allow the appropriate allocation of testing resources to the prioritized modules."
pub.1095793897,Module-Order Modeling using an Evolutionary Multi-Objective Optimization Approach,"The problem of quality assurance is important for software systems. The extent to which software reliability improvements can be achieved is often dictated by the amount of resources available for the same. A prediction for risk-based rankings of software modules can assist in the cost-effective delegation of the limited resources. A module-order model (MOM) is used to gauge the performance of the predicted rankings. Depending on the software system under consideration, multiple software quality objectives may be desired for a MOM; e.g., the desired rankings may be such that if 20% of modules are targeted for reliability enhancements then 80% of the faults would be detected. In addition, it may also be desired that if 50% of modules are targeted then 100% of the faults would be detected. Existing works related to MOM $(s)$ have used an underlying prediction model to obtain the rankings, implying that only the average, relative, or mean square errors are minimized. Such an approach does not provide an insight into the behavior of a MOM, the performance of which focusses on how many faults are accounted for by the given percentage of modules enhanced. We propose a methodology for building MOM $(s)$ by implementing a multi-objective optimization with genetic programming. It facilitates the simultaneous optimization of multiple performance objectives for a MOM. Other prediction techniques, e.g., multiple linear regression and neural networks, cannot achieve multi-objective optimization for MOM $(s)$. A case study of a high-assurance telecommunications software system is presented. The observed results show a new promise in the modeling of goal-oriented software quality estimation models."
pub.1169296345,Search-Based Prediction of Software Functional Fault Slip-Through,"pressure to improve software development processes is not new, but today 's competitive environment places even greater emphasis on delivering better services at lower costs. Research and development of technologies to simplify and accelerate software development has been conducted since the existence of software. Never the less, projects typically spend at least 50 percent of their development work on rework that could have been avoided, or at least fixed in a more cost-effective manner. By finding more defects early in the software testing process, much of the rework cost can be avoided. One of the main reasons for high rework costs is that defects leak from early stages, when it is cheaper to find and eliminate them. Fault slip-through(FST) metrics are used to determine whether a fault has passed through the phrase in which it should be discovered. Defects can occur during unit testing, functional testing, integration testing, and system testing stages of a software project. The purpose of this study is to investigate the performance of the Cat Swarm optimization algorithm in predicting the drift of functional bugs during the software testing stage. The results obtained in this work show that the accuracy, precision, recall, f1: of the Cat Swarm optimization algorithm for the functional metric number of fault slip-through are 92%, 83%, 91% and 87%, respectively is show that."
pub.1175733674,An enhanced conventional neural network schema for structural class-based software fault prediction,"Malicious software detection is the most prominent process required by various industries to avoid server failure. It is required to detect malicious software accurately to avoid time and cost wastage. Various research works have been introduced earlier for the detection of malicious software. In the existing work Support Vector Machine (SVM) is introduced for malicious software detection. However, existing works cannot perform well where there are error modules in the software. It is addressed in this suggested study by developing Coupling and Cohesion Metrics-based Fault Detection (CCMFD). In this research work, structural measures are mainly examined which come under the cohesion measures and comprise deficient cohesion in approaches (LCOM), and Conceptual Coupling between Object Classes (CCBO). Failure situations and measures relating to information flow are used in other techniques. A high-quality service has a low coupling and a high cohesiveness. These extracted features will be given as input to the enhanced Conventional Neural Network (CNN) for software mistake forecasting. A complete study analysis is done in a Java simulator, indicating that the suggested approach tends to have superior fault prediction outcomes than the current method."
pub.1156912887,Design an Improved Model of Software Defect Prediction Model for Web Applications,"In the software industry, web applications are crucial and are frequently updated to comply with standards or to include new capabilities. However, even while testing ensures quality, the existence of faults obstructs a smooth development. Defects are caused by a number of variables, many of which must be eliminated at great cost. Determining defects at early stage of the software development process is crucial. Therefore, it is highly desirable to develop such a model that can detect defects in a web application. In this study, the researcher surveyed object-oriented metrics and many Software Defect Prediction (SDP) models for web applications. The author has proposed an architecture for an enhanced model of SDP using machine learning techniques. The proposed model will use supervised and unsupervised learning on object oriented metrices to overcome the problem of class imbalance, cost sensitivity and correlation between Attributes and Faults."
pub.1093974467,An empirical study of the correlation between code coverage and reliability estimation,"Existing time-domain models for software reliability often result in an overestimation, of such reliability because they do not take the nature of testing techniques into account. Since every testing technique has a limit to its ability to reveal faults in a given system, as a technique approaches its saturation region fewer faults are discovered and reliability growth phenomena are predicted from the models. When the software is turned over to field operation, significant overestimates of reliability are observed. We present a technique to solve this problem by addressing both time and coverage measures for the prediction of software failures. Our technique uses coverage information collected during testing to extract only effective data from a given operational profile. Execution time between test cases which neither increase coverage nor cause a failure as reduced by a parameterized factor. Experiments using this technique were conducted on a program created in a simulation environment with simulated faults and on an industrial automatic flight control project which contained several natural faults. Results from both experiments indicate that overestimation of reliability is reduced significantly using our technique. This new approach not only helps reliability growth models make more accurate predictions, but also reveals the efficiency of a testing profile so that more effective testing techniques can be conducted."
pub.1141457432,Improving Cross-Project Defect Prediction with Weighted Software Modules via Transfer Learning,"Cross-project defect prediction is investigated to resolve the trouble that software program defect prediction besides historic data. However, there are differences in distribution of software metrics of different software projects, which decreases the overall performance of cross-project defect prediction. This research presents a transfer learning-based cross-project fault prediction approach. The weights of the training software modules are determined by analogy with gravity and compared to those in the test set. The costs associated with different prediction errors are considered. Cost-sensitive C4.5 is employed on weighted training data for cross-project defect prediction. 10 projects from NASA are used in our experiments. Our suggested technique delivers promising cross-project defect prediction results, according to the results, 0.81, 0.41 and 0.8 in average PD value, F-measure value and AUC value, which are best compared to Naïve Bayes based cross-project defect prediction."
pub.1036374868,Predicting aging-related bugs using software complexity metrics,"Long-running software systems tend to show degraded performance and an increased failure occurrence rate. This problem, known as Software Aging, which is typically related to the runtime accumulation of error conditions, is caused by the activation of the so-called Aging-Related Bugs (ARBs). This paper aims to predict the location of Aging-Related Bugs in complex software systems, so as to aid their identification during testing. First, we carried out a bug data analysis on three large software projects in order to collect data about ARBs. Then, a set of software complexity metrics were selected and extracted from the three projects. Finally, by using such metrics as predictor variables and machine learning algorithms, we built fault prediction models that can be used to predict which source code files are more prone to Aging-Related Bugs."
pub.1118993865,The impact of software complexity on cost and quality - A comparative analysis between Open source and proprietary software,"Early prediction of software quality is important for better software
planning and controlling. In early development phases, design complexity
metrics are considered as useful indicators of software testing effort and some
quality attributes. Although many studies investigate the relationship between
design complexity and cost and quality, it is unclear what we have learned
beyond the scope of individual studies. This paper presented a systematic
review on the influence of software complexity metrics on quality attributes.
We aggregated Spearman correlation coefficients from 59 different data sets
from 57 primary studies by a tailored meta-analysis approach. We found that
fault proneness and maintainability are most frequently investigated
attributes. Chidamber and Kemerer metric suite is most frequently used but not
all of them are good quality attribute indicators. Moreover, the impact of
these metrics is not different in proprietary and open source projects. The
result provides some implications for building quality model across project
type"
pub.1163808264,Software Reliability Growth Model for N-Version Fault Tolerant Software with Common and Independent Faults,"Research and development teams have become increasingly focused on developing highly reliable software for safety-critical systems. It is a major challenge for real-time control systems to achieve high reliability software to meet safety standards. A reliability evaluation focuses primarily on analytical and modeling techniques for fault prediction. In safety-critical systems like nuclear plant controls, aircraft controls and railroad signalization systems, N-version programming (NVP) is an effective technique for raising software’s reliability, particularly in areas with high-risk ratios because small errors can result in hazardous incidents. It allows the software to be fault-tolerant, aiding it to produce accurate results even when the software has faults. We present an analytical method for assessing the reliability of N-version software systems. Analysis of the system’s reliability and other performance metrics is provided with closed-form expressions. As an additional extension, we conduct numerical analyses of two cases, the 2VP system and 3VP system, in which suitable parameters are used. We conduct numerical simulations using MATLAB to generate the analytical results and compare the analytical results by using numerical results and neuro-fuzzy results using fuzzy interference systems."
pub.1095698159,An Approach of Software Quality Prediction Based on Relationship Analysis and Prediction Model,"By predicting the quality of the software that will be formed in the early stage of development, faults brought in at the phase of design will be found out early in order not leave them in the software product. Furthermore, it will be easy for designers to adopt appropriate plans based on specific expectations of the target software. However, the traditional prediction models have following shortages: 1) the relationship between attributes and metrics effectively cannot be expressed; 2) lack of the ability to process data both qualitatively and quantitatively; 3) not appropriate to the case with uncompleted information. In this paper, a model built based on regression analysis and fuzzy neural network is proved to be good at quality prediction of object-oriented software."
pub.1146814837,Research on fault diagnosis in early stage of software development based on Object-oriented Bayesian Networks,"Continuous development of Internet of Things, big data and other emerging technologies has brought new challenges to the reliability of security-critical system products in various industries. Fault detection and evaluation in the early stage of software plays an important role in improving the reliability of software. However, fault prediction and evaluation, which are currently focused on the early stage of software, hardly provide high guidance for actual project development. In this study, a fault diagnosis method based on object-oriented Bayesian network (OOBN) is proposed. Starting from the time dimension and internal logic, a two-dimensional metric fault propagation model is established to calculate the failure rate of each early stage of software respectively, and the fault relationship of each stage is analyzed to find out the key fault units. In particular, it explores and validates the relationship between the failure rate of code phase and the failure caused by faults in requirement analysis stage and design stage in a train control system, to alert the developer strictly accordance with the industry development standards for software requirements analysis, design and coding, so as to reduce potential faults in the early stage. There is evidence that the study plays a crucial role to optimize the cost of software development and avoid catastrophic consequences."
pub.1094508956,Defect Collection and Reporting System for Git based Open Source Software,"This paper describes Defect Collection and Reporting System which is an automated tool that aids in generating various reports to provide useful information regarding the defects which were present in a given version of a Git Version Control System based Open Source Software and were fixed in the subsequent version. The generated reports contain information such as the total number of defects, class wise and the corresponding values of different OO metrics for each class in the source code. Such kind of defect data can be readily used for defect prediction hypothesis pertaining to Git based Open Source Software. Some potential fields of application could be analysis and validation of the effect of a given metric suite on fault proneness; to predict fault proneness models for Defect Prediction, etc. In addition to the core functionalities and overall functioning of the above stated tool, this paper also gives an overview of some of the functionalities which might be useful for the end user, namely-cloning of Git Repositories, and self-logging data of the tool."
pub.1094166350,Role of Parameter Estimation & Prediction During Development of Software Using SRGM,"Predicting Reliability of Software using SRGMs are a big challenge for Software Engineers. Software Reliability is a way to find the probability of software to operate in a given time limit and in a specified environment without causing any failure; hence it is reviewed as Quantifiable Metric. System faults can be the result of software or hardware errors. Software fault is comparatively more difficult to predict than hardware faults. Even the Reliability of a web application is also hard to determine due to its highly distributed nature. Predicting the reliability of application helps the Engineers to compute the software's release date/time and to manage various resources of software such as people, money, time etc. In this paper SRGM Models are considered namely Goel Okumoto Model (GO Model), Yamada S-shaped Model and Kapur & Garg Model (KG Model) to estimate and predict Software Reliability by detecting the cumulative number of faults in software application within specified time. Additional number of days are also calculated to remove them and release the software on time. By implementing the test cases of actual defects per day, Rate of Change or Test Case Efficiency can be measured."
pub.1018253180,Empirical analysis for investigating the effect of object‐oriented metrics on fault proneness: a replicated case study,"Abstract  The importance of software measurement is increasing, leading to the development of new measurement techniques. Many metrics have been proposed related to the various object‐oriented (OO) constructs like class, coupling, cohesion, inheritance, information hiding and polymorphism. The purpose of this article is to explore relationships between the existing design metrics and probability of fault detection in classes. The study described here is a replication of an analogous study conducted by Briand et al . The aim is to provide empirical evidence to draw the strong conclusions across studies. We used the data collected from Java applications for constructing a prediction model. Results of this study show that many metrics capture the same dimensions in the metric set, hence are based on comparable ideas and provides redundant information. It is shown that by using a subset of metrics prediction models can be built to identify faulty classes. The model predicts faulty classes with more than 90% accuracy. The predicted model shows that import coupling and size metrics are strongly related to fault proneness, confirming the results from previous studies. However, there are also differences reported in this study with respect to previous studies such as inheritance metric which counts methods inherited in a class is also included in the predicted model. Copyright © 2008 John Wiley & Sons, Ltd. "
pub.1086345733,REACT: a synthesis and evaluation tool for fault-tolerant multiprocessor architectures,"A software testbed that performs automated life testing of a variety of multiprocessor architectures through simulated fault injection is discussed. It is being developed to meet the need for a generalized simulation tool which can evaluate system reliability and availability metrics while avoiding several of the limitations associated with combinatorial and Markov modeling. Incorporating detailed system, workload, and fault/error models, REACT can be more accurate and easier to use than many dependability prediction tools based on analytical approaches. The authors motivate the development of REACT, describe its features, and explain its use. Example applications for the software are provided, and its limitations are discussed.<>"
pub.1101803958,An optimized feature selection using fuzzy mutual information based ant colony optimization for software defect prediction,"In recent years, there is a significant notification focused towards the prediction of software defect in the field of software engineering. The prediction of software defects assist in reducing the cost of testing effort, improving the process of software testing and to concentrate only on the fault-prone software modules. Recently, software defect prediction is an important research topic in the software engineering field. One of the important factors which effect the software defect detection is the presence of noisy features in the dataset. The objective of this proposed work is to contribute an optimization technique for the selection of potential features to improve the prediction capability of software defects more accurately. The Fuzzy Mutual Information Ant Colony Optimization is used for searching the optimal feature set with the ability of Meta heuristic search. This proposed feature selection efficiency is evaluated using the datasets from NASA metric data repository. Simulation results have indicated that the proposed method makes an impressive enhancement in the prediction of routine for three different classifiers used in this work."
pub.1051252581,"Using complexity, coupling, and cohesion metrics as early indicators of vulnerabilities","Software security failures are common and the problem is growing. A vulnerability is a weakness in the software that, when exploited, causes a security failure. It is difficult to detect vulnerabilities until they manifest themselves as security failures in the operational stage of software, because security concerns are often not addressed or known sufficiently early during the software development life cycle. Numerous studies have shown that complexity, coupling, and cohesion (CCC) related structural metrics are important indicators of the quality of software architecture, and software architecture is one of the most important and early design decisions that influences the final quality of the software system. Although these metrics have been successfully employed to indicate software faults in general, there are no systematic guidelines on how to use these metrics to predict vulnerabilities in software. If CCC metrics can be used to indicate vulnerabilities, these metrics could aid in the conception of more secured architecture, leading to more secured design and code and eventually better software. In this paper, we present a framework to automatically predict vulnerabilities based on CCC metrics. To empirically validate the framework and prediction accuracy, we conduct a large empirical study on fifty-two releases of Mozilla Firefox developed over a period of four years. To build vulnerability predictors, we consider four alternative data mining and statistical techniques – C4.5 Decision Tree, Random Forests, Logistic Regression, and Naïve-Bayes – and compare their prediction performances. We are able to correctly predict majority of the vulnerability-prone files in Mozilla Firefox, with tolerable false positive rates. Moreover, the predictors built from the past releases can reliably predict the likelihood of having vulnerabilities in the future releases. The experimental results indicate that structural information from the non-security realm such as complexity, coupling, and cohesion are useful in vulnerability prediction."
pub.1052866134,Experiences of Fault Data in a Large Software System,"Early identification of fault-prone modules is desirable both from developer and customer perspectives because it supports planning and scheduling activities that facilitate cost avoidance and improved time to market. Large-scale software systems are rarely built from scratch, and usually involve modification and enhancement of existing systems. This suggests that development planning and software quality could greatly be enhanced, because knowledge about product complexity and quality of previous releases can be taken into account when making improvements in subsequent projects. In this article we present results from empirical studies at Ericsson Telecom AB that examine the use of metrics to predict fault-prone modules in successive product releases. The results show that such prediction appears to be possible and has potential to enhance project maintenance."
pub.1084529295,Source code metrics: A systematic mapping study," Context Source code metrics are essential components in the software measurement process. They are extracted from the source code of the software, and their values allow us to reach conclusions about the quality attributes measured by the metrics. Objectives This paper aims to collect source code metrics related studies, review them, and perform an analysis, while providing an overview on the current state of source code metrics and their current trends. Method A systematic mapping study was conducted. A total of 226 studies, published between the years 2010 and 2015, were selected and analyzed. Results Almost 300 source code metrics were found. Object oriented programming is the most commonly studied paradigm with the Chidamber and Kemerer metrics, lines of code, McCabe's cyclomatic complexity, and number of methods and attributes being the most used metrics. Research on aspect and feature oriented programming is growing, especially for the current interest in programming concerns and software product lines. Conclusions Object oriented metrics have gained much attention, but there is a current need for more studies on aspect and feature oriented metrics. Software fault prediction, complexity and quality assessment are recurrent topics, while concerns, big scale software and software product lines represent current trends."
pub.1133313973,Predicting Code Smells and Analysis of Predictions: Using Machine Learning Techniques and Software Metrics,"Code smell detection is essential to improve software quality, enhancing software maintainability, and decrease the risk of faults and failures in the software system. In this paper, we proposed a code smell prediction approach based on machine learning techniques and software metrics. The local interpretable model-agnostic explanations (LIME) algorithm was further used to explain the machine learning model’s predictions and interpretability. The datasets obtained from Fontana et al. were reformed and used to build binary-label and multi-label datasets. The results of 10-fold cross-validation show that the performance of tree-based algorithms (mainly Random Forest) is higher compared with kernel-based and network-based algorithms. The genetic algorithm based feature selection methods enhance the accuracy of these machine learning algorithms by selecting the most relevant features in each dataset. Moreover, the parameter optimization techniques based on the grid search algorithm significantly enhance the accuracy of all these algorithms. Finally, machine learning techniques have high potential in predicting the code smells, which contribute to detect these smells and enhance the software’s quality."
pub.1171156362,Software Bug Prediction Using Machine Learning,"Software bug prediction is a crucial aspect of software development and maintenance as it directly impacts the overall success of the software. By identifying potential bugs early on, software quality, reliability, and efficiency can be improved while also helping to reduce costs. Creating a reliable bug prediction model is a complex task, with various techniques proposed in the literature. In this paper, a bug prediction model utilizing machine learning algorithms is introduced. Three supervised machine learning algorithms have been incorporated to forecast future software faults using historical data. The evaluation process revealed that Machine Learning algorithms, specifically Naïve Bayes (NB), Decision Tree (DT), and Artificial Neural Networks (ANNs), can be effectively utilized with a high level of accuracy. Additionally, a comparison measure was implemented to assess the proposed prediction model against other methods. The findings indicated that the Machine Learning approach outperformed other techniques in terms of performance. Key Words: Bug Prediction, Reliability, Efficiency, Quality, Machine Learning, Performance Metrics"
pub.1039736203,The limited impact of individual developer data on software defect prediction,"Previous research has provided evidence that a combination of static code metrics and software history metrics can be used to predict with surprising success which files in the next release of a large system will have the largest numbers of defects. In contrast, very little research exists to indicate whether information about individual developers can profitably be used to improve predictions. We investigate whether files in a large system that are modified by an individual developer consistently contain either more or fewer faults than the average of all files in the system. The goal of the investigation is to determine whether information about which particular developer modified a file is able to improve defect predictions. We also extend earlier research evaluating use of counts of the number of developers who modified a file as predictors of the file’s future faultiness. We analyze change reports filed for three large systems, each containing 18 releases, with a combined total of nearly 4 million LOC and over 11,000 files. A buggy file ratio is defined for programmers, measuring the proportion of faulty files in Release R out of all files modified by the programmer in Release R-1. We assess the consistency of the buggy file ratio across releases for individual programmers both visually and within the context of a fault prediction model. Buggy file ratios for individual programmers often varied widely across all the releases that they participated in. A prediction model that takes account of the history of faulty files that were changed by individual developers shows improvement over the standard negative binomial model of less than 0.13% according to one measure, and no improvement at all according to another measure. In contrast, augmenting a standard model with counts of cumulative developers changing files in prior releases produced up to a 2% improvement in the percentage of faults detected in the top 20% of predicted faulty files. The cumulative number of developers interacting with a file can be a useful variable for defect prediction. However, the study indicates that adding information to a model about which particular developer modified a file is not likely to improve defect predictions."
pub.1128549284,Comparative Analysis of Selected Heterogeneous Classifiers for Software Defects Prediction Using Filter-Based Feature Selection Methods,"Classification techniques is a popular approach to predict software defects and it involves categorizing modules, which is represented by a set of metrics or code attributes into fault prone (FP) and non-fault prone (NFP) by means of a classification model. Nevertheless, there is existence of low quality, unreliable, redundant and noisy data which negatively affect the process of observing knowledge and useful pattern. Therefore, researchers need to retrieve relevant data from huge records using feature selection methods. Feature selection is the process of identifying the most relevant attributes and removing the redundant and irrelevant attributes. In this study, the researchers investigated the effect of filter feature selection on classification techniques in software defects prediction. Ten publicly available datasets of NASA and Metric Data Program software repository were used. The topmost discriminatory attributes of the dataset were evaluated using Principal Component Analysis (PCA), CFS and FilterSubsetEval. The datasets were classified by the selected classifiers which were carefully selected based on heterogeneity. Naïve Bayes was selected from Bayes category Classifier, KNN was selected from Instance Based Learner category, J48 Decision Tree from Trees Function classifier and Multilayer perceptron was selected from the neural network classifiers. The experimental results revealed that the application of feature selection to datasets before classification in software defects prediction is better and should be encouraged and Multilayer perceptron with FilterSubsetEval had the best accuracy. It can be concluded that feature selection methods are capable of improving the performance of learning algorithms in software defects prediction."
pub.1157368561,Faulty Classes Prediction in Object-Oriented Programming Using Composed Dagging Technique,"Class is one of the fundamental concepts of the object-oriented paradigm and has been scrutinized since the developers moved on from procedural programming design. In software fault prediction, the legalization of software metrics is essential. As a handful of software metrics suites exist, it is a very hard task to predict the defective classes flawlessly using a particular set of metrics suites. However, it is a rational approach to use only the object-oriented metrics that are directly relatable to the class definitions in the code that helps the developers foresee the errors in defining the classes and minimize the errors as much as possible. This paper utilized twelve object-oriented metrics selected from various metrics suites. The dagging ensemble model is merged with three well-known classification algorithms (Naive Bayes, Multilayer Perceptron, J48 Decision Tree) individually and applied to twelve java projects. The study depicts that the proposed ensemble method gives improved outcomes that are statistically significant when merged with Naive Bayes and Multilayer Perceptron. The proposed ensemble method shows improvements up to 12.5% in accuracy and 15% in F-Score."
pub.1164616291,Hybrid optimization-enabled deep Q network for fault prediction in service-oriented architecture,"Fault prediction in service-oriented architecture-based models has been recognized as one of the essential processes to reduce computational expenses and computational complexities of software system improvement. Prediction of errors and determining their positions at an early stage facilitate maintenance mechanisms very easily and enhance resource utilities. Hence, an effective fault prediction mechanism named fractional water cycle algorithm (Fr-WCA) is established in this research. The web service description language data are converted into JAVA files, and faults are injected into it in order to create a database. Thereafter, features like object-oriented metrics and statistical features are extracted, and data augmentation is completed effectively. The process of fault prediction is executed using a deep Q network classifier, which is trained by means of Fr-WCA. The Fr-WCA is the combination of fractional calculus and water cycle algorithm. The Fr-WCA achieved the greatest precision, recall, and f-measure of 0.932, 0.956, and 0.947."
pub.1024007537,Empirical Evaluation of Selected Algorithms for Complexity-Based Classification of Software Modules and a New Model,"Software plays a major role in many organizations. Organizational success depends partially on the quality of softwares used. In recent years, many researchers have recognized that statistical classification techniques are well-suited to develop software quality prediction models. Different statistical software quality models, using complexity metrics as early indicators of software quality, have been proposed in the past. At a high-level the problem of software categorization is to classify software modules into fault prone and non-fault prone. Indeed, a learner is given a set of training modules and the corresponding class labels (i.e fault prone or non-fault-prone), and outputs a classifier. Then, the classifier takes an unlabeled module (i.e hitherto-unseen module) and assigns it to a class. The focus of this paper is to study some selected classification techniques widely used for software categorization. Indeed, practitioners are faced with a body of approaches and literature that give several conflicting advices about the usefulness of these classification approaches. The techniques evaluated in this paper include: principal component analysis, linear discriminant analysis, multiple linear regression, logistic regression, support vector machine and finite mixture models. Moreover, we propose a Bayesian approach based on finite Dirichlet mixture models. We evaluate experimentally these approaches using a real data set. Our experimental results show that different algorithms lead to different statistically significant results."
pub.1164349811,A simplified predictive framework for cost evaluation to fault assessment using machine learning,"Software engineering is an integral part of any software development scheme which frequently encounters bugs, errors, and faults. Predictive evaluation of software fault contributes towards mitigating this challenge to a large extent; however, there is no benchmarked framework being reported in this case yet. Therefore, this paper introduces a computational framework of the cost evaluation method to facilitate a better form of predictive assessment of software faults. Based on lines of code, the proposed scheme deploys adopts a machine-learning approach to address the perform predictive analysis of faults. The proposed scheme presents an analytical framework of the correlation-based cost model integrated with multiple standards machine learning (ML) models, e.g., linear regression, support vector regression, and artificial neural networks (ANN). These learning models are executed and trained to predict software faults with higher accuracy. The study considers assessing the outcomes based on error-based performance metrics in detail to determine how well each learning model performs and how accurate it is at learning. It also looked at the factors contributing to the training loss of neural networks. The validation result demonstrates that, compared to logistic regression and support vector regression, neural network achieves a significantly lower error score for software fault prediction."
pub.1159889658,Comparison of Feature Selection via Semi supervised denoising autoencoder and traditional approaches For Software Fault-prone Classification,"<p>Software quality is the capability of a software process to produce software product satisfying the end user. The quality of process or product entities is described through a set of attributes that may be internal or external. For the product entity, especially, the source code, different internal attributes are defined to evaluate its quality like complexity and cohesion. Concerning external attributes related to the product environment like reliability, their assessment is more difficult. Thus, they are usually predicted by the development of prediction models based on software metrics as independent variables and other measurable attributes as dependent variables. For instance, reliability like other external attributes is generally measured and predicted based on other quality attributes like defect density, defect count and fault-proneness. The success of machine learning (ML) and deep learning (DL) approaches for software defect and faulty modules classification as crucial attributes for software reliability improvement is remarkable. In recent years, there has been growing interest in exploring the use of deep learning autoencoders, a type of neural network architecture, for software defect prediction. Therefore, we aim in this paper to explore the semi-supervised denoising DL autoencoder in order to capture relevant features. Then, we evaluate its performance in comparison to traditional ML supervised SVM technique for fault-prone modules classification. The performed experiments based on a set of software metrics extracted from NASA projects achieve promising results in terms of accuracy and show that denoising DL autoencoder outperforms traditional SVM technique.</p>"
pub.1009417172,An adaptive approach with active learning in software fault prediction,"Background: Software quality prediction plays an important role in improving the quality of software systems. By mining software metrics, predictive models can be induced that provide software managers with insights into quality problems they need to tackle as effectively as possible. Objective: Traditional, supervised learning approaches dominate software quality prediction. Resulting models tend to be project specific. On the other hand, in situations where there are no previous releases, supervised learning approaches are not very useful because large training data sets are needed to develop accurate predictive models. Method: This paper eases the limitations of supervised learning approaches and offers good prediction performance. We propose an adaptive approach in which supervised learning and active learning are coupled together. NaiveBayes classifier is used as the base learner. Results: We track the performance at each iteration of the adaptive learning algorithm and compare it with the performance of supervised learning. Our results show that proposed scheme provides good fault prediction performance over time, i.e., it eventually outperforms the corresponding supervised learning approach. On the other hand, adaptive learning classification approach reduces the variance in prediction performance in comparison with the corresponding supervised learning algorithm. Conclusion: The adaptive approach outperforms the corresponding supervised learning approach when both use Naive-Bayes as base learner. Additional research is needed to investigate whether this observation remains valid with other base classifiers."
pub.1094903187,Generalizing Fault Contents from a Few Classes,"The challenges in fault prediction today are to get a prediction as early as possible, at as low a cost as possible, needing as little data as possible and preferably in such a language that your average developer can understand where it came from. This paper presents a fault sampling method where a summary of a few, easily available metrics is used together with the results of a few sampled classes to generalize the fault content to an entire system. The method is tested on a large software system written in Java, that currently consists of around 2 000 classes and 300 000 lines of code. The evaluation shows that the fault generalization method is good at predicting fault-prone clusters and that it is possible to generalize the values of a few representative classes."
pub.1158416909,Machine Learning Empowered Software Prediction System,"Prediction of software defects is one of the most active study fields in software engineering today. Using a defect prediction model, a list of code prone to defects may be compiled. Using a defect prediction model, software may be made more reliable by identifying and discovering faults before or during the software enhancement process. Defect prediction will play an increasingly important role in the design process as the scope of software projects grows. Bugs or the number of bugs used to measure the performance of a defect prediction procedure are referred to as ""bugs"" in this context. Defect prediction models can incorporate a wide range of metrics, including source code and process measurements. Defects are determined using a variety of models. Using machine learning, the defect prediction model may be developed. Machine inclining in the second and third levels is dependent on the preparation and assessment of data (to break down model execution). Defect prediction models typically use 90 percent preparation information and 10 percent testing information. Improve prediction performance with the use of dynamic/semi-directed taking in, a machine learning approach. So that the results and conclusion may be sharply defined under many circumstances and factors, it is possible to establish a recreated domain to house the entire method. Computer-aided engineering (CAE) is being used to identify software defects in the context of neural networks. Neural network-based software fault prediction is compared to fuzzy logic fundamental results in this research paper. On numerous parameters, neural network training provides better and more effective outcomes, according to the recommended findings and outputs."
pub.1062959784,An Empirical Investigation on Wrapper-Based Feature Selection for Predicting Software Quality,"The basic measurements for software quality control and management are the various project and software metrics collected at various states of a software development life cycle. The software metrics may not all be relevant for predicting the fault proneness of software components, modules, or releases. Thus creating the need for the use of feature (software metric) selection. The goal of feature selection is to find a minimum subset of attributes that can characterize the underlying data with results as well as, or even better than the original data when all available features are considered. As an example of inter-disciplinary research (between data science and software engineering), this study is unique in presenting a large comparative study of wrapper-based feature (or attribute) selection techniques for building defect predictors. In this paper, we investigated thirty wrapper-based feature selection methods to remove irrelevant and redundant software metrics used for building defect predictors. In this study, these thirty wrappers vary based on the choice of search method (Best First or Greedy Stepwise), leaner (Naïve Bayes, Support Vector Machine, and Logistic Regression), and performance metric (Overall Accuracy, Area Under ROC (Receiver Operating Characteristic) Curve, Area Under the Precision-Recall Curve, Best Geometric Mean, and Best Arithmetic Mean) used in the defect prediction model evaluation process. The models are trained using the three learners and evaluated using the five performance metrics. The case study is based on software metrics and defect data collected from a real world software project.
                  The results demonstrate that Best Arithmetic Mean is the best performance metric used within the wrapper. Naïve Bayes performed significantly better than Logistic Regression and Support Vector Machine as a wrapper learner on slightly and less imbalanced datasets. We also recommend Greedy Stepwise as a search method for wrappers. Moreover, comparing to models built with full datasets, the performances of defect prediction models can be improved when metric subsets are selected through a wrapper subset selector."
pub.1003458027,Evaluating the change of software fault behavior with dataset attributes based on categorical correlation,"Utilization of data mining in software engineering has been the subject of several research papers. Majority of subjects of those paper were in making use of historical data for decision making activities such as cost estimation and product or project attributes prediction and estimation. The ability to predict software fault modules and the ability to correlate relations between faulty modules and product attributes using statistics is the subject of this paper. Correlations and relations between the attributes and the categorical variable or the class are studied through generating a pool of records from each dataset and then select two samples every time from the dataset and compare them. The correlation between the two selected records is studied in terms of changing from faulty to non-faulty or the opposite for the module defect attribute and the value change between the two records in each evaluated attribute (e.g. equal, larger or smaller). The goal was to study if there are certain attributes that are consistently affecting changing the state of the module from faulty to none, or the opposite. Results indicated that such technique can be very useful in studying the correlations between each attribute and the defect status attribute. Another prediction algorithm is developed based on statistics of the module and the overall dataset. The algorithm gave each attribute true class and faulty class predictions. We found that dividing prediction capability for each attribute into those two (i.e. correct and faulty module prediction) facilitate understanding the impact of attribute values on the class and hence improve the overall prediction relative to previous studies and data mining algorithms. Results were evaluated and compared with other algorithms and previous studies. ROC metrics were used to evaluate the performance of the developed metrics. Results from those metrics showed that accuracy or prediction performance calculated traditionally using accurately predicted records divided by the total number of records in the dataset does not necessarily give the best indicator of a good metric or algorithm predictability. Those predictions may give wrong implication if other metrics are not considered with them. The ROC metrics were able to show some other important aspects of performance or accuracy."
pub.1148036337,Burr-type NHPP-based software reliability models and their applications with two type of fault count data,"In this paper, we summarize the so-called Burr-type software reliability models (SRMs) based on the non-homogeneous Poisson process (NHPP) and comprehensively evaluate the model performances by comparing them with the existing NHPP-based SRMs. Two kinds of software fault count data are considered; fault-detection time-domain data and fault-detection time-interval data (group data). For 8 data sets in each fault count type, we estimate the model parameters by means of the maximum likelihood estimation and evaluate the performance metrics in terms of goodness-of-fit and prediction. It is shown that the Burr-type NHPP-based SRMs could show the better performances than the existing NHPP-based SRMs in many cases. The main contribution of the paper consists in suggesting that the Burr-type NHPP-based SRMs should be the possible candidates for selecting the best SRM in terms of goodness-of-fit and predictive performances."
pub.1132753802,A Universal Model for Defective Classes Prediction Using Different Object-Oriented Metrics Suites,"Recently, research studies were directed to the construction of a universal defect prediction model. Such models are trained using different projects to have enough training data and be generic. One of the main challenges in the construction of a universal model is the different distributions of metrics in various projects. In this study, we aim to build a universal defect prediction model to predict software defective classes. We also aim to validate the Object-Oriented Cognitive Complexity metrics suite (CC metrics) for its association with fault-proneness. Finally, this study aims to compare the prediction performances of the CC metrics and the Chidamber and Kemerer metrics suite (CK metrics), taking into account the effect of preprocessing techniques. A neural network model is constructed using these 2 metrics suites (CK & CC metrics suites). We apply different preprocessing techniques on these metrics to overcome variations in their distributions. The results show that the CK metrics perform well whether a preprocessing is applied or not, while CC metrics’ performance is significantly affected by different preprocessing techniques. The CC metrics always outperform in the recall, while the CK metrics usually outperform in other performance metrics. Normalization preprocessing results in the highest recall values using either of the two metrics suites."
pub.1093644864,A Novel Industry Grade Dataset for Fault Prediction Based on Model-Driven Developed Automotive Embedded Software,"In this paper, we present a novel industry dataset on static software and change metrics for Matlab/Simulink models and their corresponding auto-generated C source code. The data set comprises data of three automotive projects developed and tested accordingly to industry standards and restrictive software development guidelines. We present some background information of the projects, the development process and the issue tracking as well as the creation steps of the dataset and the used tools during development. A specific highlight of the dataset is a low measurement error on change metrics because of the used issue tracking and commit policies."
pub.1061788688,Benchmarking Classification Models for Software Defect Prediction: A Proposed Framework and Novel Findings,"Software defect prediction strives to improve software quality and testing efficiency by constructing predictive classification models from code attributes to enable a timely identification of fault-prone modules. Several classification models have been evaluated for this task. However, due to inconsistent findings regarding the superiority of one classifier over another and the usefulness of metric-based classification in general, more research is needed to improve convergence across studies and further advance confidence in experimental results. We consider three potential sources for bias: comparing classifiers over one or a small number of proprietary data sets, relying on accuracy indicators that are conceptually inappropriate for software defect prediction and cross-study comparisons, and, finally, limited use of statistical testing procedures to secure empirical findings. To remedy these problems, a framework for comparative software defect prediction experiments is proposed and applied in a large-scale empirical comparison of 22 classifiers over 10 public domain data sets from the NASA Metrics Data repository. Overall, an appealing degree of predictive accuracy is observed, which supports the view that metric-based classification is useful. However, our results indicate that the importance of the particular classification algorithm may be less than previously assumed since no significant performance differences could be detected among the top 17 classifiers."
pub.1094772648,Software Quality Classification Modeling Using the SPRINT Decision Tree Algorithm,"Predicting the quality of system modules prior to software testing and operations can benefit the software development team. Such a timely reliability estimation can be used to direct cost-effective quality improvement efforts to the high-risk modules. Tree-based software quality classification models based on software metrics are used to predict whether a software module is fault-prone or not fault-prone. They are white box quality estimation models with good accuracy, and are simple and easy to interpret. This paper presents an in-depth study of calibrating classification trees for software quality estimation using the SPRINT decision tree algorithm. Many classification algorithms have memory limitations including the requirement that data sets be memory resident. SPRINT removes all of these limitations and provides a fast and scalable analysis. It is an extension of a commonly used decision tree algorithm, CART, and provides a unique tree-pruning technique based on the Minimum Description Length (MDL) principle. Combining the MDL pruning technique and the modified classification algorithm, SPRINT yields classification trees with useful prediction accuracy. The case study used comprises of software metrics and fault data collected over four releases from a very large telecommunications system. It is observed that classification trees built by SPRINT are more balanced and demonstrate better stability in comparison to those built by CART."
pub.1035889139,Metrics to study symptoms of bad software designs,"Design of a software product largely influences its quality. Good design is one of the pre-requisites of a high quality product. Me-trics are usually used to assess the quality of software designs. The metrics for object oriented design focus on design characteristics, such as abstraction, coupling, cohesion, inheritance, polymorphism and encapsulation and are applied at attribute, method, class, pack-age, file and systems levels. Design metrics help the software de-signers to understand the problem areas in a design and to develop prediction models. A number of studies have modeled relation-ships between object oriented metrics and reusability, defects and faults, maintainability, and effort, and cost savings. So design me-trics can give an early indication of goodness of design and thus of the software product developed using that design. If designers know symptoms of bad design then it is helpful for them to avoid the bad design. In this paper, we have explored some of the symp-toms of bad design and studied metric relationships which high-light these symptoms."
pub.1165699957,An empirical analysis of software fault proneness using factor analysis with regression,"The fault prediction process becomes essential in the early stages of Software Development Life Cycle, so as to be able to generate various modules that can thereafter help detect faulty modules and classes. Further, this procedure will facilitate identification of modules that require a high level of refactoring during the maintenance stage. Hence, the current research proposes a mechanism to recognise faults and to explore the usability of Factor Analysis with Regression (FAWR) which can help ameliorate the system performance remarkably. To direct this study, two research questions (RQ) are defined- how can integration of techniques to enhance the development of fault prediction model, and evaluation of the suggested technique to overcome the limitations of the older methods. In order to answer these RQs, FAWR techniques are applied. The quality of the technique is then tested through two experiments. Results reveal that FAWR is the better performing method in terms of its prediction capability compared to the two methods used individually. For example, values for different performance metrics such as accuracy, precision, recall and F1 score reported by FAWR technique are 89.34%, 88.73%, 88.49 % and 88.61 %, respectively. The current study has practical implications as the models constructed to estimate the proneness of faults surpass the standard regression models. The factorization method used shall be able to classify any module based on its fault proneness. The more efficient and reliable software thus produced will have better outcomes for the users for basic and applied research purposes."
pub.1163893165,An Enhanced Convolutional Neural Network Schema for Structural Class-based Software Fault Prediction,"<p>Malicious software detection is the most prominent process required by various industries to avoid server failure. It is required to detect malicious software accurately to avoid time and cost wastage. Various research works have been introduced earlier for the detection of malicious software. In the existing work Support Vector Machine (SVM) is introduced for malicious software detection. However, existing works cannot perform well where there are error modules in the software. It is addressed in this suggested study by developing Coupling and Cohesion Metrics based Fault Detection (CCMFD). In this research work, structural measures are mainly examined which come under the cohesion measures and comprise deficient cohesion in approaches (LCOM), and Conceptual Coupling between Object Classes (CCBO). Failure situ- ations and measures relating to information flow are used in other techniques. A high-quality service has a low coupling and a high cohesiveness. These extracted features will be given as input to the enhanced Convolutional Neural Network (CNN) for software mistake forecasting. A complete study analysis is done in a Java simulator, indicating that the suggested approach tends to have superior fault prediction outcomes than the current method.</p>"
pub.1157484854,A Comparative Study of Classification Techniques and Imbalanced Data Treatment for Prediction of Software Faults,"<p>Software Defect Prediction is one of the major challenges faced by software engineers across the world as software grows in size and function. It is the process of identifying error-prone modules in software before the testing phase, which helps with cost-cutting and saves time. The primary goal of this research is to compare the different data balancing techniques along with the popular classification models used for software fault prediction and optimize the best results. In this study, we have used the AEEEM dataset, along with mean value treatment and min-max scaling to pre-process data. Then dataset balancing is performed using class-weight-based, over-sampling, under-sampling, and hybridization techniques. The balanced datasets are now analyzed using 5 classification techniques: Random Forest Classifier, XGBoost, Support Vector Classifier, LightGBM, and Logistic Regression. Thus, a total of 25 combinations are accessed to find the best results using 10-fold cross-validation with f1-score and AUC as the performance metric. Further, the best methods are improved using feature selection. Finally, the best case is optimized using Optuna.</p>"
pub.1041879965,Accuracy of software quality models over multiple releases,"Many evolving mission‐critical systems must have high software reliability. However, it is often difficult to identify fault‐prone modules early enough in a development cycle to guide software enhancement efforts effectively and efficiently. Software quality models can yield timely predictions of membership in the fault‐prone class on a module‐by‐module basis, enabling one to target enhancement techniques. However, it is an open empirical question, “Can a software quality model remain useful over several releases?” Most prior software quality studies have examined only one release of a system, evaluating the model with modules from the same release. We conducted a case study of a large legacy telecommunications system where measurements on one software release were used to build models, and three subsequent releases of the same system were used to evaluate model accuracy. This is a realistic assessment of model accuracy, closely simulating actual use of a software quality model. A module was considered fault‐prone if any of its faults were discovered by customers. These faults are extremely expensive due to consequent loss of service and emergency repair efforts. We found that the model maintained useful accuracy over several releases. These findings are initial empirical evidence that software quality models can remain useful as a system is maintained by a stable software development process."
pub.1094795038,A Multi-Instance Model for Software Quality Estimation in OO Systems,"In this paper, a problem of object-oriented (OO) software quality estimation is investigated with a multi-instance (MI) perspective. In detail, each set of classes that have inheritance relation, named ‘class hierarchy’, is regarded as a bag in the training, while each class in the bag is regarded as an instance. The task of the software quality estimation in this study is to predict the label of unseen bags, i.e. the fault-proneness of untested class hierarchies. It is stipulated that a fault-prone class hierarchy contains at least one fault-prone (negative) class, while a not fault-prone (positive) one has no negative class. Based on the modification records (MR) of previous project releases and 00 software metrics, the fault-proneness of untested class hierarchy can be predicted. A MI kernel specifically designed for MI data was utilized to build the OO software quality prediction model. This model was evaluated on five datasets collected from an industrial optical communication software project. Among the MI learning algorithms applied in our empirical study, the support vector algorithms combined with dedicated MI kernel led others in accurately and correctly predicting the fault-proneness of the class hierarchy."
pub.1032254272,Count Models for Software Quality Estimation,"Timely and accurate prediction of the quality of software modules in the early stages of the software development life cycle is very important in the field of software reliability engineering. With such predictions, a software quality assurance team can assign the limited quality improvement resources to the needed areas and prevent problems from occurring during system operation. Software metrics-based quality estimation models are tools that can achieve such predictions. They are generally of two types: a classification model that predicts the class membership of modules into two or more quality-based classes (Khoshgoftaar et al., 2005b), and a quantitative prediction model that estimates the number of faults (or some other quality factor) that are likely to occur in software modules (Ohlsson et al., 1998). In recent years, a variety of techniques have been developed for software quality estimation (Briand et al., 2002; Khoshgoftaar et al., 2002; Ohlsson et al., 1998; Ping et al., 2002), most of which are suited for either prediction or classification, but not for both. For example, logistic regression (Khoshgoftaar & Allen, 1999) can only be used for classification, whereas multiple linear regression (Ohlsson et al., 1998) can only be used for prediction. Some software quality estimation techniques, such as case-based reasoning (Khoshgoftaar & Seliya, 2003), can be used to calibrate both prediction and classification models, however, they require distinct modeling approaches for both types of models. In contrast to such software quality estimation methods, count models such as the Poisson regression model (PRM) and the zero-inflated Poisson (ziP) regression model (Khoshgoftaar et al., 2001) can be applied to yield both with just one modeling approach. Moreover, count models are capable of providing the probability that a module has a given number of faults. Despite the attractiveness of calibrating software quality estimation models with count modeling techniques, we feel that their application in software reliability engineering has been very limited (Khoshgoftaar et al., 2001). This study can be used as a basis for assessing the usefulness of count models for predicting the number of faults and quality-based class of software modules."
pub.1021018498,A quantitative analysis of the unit verification perspective on fault distributions in complex software systems: an operational replication,"Unit verification, including software inspections and unit tests, is usually the first code verification phase in the software development process. However, principles of unit verification are weakly explored, mostly due to the lack of data, since unit verification data are rarely systematically collected and only a few studies have been published with such data from industry. Therefore, we explore the theory of fault distributions, originating in the quantitative analysis by Fenton and Ohlsson, in the weakly explored context of unit verification in large-scale software development. We conduct a quantitative case study on a sequence of four development projects on consecutive releases of the same complex software product line system for telecommunication exchanges. We replicate the operationalization from earlier studies, analyzed hypotheses related to the Pareto principle of fault distribution, persistence of faults, effects of module size, and quality in terms of fault densities, however, now from the perspective of unit verification. The patterns in unit verification results resemble those of later verification phases, e.g., regarding the Pareto principle, and may thus be used for prediction and planning purposes. Using unit verification results as predictors may improve the quality and efficiency of software verification."
pub.1002439831,Software Metrics and Measurements,"In the past few years, a large number of e-government and e-commerce systems have been developed, thus resulting to a constantly increasing number of software developers involved in software development for such systems. To ensure the production of high quality e-government and e-commerce systems, it is important for developers to collect and analyze measurable data that guide estimation, decision making, and assessment. It is common sense that one can control and manage better what he is able to measure. Although there are major differences between e-commerce and e-government (e.g., access, structure and accountability; Jorgenson & Cable, 2002) there are no significant differences in terms of software metrics that can be applied to both. Metrics are used in e-government and e-commerce software development to measure various factors related to software quality and can be classified as product metrics, process metrics and recourse metrics. Product metrics are also called software metrics. These are metrics that are directly related to the product itself, such as code statements, delivered executables, manuals, and strive to measure product quality, or attributes of the product that can be related to product quality. Process metrics focus on the process of software development and measure process characteristics, aiming to detect problems or to push forward successful practices. Resource metrics are related to the resources required for software development and their performance. This article focuses on product metrics and on how such metrics can aid in design, prediction and assessment of the final product quality, provide data used for decision making, cost and effort estimation, fault prevention, testing time reduction, and, consequently, aid in producing better software for e-government and e-commerce sys"
pub.1093737588,Toward the Use of Automated Static Analysis Alerts for Early Identification of Vulnerability- and Attack-prone Components,"Extensive research has shown that software metrics can be used to identify fault- and failure-prone components. These metrics can also give early indications of overall software quality. We seek to parallel the identification and prediction of fault- and failure-prone components in the reliability context with vulnerability- and attack-prone components in the security context. Our research will correlate the quantity and severity of alerts generated by source code static analyzers to vulnerabilities discovered by manual analyses and testing. A strong correlation may indicate that automated static analyzers (ASA), a potentially early technique for vulnerability identification in the development phase, can identify high risk areas in the software system. Based on the alerts, we may be able to predict the presence of more complex and abstract vulnerabilities involved with the design and operation of the software system. An early knowledge of vulnerability can allow software engineers to make informed risk management decisions and prioritize redesign, inspection, and testing efforts. This paper presents our research objective and methodology."
pub.1095234367,Improving tree-based models of software quality with principal components analysis,"Software quality classification models can predict which modules are to be considered fault-prone, and which are not, based on software product metrics, process metrics and execution metrics. Such predictions can be used to target improvement efforts to those modules that need them the most. Classification-tree modeling is a robust technique for building such software quality models. However, the model structure may be unstable, and accuracy may suffer when the predictors are highly correlated. This paper presents an empirical case study of four releases of a very large telecommunications system, which shows that the tree-based models can be improved by transforming the predictors with principal components analysis, so that the transformed predictors are not correlated. The case study used the regression-tree algorithm in the S-Plus package and then applied a general decision rule to classify the modules."
pub.1095054505,Fault Prediction by Utilizing Self-Organizing Map and Threshold,"Predicting parts of the programs that are more defects prone could ease up the software testing process, which leads to testing cost and testing time reduction. Fault prediction models use software metrics and defect data of earlier or similar versions of the project in order to improve software quality and exploit available resources. However, some issues such as cost, experience, and time, limit the availability of faulty data for modules or classes. In such cases, researchers focus on unsupervised techniques such as clustering and they use experts or thresholds for labeling modules as faulty or not faulty. In this paper, we propose a prediction model by utilizing self-organizing map (SOM) with threshold to build a better prediction model that could help testers in labeling process and does not need experts to label the modules any more. Data sets obtained from three Turkish white-goods controller software are used in our empirical investigation. The results based on the proposed technique is shown to aid the testers in making better estimation in most of the cases in terms of overall error rate, false positive rate (FPR), and false negative rate (FNR)."
pub.1093693363,Integrated maintainability analysis: a practical case study,"Working from preliminary time estimates and software expectations, a system for premature maintainability analysis and prediction for a parallel signal processing system was offered on schedule to the customer. Upon review, a mutual plan was agreed that further data was needed and would be obtained, throughout the fault isolation software development and formal testing. Early fault insertion data provided a new software design direction, physical time studies verified selection of the best tools, formal BIT diagnostic testing isolated some software corrections and provided significant data points along with the formal maintainability demonstration. Using the initial maintainability model as the controlling metric throughout the program, each time a change was observed that could effect one or more of the parameters in the model, a new prediction was calculated. These reiterative calculations, integrating the progression of data, provided a consistent measure of the teams progress and assured a final best estimate of the systems maintainability capability with a level of confidence acceptable to ourselves and our customer.<>"
pub.1137195902,"Feature-Oriented Defect Prediction: Scenarios, Metrics, and Classifiers","Several software defect prediction techniques have been developed over the
past decades. These techniques predict defects at the granularity of typical
software assets, such as components and files. In this paper, we investigate
feature-oriented defect prediction: predicting defects at the granularity of
features -- domain-entities that represent software functionality and often
cross-cut software assets. Feature-oriented defect prediction can be beneficial
since: (i) some features might be more error-prone than others, (ii)
characteristics of defective features might be useful to predict other
error-prone features, and (iii) feature-specific code might be prone to faults
arising from feature interactions. We explore the feasibility and solution
space for feature-oriented defect prediction. Our study relies on 12 software
projects from which we analyzed 13,685 bug-introducing and corrective commits,
and systematically generated 62,868 training and test datasets to evaluate
classifiers, metrics, and scenarios. The datasets were generated based on the
13,685 commits, 81 releases, and 24, 532 permutations of our 12 projects
depending on the scenario addressed. We covered scenarios such as just-in-time
(JIT) and cross-project defect prediction. Our results confirm the feasibility
of feature-oriented defect prediction. We found the best performance (i.e.,
precision and robustness) when using the Random Forest classifier, with process
and structure metrics. Surprisingly, single-project JIT and release-level
predictions had median AUC-ROC values greater than 95% and 90% respectively,
contrary to studies that assert poor performance due to insufficient training
data. We also found that a model trained on release-level data from one of the
twelve projects could predict defect-proneness of features in the other eleven
projects with median AUC-ROC of 82%, without retraining."
pub.1094653568,Software Fault Prediction Model Based on Adaptive Dynamical and Median Particle Swarm Optimization,"Software quality prediction can play a role of importance in software management, and thus in improve the quality of software systems. By mining software with data mining technique, predictive models can be induced that software managers the insights they need to tackle these quality problems in an efficient way. This paper deals with the adaptive dynamic and median particle swarm optimization (ADMPSO) based on the PSO classification technique. ADMPSO can act as a valid data mining technique to predict erroneous software modules. The predictive model in this paper extracts the relationship rules of software quality and metrics. Information entropy approach is applied to simplify the extraction rule set. The empirical result shows that this method set of rules can be streamlined and the forecast accuracy can be improved."
pub.1030161394,By no means,"Fault prediction models usually employ software metrics which were previously shown to be a strong predictor for defects, e.g., SLOC. However, metrics are usually defined on a microlevel (method, class, package), and should therefore be aggregated in order to provide insights in the evolution at the macro-level (system). In addition to traditional aggregation techniques such as the mean, median, or sum, recently econometric aggregation techniques, such as the Gini, Theil, and Hoover indices have been proposed. In this paper we wish to understand whether the aggregation technique influences the presence and strength of the relation between SLOC and defects. Our results indicate that correlation is not strong, and is influenced by the aggregation technique."
pub.1061789019,Assessing the Cost Effectiveness of Fault Prediction in Acceptance Testing,"Until now, various techniques for predicting fault-prone modules have been proposed and evaluated in terms of their prediction performance; however, their actual contribution to business objectives such as quality improvement and cost reduction has rarely been assessed. This paper proposes using a simulation model of software testing to assess the cost effectiveness of test effort allocation strategies based on fault prediction results. The simulation model estimates the number of discoverable faults with respect to the given test resources, the resource allocation strategy, a set of modules to be tested, and the fault prediction results. In a case study applying fault prediction of a small system to acceptance testing in the telecommunication industry, results from our simulation model showed that the best strategy was to let the test effort be proportional to ""the number of expected faults in a module × log(module size)."" By using this strategy with our best fault prediction model, the test effort could be reduced by 25 percent while still detecting as many faults as were normally discovered in testing, although the company required about 6 percent of the test effort for metrics collection, data cleansing, and modeling. The simulation results also indicate that the lower bound of acceptable prediction accuracy is around 0.78 in terms of an effort-aware measure, Norm(Popt). The results indicate that reduction of the test effort can be achieved by fault prediction only if the appropriate test strategy is employed with high enough fault prediction accuracy. Based on these preliminary results, we expect further research to assess their general validity with larger systems."
pub.1123601847,SLDeep: Statement-level software defect prediction using deep-learning model on static code features,"Software defect prediction (SDP) seeks to estimate fault-prone areas of the code to focus testing activities on more suspicious portions. Consequently, high-quality software is released with less time and effort. The current SDP techniques however work at coarse-grained units, such as a module or a class, putting some burden on the developers to locate the fault. To address this issue, we propose a new technique called as Statement-Level software defect prediction using Deep-learning model (SLDeep). The significance of SLDeep for intelligent and expert systems is that it demonstrates a novel use of deep-learning models to the solution of a practical problem faced by software developers. To reify our proposal, we defined a suite of 32 statement-level metrics, such as the number of binary and unary operators used in a statement. Then, we applied as learning model, long short-term memory (LSTM). We conducted experiments using 119,989 C/C++ programs within Code4Bench. The programs comprise 2,356,458 lines of code of which 292,064 lines are faulty. The benchmark comprises a diverse set of programs and versions, written by thousands of developers. Therefore, it tends to give a model that can be used for cross-project SDP. In the experiments, our trained model could successfully classify the unseen data (that is, fault-proneness of new statements) with average performance measures 0.979, 0.570, and 0.702 in terms of recall, precision, and accuracy, respectively. These experimental results suggest that SLDeep is effective for statement-level SDP. The impact of this work is twofold. Working at statement-level further alleviates developer's burden in pinpointing the fault locations. Second, cross-project feature of SLDeep helps defect prediction research become more industrially-viable."
pub.1063001066,ENSEMBLE OF SOFTWARE DEFECT PREDICTORS: AN AHP-BASED EVALUATION METHOD,"Classification algorithms that help to identify software defects or faults play a crucial role in software risk management. Experimental results have shown that ensemble of classifiers are often more accurate and robust to the effects of noisy data, and achieve lower average error rate than any of the constituent classifiers. However, inconsistencies exist in different studies and the performances of learning algorithms may vary using different performance measures and under different circumstances. Therefore, more research is needed to evaluate the performance of ensemble algorithms in software defect prediction. The goal of this paper is to assess the quality of ensemble methods in software defect prediction with the analytic hierarchy process (AHP), which is a multicriteria decision-making approach that prioritizes decision alternatives based on pairwise comparisons. Through the application of the AHP, this study compares experimentally the performance of several popular ensemble methods using 13 different performance metrics over 10 public-domain software defect datasets from the NASA Metrics Data Program (MDP) repository. The results indicate that ensemble methods can improve the classification results of software defect prediction in general and AdaBoost gives the best results. In addition, tree and rule based classifiers perform better in software defect prediction than other types of classifiers included in the experiment. In terms of single classifier, K-nearest-neighbor, C4.5, and Naïve Bayes tree ranked higher than other classifiers."
pub.1096189817,The Potential of Key Process/Performance Indicators (KPIs) in Automotive Software Quality Management,"A steady increasing share and complexity of automotive software is a huge challenge for quality management during software development and in-use phases. In cases of faults occurring in customer’s use, warranty leads to product recalls which are typically associated with high costs. To avoid software faults efficiently, quality management and enhanced development processes have to be realized by the introduction of specific analysis methods and Key Process/Performance Indicators (KPIs) to enable objective quality evaluations as soon as possible during product development process. The paper introduces an application of specific analysis methods by using KPIs and discusses their potential for automotive software quality improvement. Target is to support quality evaluation and risk-analysis for the release process of automotive software. A new approach is presented, which enables an objective analysis of the software development process by use of stochastic analysis methods to gain an estimation of software reliability. Modelling of the expected residual error rate at certain release points during development provides basis information for the decision, if further development or tests are necessary. In addition, it delivers prediction of expected failure performance during in-use phases. A comparison of stochastic fault rate models, covering development and in-use phases, highlights potentials of enhancement and improvement of different prediction models. Finally, the paper presents and evaluates a combination of indicators, metrics as well as stochastic methods to deliver risk analysis for software release processes, with the target to optimize reliability at the costumer, decrease fault costs and support an improvement of development processes."
pub.1125662688,Software quality analysis based on cost and error using fuzzy combined COCOMO model,"Software quality analysis and estimation is essential in developing a software to avoid faults and increase the reliability. Software quality model (SQM) is highly concerned with standard metrics to qualify the software modules to classify bug or no bug. By using these models, it is easy to identify the hurdles called as errors or faults Apriori to the development cycle. More likely the metrics will not follow the standard protocol in terms of size, performance, technology and the complexity involved. It will vary across the projects. Surprisingly there is no model-based architecture driven tool is available to intact the baseline estimates of the project based on the previous knowledge resource. In earlier research works, various quality assurance metrics are used for analysing the SQ. Also, there is no existing approaches can do earlier prediction of the faults/errors or reduced misclassification rates. But, the COCOMO (COnstructive COst MOdel) gives an approximate estimate in terms of the month constant will not be same for simulating the study. Hence By combining more than one model estimates COCOMO and Gaussian Membership Function software estimate relative error will be the best suite. A fuzzy-based analogy is obtained in the present study to select the nearest path from the history available to meet the project cost and time. Small or standard training sets were considered to deploy the estimate, and compare the performance with different estimators. From the experiment, it is concluded that the proposed fuzzy-COCOMO model outperforms than the existing approaches in terms of relative error."
pub.1171280876,Early Detection of Permanent Faults in DNNs Through the Application of Tensor-Related Metrics,"Computational models based on deep learning are today integrated in many safety-critical domains. These algorithms, such as deep neural networks (DNNs), are rapidly growing in size, reaching billions or even trillions of parameters. This factor brings big challenges not only for performance goals but also for dependability aspects such as reliability. The larger the model, the more challenging the reliability assessment becomes. It is now crucial to develop new test approaches supported by acceptable computational costs for the detection of random-hardware faults such as permanent faults, which may change the predictions of DNNs. The aim of this paper is to leverage tensor-related metrics to early detect faulty behaviors during the inference of DNNs. This involves calculating metrics applied to tensors across various domains (such as image processing, audio analysis, and regression) on the Output Feature Maps (OFMs) of a layer. This analysis allows knowing in advance the effect that a permanent fault will have on the output of the DNN application. The effectiveness of the approach has been experimentally demonstrated by means of software fault injection campaigns considering faults affecting weights of Convolutional Neural Networks (CNNs), i.e., ResNet20 and MobileNetV2. The quality of the metrics is discussed in terms of the trade-off between energy consumption and the ability to differentiate between critical and non-critical faults."
pub.1095619387,A phase-based approach to creating highly reliable software,"Software reliability engineering includes: software reliability measurement, which includes estimation and prediction, with the help of software reliability models established in the literature; the attributes and metrics of product design, development process, system architecture, software operational environment, and their implications on reliability; and the application of this knowledge in specifying and guiding system software architecture, development, testing, acquisition, use, and maintenance. My position is that we should attack the problem of software reliability engineering in three phases: modeling and analysis phase; design and implementation phase; and testing and measurement phase. All these phases deal with the management of software faults and failures."
pub.1127941581,NHPP-Based SRGM Using Time-Dependent Fault Reduction Factors (FRF) and Gompertz TEF,"Fault reduction factor (FRF) is a key feature in the assessment of the software aspect and achieving the mission reliability in many software embedded complex systems. In literature on software reliability, there is scarcity of research contributions which deal with fault reduction factors (FRFs) and testing effort functions (TEFs) while developing reliability models for the software. The FRF can be included in the reliability models to quantify the effectiveness of the testing process. A modified model for the reliability growth prediction of the software in generic form by incorporating the FRF and Gompertz testing effort function (TEF) is investigated. The mean value function is derived by considering the non-homogenous Poisson process (NHPP) so as to analyze the fault contents which are further used to evaluate the total testing cost and reliability indices. By performing the sensitivity analysis, we study the effects of change in the system descriptors on the reliability and other performance metrics of the proposed model with FRF and Gompertz TEF."
pub.1095708215,Experience from Replicating Empirical Studies on Prediction Models,"When conducting empirical studies, replications are important contributors to investigate the generality of the studies. By replicating a study in another context, it is investigated which impact the specific environment has, related to the effect of the studied object. In this paper, we define different levels of replication to characterise the similarities and differences between an original study and a replication with particular focus on prediction models for identification of fault-prone components. Further, we derive a set of issues and concerns which are important in order to enable replication of an empirical study and to enable practitioners to use the results. To illustrate the importance of the raised issues, a replication case study is presented in the domain of prediction models for fault-prone software components. It is concluded that the results are very divergent depending on how different parameters are chosen, which demonstrates the need for well documented empirical studies to enable replication and use."
pub.1000454471,Metric-driven classification analysis,"Metric-driven classification models identify software components with user-specifiable properties, such as those likely to be fault-prone, have high development effort, or have faults in a certain class. These models are generated automatically from past metric data, and they are scalable to large systems and calibratable to different projects. These models serve as extensible integration frameworks for software metrics because they allow the addition of new metrics and integrate symbolic and numeric data from all four measurement abstractions. In our past work, we developed and evaluated techniques for generating tree-based classification models. In this paper, we investigate a technique for generating network-based classification models. The principle underlying the tree-based models is partitioning, while the principle underlying the network-based models is pattern matching. Tree-based models prune away information and can be decomposed, while network-based models retain all information and tend to be more complex. We evaluate the predictive accuracy of network-based models and compare them to the tree-based models.The evaluative study uses metric data from 16 NASA production systems ranging in size from 3000 to 112,000 source lines. The goal of the classification models is to identify the software components in the systems that had “high” development faults or effort, where “high” is defined to be in the uppermost quartile relative to past data. The models are derived from 74 candidate metrics that capture a multiplicity of information about the components: development effort, faults, changes, design style, and implementation style. A total of 1920 tree- and network-based models are automatically generated, and their predictive accuracies are compared in terms of correctness, completeness, and consistency using a non-parametric analysis of variance model. On the average, the predictions from the network-based models had 89.6% correctness, 69.1% completeness, and 79.5% consistency, while those from the tree-based models had 82.2% correctness, 56.3% completeness, and 74.5% consistency. The network-based models had statistically higher correctness and completeness than did the tree-based models, but they were not different statistically in terms of consistency. Capabilities to generate metric-driven classification models will be supported in the Amadeus measurement-driven analysis and feedback system."
pub.1033188833,"A comparative study of fault density prediction in aspect-oriented systems using MLP, RBF, KNN, RT, DENFIS and SVR models","This paper investigates and empirically evaluates and compares six popular computational intelligence models in the context of fault density prediction in aspect-oriented systems. These models are multi-layer perceptron (MLP), radial basis function (RBF), k-nearest neighbor (KNN), regression tree (RT), dynamic evolving neuro-fuzzy inference system (DENFIS), and support vector regression (SVR). The models were trained and tested, using leave-one-out procedure, on a dataset that consists of twelve aspect-level metrics (explanatory variables) that measure different structural properties of an aspect. It was observed that the DENFIS, SVR, and RT models were more accurate in predicting fault density compared to the MLP, RBF, and KNN models. The MLP model was the worst model, and all the other models were significantly better than it."
pub.1170791119,Decision Making on a Software Upgrade or Decommission with Data Mining and Machine Learning Techniques in Information Technology Industry,"The Organizations have been investing more in Technology and Infrastructure spends like software upgrades, software renewals, software replacements, platform migrations etc., apart from investment in Business, People, and Processes. In this context, it is not an easy task for stakeholders to decide whether to go for a software upgrade or to replace it with another software. There is no unified approach or solution to consolidate data and relationships of Information Technology Assets, Software Upgrades, Software costs, Software defects, Software Performance Metrics, Security issues, IT system versions, service level objectives etc. Due to this, the decision making of software upgrades and software decommissioning is a tedious process and takes more time and effort. There is a need to build a solution that can integrate and validate the information like software assets, software upgrade success and failure likelihoods, cost benefit analysis of Cloud Computing, software metrics for fault prediction, software maintainability prediction results, Digital Transformation readiness and other related factors. There is an opportunity to apply Machine Learning techniques in defining and deriving the success likelihoods on the following data: Systems and data integration, software assets compatibility, operational service level agreement breaches, quality assurance metrics, security issues, number of open defects, number of defect fixes, number of priority incidents, mean time to resolve critical incidents, expected cost increase in software maintenance, potential cost reduction with the software or hardware replacement etc. This Research Proposal outlines the above mentioned to build a recommendation system aka decision tree namely Software Upgrades or Decommissions Life Cycle."
pub.1123388046,Software Defect Prediction Using Bad Code Smells: A Systematic Literature Review,"The challenge of effective refactoring in the software development cycle brought forward the need to develop automated defect prediction models. Among many existing indicators of bad code, code smells have attracted particular interest of both the research community and practitioners in recent years. In this paper, we describe the current state-of-the-art in the field of bug prediction with the use of code smells and attempt to identify areas requiring further research. To achieve this goal, we conducted a systematic literature review of 27 research papers published between 2006 and 2019. For each paper, we (i) analysed the reported relationship between smelliness and bugginess, as well as (ii) evaluated the performance of code smell data used as a defect predictor in models developed using machine learning techniques. Our investigation confirms that code smells are both positively correlated with software defects and can positively influence the performance of fault detection models. However, not all types of smells and smell-related metrics are equally useful. God Class, God Method, Message Chains smells and Smell intensity metric stand out as particularly effective. Smells such as Inappropriate Intimacy, Variable Re-assign, Clones, Middle Man or Speculative Generality require further research to confirm their contribution. Metrics describing the introduction and evolution of anti-patterns in code present a promising opportunity for experimentation."
pub.1168164610,Fault Detection and Diagnosis in Automotive Control Systems using Machine Learning,"The Software Fault detection and diagnosis approaches supports to find the fault vulnerable constituents in the software development in early stages. An effective diagnosis approach can support test administrators to locate defects and defect-vulnerable software modules. The Feature Extraction (FE) process is the applicable solution to solve high dimensionality and polynomial time complexity issue in the prediction of software defect. In this research, a new fault detection approach is proposed by utilizing the Stacked Auto Encoder (SAE) with Support Vector Machine (SVM) and Artificial Neural Network (ANN). In this approach, the ANN is utilized for the diagnosis process to distribute the data named the fault type. Now, the input generates the Deep Neural Network as well as fuzzy depiction process. the outcome of these approaches is then integrated by the dense connected layers. The proposed SAE based SVM-ANN model attains better results by utilizing evaluation metrics like Accuracy, Precision, F1-score, and Area Under Curve (AUC) values about 99.87%, 99.52%, 99.82% and 0.99 respectively which is comparatively higher than existing techniques like Unsupervised Learning, SVM, Generative Adversarial Neural Network."
pub.1162683308,An Efficient Hybrid Mine Blast Algorithm for Tackling Software Fault Prediction Problem,"An inherent problem in software engineering is that competing prediction systems have been found to produce conflicting results. Yet accurate prediction is crucial because the complexity and quality of software requirements have dramatically changed in recent years, and consumers have become considerably more demanding in terms of the cost, timeframe, and quality of software solutions. Moreover, these variables may also be in direct conflict and can only be resolved by the optimum development of software by using reliable software engineering strategies. In this paper, a novel method based on the integration of the mine blast algorithm (MBA) and the simulated annealing (SA) algorithm is used to create input connection weights and biases for a back propagation neural network (BPNN) for the purpose of addressing the software fault prediction problem (SFP). The aim of hybridizing the MBA and SA is to find a way to efficiently explore and manipulate the search space. The proposed MBA-SA was tested on 18 datasets for SFP. The results indicated that the MBA-SA outperformed the MBA on all datasets. These results were subjected to additional statistical validity, boxplot distribution, and convergence analysis. Furthermore, a comparative evaluation of MBA-SA against twenty state-of-the-art methods for various output metrics was performed, and the result indicated that the hybrid MBA-SA outperformed most other state-of-the-art methods in the majority of datasets."
pub.1149183449,A clustering approach for software defect prediction using hybrid social mimic optimization algorithm,"In this information era, software usage is intertwined with daily routine work and business. Defects in software can cause a severe economic crisis. It is a crucial task in the software industry to be able to predict software defects in advance. Software Defect Prediction (SDP) aims to identify the potential defects based on the software metrics. A software module is a software component(piece of program) that contains one or more procedure. In this study, we propose a clustering approach for grouping the software modules. This work proposes a hybrid elitist self-adaptive multi-population social mimic optimization technique (ESAMP-SMO) for clustering the software defect modules. The objective function (fitness function) of the proposed study minimizes the intra cluster distance and maximizes fault prediction rate. In this study, we used the three popular benchmark NASA datasets (CM1, JM1 and KC1) for the experimental work. The performance comparison analysis shows that the proposed clustering technique outperforms the other competitor approaches."
pub.1093889724,Fast Lossless Image Compression with Radiation Hardening By Hardware/Software Co-Design on Platform FPGAs,"Motivated by the proposed NASA HyspIRI mission, our work improves existing Radiation Hardening by Software (RHBSW) techniques with FPGA Fabric Checkpoint/Restart (F2CPR) to bring enhanced hardware/software co-designed fault tolerance to commercial FPGA devices. We evaluate our approach on Fast Lossless (FL) image compression prediction for hyperspectral imagery in order to meet real-time performance requirements that cannot be achieved with aging radiation hardened devices. We report results across several metrics including resource utilization, performance, and an analysis of the vulnerability to Single Event Upsets (SEU) through the use of a hardware based fault injector. Results show low performance overhead (4–8%) achieving a speedup of ${\bf 11.28}\times$ with a hardware accelerated implementation."
pub.1154711623,Development of Homogenous Cross-Project Defect Prediction Model Using Artificial Neural Network,"Defect prediction is an extremely new software quality assurance study field. A project team’s goal is to provide a high-quality product with no or few flaws. The quantity of flaws in a product is connected to its quality, which is also restricted by time and money. As a result, defect prediction is critical in the field of software quality. This study provides an in-depth look of the software defect/fault prediction. It covers important aspects of software defect prediction. It emphasizes several significant outstanding concerns for the future and explains the key areas of software defect prediction practice. This paper discusses methods for homogenous defect prediction (HDP), which compares metrics within projects. Our aim is to improve the quality of the software by removing the defects so that the working could be more efficient and the results would be more optimum. Our model will help in identifying the problematic modules, which would save a lot of resources that are required for the assurance of the software quality. All the algorithms and techniques of an HDP model will be Universal, but depending on the type of dataset used, the model can be used in multiple industries, for instance food, healthcare, business, and many more. We have built a HDP model using multiple activation functions. HDP models will only be applicable to balanced datasets but we have taken an unbalanced dataset for the model in order to show how to balance a dataset using multiple balancing techniques before moving to the actual development of the HDP model."
pub.1002515918,Comparative Performance of Fault-Prone Prediction Classes with K-means Clustering and MLP,"Software defect in today's era is most important in the field of software engineering. Most of the organizations used various techniques to predict defects in their products before they are delivered. Defect prediction techniques help the organizations to use their resources effectively which results in lower cost and time requirements. There are various techniques that are used for predicting defects in software before it has to be delivered. For example clustering, neural networks, support vector machine (SVM) etc. In this paper two defect prediction techniques: - K-means Clustering and Multilayer Perceptron model (MLP), are compared. Both the techniques are implemented on different platforms. K-means clustering is implemented using WEKA tool and MLP is implemented using SPSS. The results are compared to find which algorithm produces better results. In this paper Object-Oriented metrics are used for predicting defects in the software."
pub.1094113948,A Neural Network Based Approach for Modeling of Severity of Defects in Function Based Software Systems,"There is lot of work done in prediction of the fault proneness of the software systems. But, it is the severity of the faults that is more important than number of faults existing in the developed system as the major faults matters most for a developer and those major faults needs immediate attention. As, Neural networks, which have been already applied in software engineering applications to build reliability growth models predict the gross change or reusability metrics. Neural networks are non-linear sophisticated modeling techniques that are able to model complex functions. Neural network techniques are used when exact nature of input and outputs is not known. A key feature is that they learn the relationship between input and output through training. In this paper, five Neural Network Based techniques are explored and comparative analysis is performed for the modeling of severity of faults present in function based software systems. The NASA's public domain defect dataset is used for the modeling. The comparison of different algorithms is made on the basis of Mean Absolute Error, Root Mean Square Error and Accuracy Values. It is concluded that out of the five neural network based techniques Resilient Backpropagation algorithm based Neural Network is the best for modeling of the software components into different level of severity of the faults. Hence, the proposed algorithm can be used to identify modules that have major faults and require immediate attention."
pub.1173418908,A Practical Failure Prediction Model based on Code Smells and Software Development Metrics,"Making errors during software development is unavoidable. Developers inevitably make errors that take additional time to fix later. Consequently, efforts for bug fixing compete with implementing new features. Typically, the later bugs are found, the higher the cost for remediation. To address this concern, software testing should start as early as possible in software development lifecycle. For this purpose, static analysis is proposed, but typically shows too many findings and hence do not support development teams appropriately. So, it would be a benefit to premature detect those findings in static analysis that will result in failures to reduce subsequent efforts notably. The purpose of the paper is to analyze failure data from issue tracking systems that are correlated to findings from static analysis. Thereupon an artificial intelligence-based approach is used to train practicable models for business environment that enables effective prediction of software faults. The results from static analysis show that predefined complexity measures encompassed the most defects. While there are commonalities in relevant defect findings in static analysis reports, meaningful prediction models cannot be expected based solely on this data. In addition to the findings of the static analysis, metrics like code changes in a time period or number of authors involved in code changes were considered for building the prediction models. Two of the developed prediction models have a high accuracy and excellent utility rate. These resulting prediction models are currently used at Raiffeisen Software GmbH for a long-term study on failure prediction based on code smells."
pub.1022198548,Balancing Misclassification Rates in Classification-Tree Models of Software Quality,"Software product and process metrics can be useful predictorsof which modules are likely to have faults during operations.Developers and managers can use such predictions by softwarequality models to focus enhancement efforts before release.However, in practice, software quality modeling methods in theliterature may not produce a useful balance between the two kindsof misclassification rates, especially when there are few faultymodules.This paper presents a practical classificationrule in the context of classification tree models that allowsappropriate emphasis on each type of misclassification accordingto the needs of the project. This is especially important whenthe faulty modules are rare.An industrial case study using classification trees, illustrates the tradeoffs.The trees were built using the TREEDISC algorithm whichis a refinement of the CHAID algorithm. We examinedtwo releases of a very large telecommunications system, and builtmodels suited to two points in the development life cycle: theend of coding and the end of beta testing. Both trees had onlyfive significant predictors, out of 28 and 42 candidates, respectively.We interpreted the structure of the classification trees, andwe found the models had useful accuracy."
pub.1093982994,Impact of Data Sampling on Stability of Feature Selection for Software Measurement Data,"Software defect prediction can be considered a binary classification problem. Generally, practitioners utilize historical software data, including metric and fault data collected during the software development process, to build a classification model and then employ this model to predict new program modules as either fault-prone (fp) or not-fault-prone (nfp). Limited project resources can then be allocated according to the prediction results by (for example) assigning more reviews and testing to the modules predicted to be potentially defective. Two challenges often come with the modeling process: (1) high-dimensionality of software measurement data and (2) skewed or imbalanced distributions between the two types of modules (fp and nfp) in those datasets. To overcome these problems, extensive studies have been dedicated towards improving the quality of training data. The commonly used techniques are feature selection and data sampling. Usually, researchers focus on evaluating classification performance after the training data is modified. The present study assesses a feature selection technique from a different perspective. We are more interested in studying the stability of a feature selection method, especially in understanding the impact of data sampling techniques on the stability of feature selection when using the sampled data. Some interesting findings are found based on two case studies performed on datasetsfrom two real-world software projects."
pub.1152876718,Project Features That Make Machine-Learning Based Fault Proneness Analysis Successful,"Over the past years, we have witnessed the extensive use of various software fault proneness prediction techniques utilizing machine learning. These techniques use data from multiple sources representing various facets of the software systems being investigated. In spite of the complexity and performance of all such techniques and approaches proposed by the research community, we cannot yet expertly reason on the features which may render a software system a good or bad candidate for their application. In this paper, we build on the corpus of established machine learning approaches, and we perform an evaluation of system-wide process metrics versus the results acquired by the indiscriminate application of a published best set of classifiers. More specifically, we analyze the fault proneness prediction results obtained by applying a combination of the best classifiers and file features to 207 open source projects in order to identify which project features make a system suitable for Machine Learning based fault proneness analysis or not. Based on this analysis, we propose a meta-evaluator of the overall nature of a system that can be used to gauge in advance the performance that can be expected when applying the selected technique in terms of the key performance measures namely: Accuracy, Fl-measure, Precision, Recall and ROC-AUC."
pub.1140407083,An empirical study toward dealing with noise and class imbalance issues in software defect prediction,"The quality of the defect datasets is a critical issue in the domain of software defect prediction (SDP). These datasets are obtained through the mining of software repositories. Recent studies claim over the quality of the defect dataset. It is because of inconsistency between bug/clean fix keyword in fault reports and the corresponding link in the change management logs. Class Imbalance (CI) problem is also a big challenging issue in SDP models. The defect prediction method trained using noisy and imbalanced data leads to inconsistent and unsatisfactory results. Combined analysis over noisy instances and CI problem needs to be required. To the best of our knowledge, there are insufficient studies that have been done over such aspects. In this paper, we deal with the impact of noise and CI problem on five baseline SDP models; we manually added the various noise level (0–80%) and identified its impact on the performance of those SDP models. Moreover, we further provide guidelines for the possible range of tolerable noise for baseline models. We have also suggested the SDP model, which has the highest noise tolerable ability and outperforms over other classical methods. The True Positive Rate (TPR) and False Positive Rate (FPR) values of the baseline models reduce between 20–30% after adding 10–40% noisy instances. Similarly, the ROC (Receiver Operating Characteristics) values of SDP models reduce to 40–50%. The suggested model leads to avoid noise between 40–60% as compared to other traditional models."
pub.1145293059,Predicting Faultiness of Program Modules Using Mamdani Model by Fuzzy Profile Development of Software Metrics,"This research seminar proposed and implemented a new approach toward reliability and quality measurement of software systems by building a fault prediction model and faultiness degree estimation before starting the testing phase. The main goals of this model were to support decision making with regard to testing phase which leads to reduce the testing efforts, and to optimally assign the needed resources for testing activities. This research used KC2 dataset originated from National Aeronautics and Space Administration (NASA) project to evaluate the predictive accuracy of the proposed model. Software metrics in this dataset are of fuzzy nature, consequently, this work used MATLAB system to build a Mamdani fuzzy inference model. Then, this research applied and validated a published methodology for fuzzy profile development from data as an important requirement to build the model. Moreover, the proposed model utilized the capabilities of k-mean clustering algorithm as a machine learning technique to extract the fuzzy inference rules that were also required to build the model. Finally, this paper used suitable approaches to validate and evaluate the model. Accordingly, the results show that the proposed model provides significant capabilities in fault prediction and estimation."
pub.1061788656,Using the Conceptual Cohesion of Classes for Fault Prediction in Object-Oriented Systems,"High cohesion is a desirable property of software as it positively impacts understanding, reuse, and maintenance. Currently proposed measures for cohesion in Object-Oriented (OO) software reflect particular interpretations of cohesion and capture different aspects of it. Existing approaches are largely based on using the structural information from the source code, such as attribute references, in methods to measure cohesion. This paper proposes a new measure for the cohesion of classes in OO software systems based on the analysis of the unstructured information embedded in the source code, such as comments and identifiers. The measure, named the Conceptual Cohesion of Classes (C3), is inspired by the mechanisms used to measure textual coherence in cognitive psychology and computational linguistics. This paper presents the principles and the technology that stand behind the C3 measure. A large case study on three open source software systems is presented which compares the new measure with an extensive set of existing metrics and uses them to construct models that predict software faults. The case study shows that the novel measure captures different aspects of class cohesion compared to any of the existing cohesion measures. In addition, combining C3 with existing structural cohesion metrics proves to be a better predictor of faulty classes when compared to different combinations of structural cohesion metrics."
pub.1051376045,Applying the Mahalanobis-Taguchi strategy for software defect diagnosis,"The Mahalanobis-Taguchi (MT) strategy combines mathematical and statistical concepts like Mahalanobis distance, Gram-Schmidt orthogonalization and experimental designs to support diagnosis and decision-making based on multivariate data. The primary purpose is to develop a scale to measure the degree of abnormality of cases, compared to “normal” or “healthy” cases, i.e. a continuous scale from a set of binary classified cases. An optimal subset of variables for measuring abnormality is then selected and rules for future diagnosis are defined based on them and the measurement scale. This maps well to problems in software defect prediction based on a multivariate set of software metrics and attributes. In this paper, the MT strategy combined with a cluster analysis technique for determining the most appropriate training set, is described and applied to well-known datasets in order to evaluate the fault-proneness of software modules. The measurement scale resulting from the MT strategy is evaluated using ROC curves and shows that it is a promising technique for software defect diagnosis. It compares favorably to previously evaluated methods on a number of publically available data sets. The special characteristic of the MT strategy that it quantifies the level of abnormality can also stimulate and inform discussions with engineers and managers in different defect prediction situations."
pub.1011951240,Using complexity metrics to improve software security,"Information technology is quickly spreading across critical infrastructures and software has become an inevitable part of industries and organisations. At the same time, many cyberthreats are the result of poor software coding. Stuxnet, which was the most powerful cyber-weapon used against industrial control systems, exploited zero-day vulnerabilities in Microsoft Windows.1 The US Department of Homeland Security (DHS) also announced that software vulnerabilities are among the three most common cyber-security vulnerabilities in Industrial Control Systems (ICSs).2 Therefore, improving software security has an important role in increasing the security level of computer-based systems.Software vulnerability prediction is a tedious task, so automating vulnerability prediction would save a lot of time and resources. One recently used methodology in vulnerability prediction is based on automatic fault prediction using software metrics.Here, Sara Moshtari, Ashkan Sami and Mahdi Azimi of Shiraz University, Iran build on previous studies by providing more complete vulnerability information. They show what can be achieved using different classification techniques and more complete vulnerability information."
pub.1128431422,Evolutionary Computing Assisted Heterogenous Ensemble Model for Web-of-Service Software Reusability Prediction,"Software being one of the inevitable needs of industries today requires ensuring reliability of computation. On the other hand, to enhance cost of development and productivity software developers use Component based Software Development (CSD) and Free Open Source Software (FOSS) element. Existing functions or software components are used frequently to perform the task. On contrary, the uncontrolled, excessive or improper use of such components lead software faults, aging or smells, which makes overall software vulnerable. To alleviate it, software reusability estimation can be a potential solution. The classical machine learning models can be confined to perform optimal reusability prediction with highly complicate and large size software design such as Web-of-Service (WoS) software. In this paper evolutionary computing assisted ensemble model is percolated that significantly mitigates the key issues of regional minima and convergence. Being OOP software reusability prediction model, six software metrics have been extracted from WoS software, which have been processed with different base learning models. Majority voting scheme in conjunction with Genetic Algorithm based ensemble decision enables the proposed model to exhibit better performance than any other base classifiers."
pub.1093657698,Modeling software quality: the Software Measurement Analysis and Reliability Toolkit,"The paper presents the Software Measurement Analysis and Reliability Toolkit (SMART) which is a research tool for software quality modeling using case based reasoning (CBR) and other modeling techniques. Modern software systems must have high reliability. Software quality models are tools for guiding reliability enhancement activities to high risk modules for maximum effectiveness and efficiency. A software quality model predicts a quality factor, such as the number of faults in a module, early in the life cycle in time for effective action. Software product and process metrics can be the basis for such fault predictions. Moreover, classification models can identify fault prone modules. CBR is an attractive modeling method based on automated reasoning processes. However, to our knowledge, few CBR systems for software quality modeling have been developed. SMART addresses this area. There are currently three types of models supported by SMART: classification based on CBR, CBR classification extended with cluster analysis, and module-order models, which predict the rank-order of modules according to a quality factor. An empirical case study of a military command, control, and communications applied SMART at the end of coding. The models built by SMART had a level of accuracy that could be very useful to software developers."
pub.1094685547,A comparative study on the stability of software metric selection techniques,"In large software projects, software quality prediction is an important aspect of the development cycle to help focus quality assurance efforts on the modules most likely to contain faults. To perform software quality prediction, various software metrics are collected during the software development cycle, and models are built using these metrics. However, not all features (metrics) make the same contribution to the class attribute (e.g., faulty/not faulty). Thus, selecting a subset of metrics that are relevant to the class attribute is a critical step. As many feature selection algorithms exist, it is important to find ones which will produce consistent results even as the underlying data is changed; this quality of producing consistent results is referred to as “stability.” In this paper, we investigate the stability of seven feature selection techniques in the context of software quality classification. We compare four approaches for varying the underlying data to evaluate stability: the traditional approach of generating many subsamples of the original data and comparing the features selected from each; an earlier approach developed by our research group which compares the features selected from subsamples of the data with those selected from the original; and two newly-proposed approaches based on comparing two subsamples which are specifically designed to have same number of instances and a specified level of overlap, with one of these new approaches comparing within each pair while the other compares the generated subsamples with the original dataset. The empirical validation is carried out on sixteen software metrics datasets. Our results show that ReliefF is the most stable feature selection technique. Results also show that the level of overlap, degree of perturbation, and feature subset size do affect the stability of feature selection methods. Finally, we find that all four approaches of evaluating stability produce similar results in terms of which feature selection techniques are best under different circumstances."
pub.1092728838,Software metrics thresholds calculation techniques to predict fault-proneness: An empirical comparison," Context: Nowadays, fault-proneness prediction is an important field of software engineering. It can be used by developers and testers to prioritize tests. This would allow a better allocation of resources, reducing testing time and costs, and improving the effectiveness of software testing. Non-supervised fault-proneness prediction models, especially thresholds-based models, can easily be automated and give valuable insights to developers and testers on the classification performed. Objective: In this paper, we investigated three thresholds calculation techniques that can be used for fault-proneness prediction: ROC Curves, VARL (Value of an Acceptable Risk Level) and Alves rankings. We compared the performance of these techniques with the performance of four machine learning and two clustering based models. Method: Threshold values were calculated on a total of twelve different public datasets: eleven from the PROMISE Repository and another based on the Eclipse project. Thresholds-based models were then constructed using each thresholds calculation technique investigated. For comparison, results were also computed for supervised machine learning and clustering based models. Inter-dataset experimentation between different systems and versions of a same system was performed. Results: Results show that ROC Curves is the best performing method among the three thresholds calculation methods investigated, closely followed by Alves Rankings. VARL method didn’t give valuable results for most of the datasets investigated and was easily outperformed by the two other methods. Results also show that thresholds-based models using ROC Curves outperformed machine learning and clustering based models. Conclusion: The best of the three thresholds calculation techniques for fault-proneness prediction is ROC Curves, but Alves Rankings is a good choice too. In fact, the advantage of Alves Rankings over ROC Curves technique is that it is completely unsupervised and can therefore give pertinent threshold values when fault data is not available."
pub.1029312847,Which Software Modules have Faults which will be Discovered by Customers?,"Software is the medium for implementing increasingly sophisticated features during the maintenance phase as successive releases are developed. Software quality models can predict which software modules are likely to have faults that will be discovered by customers. Such models are key components of a system such as Enhanced Measurement for Early Risk Assessment of Latent Defects (EMERALD). It is a sophisticated system of decision support tools used by software designers and managers at Nortel to assess risk and improve software quality and reliability of legacy software systems. This paper reports an approach to software quality modelling that is suitable for industrial systems such as EMERALD. We conducted a case study of a large legacy telecommunications system in the maintenance phase to predict whether each module will be considered fault‐prone. The case study is distinctive in the following respects. (1) Fault‐prone modules were defined in terms of faults discovered by customers, which represent only a small fraction of the modules in the system. (2) We developed models based on software product and process metrics that can make useful predictions at the end of the coding phase and at the time of release. (3) The modelling approach is suitable for very large systems. We anticipate that refinements of this case study's models will be incorporated into EMERALD. A similar approach could be taken for other systems. Copyright © 1999 John Wiley & Sons, Ltd."
pub.1093897410,The Conceptual Cohesion of Classes,"While often defined in informal ways, software cohesion reflects important properties of modules in a software system. Cohesion measurement has been used for quality assessment, fault proneness prediction, software modularization, etc. Existing approaches to cohesion measurement in Object-Oriented software are largely based on the structural information of the source code, such as attribute references in methods. These measures reflect particular interpretations of cohesion and try to capture different aspects of cohesion and no single cohesion metric or suite is accepted as standard measurement for cohesion. The paper proposes a new set of measures for the cohesion of individual classes within an OO software system, based on the analysis of the semantic information embedded in the source code, such as comments and identifiers. A case study on open source software is presented, which compares the new measures with an extensive set of existing metrics. The differences and similarities among the approaches and results are discussed and analyzed."
pub.1152143439,Default Detection Rate-Dependent Software Reliability Model with Imperfect Debugging,"From the perspective of FDR (fault detection rate), which is an indispensable component in reliability modeling, this paper proposes two kinds of reliability models under imperfect debugging. This model is a relatively flexible and unified software reliability growth model. First, this paper examines the incomplete phenomenon of debugging and fault repair and established a unified imperfect debugging framework model related to FDR, which is called imperfect debugging type I. Furthermore, it considers the introduction of new faults during debugging and establishes a unified imperfect debugging framework model that supports multiple FDRs, called imperfect debugging type II. Finally, a series of specific reliability models are derived by integrating multiple specific FDRs into two types of imperfect debugging framework models. Based on the analysis of the two kinds of imperfect debugging models on multiple public failure data sets, and the analysis of model performance differences from the perspective of fitting metrics and prediction research, a fault detection rate function that can better describe the fault detection process is found. By incorporating this fault detection rate function into the two types of imperfect debugging models, a more accurate model is obtained, which not only has excellent performance and is superior to other models but also describes the real testing process more accurately and will guide software testers to quantitatively improve software reliability."
pub.1160128863,Performance Evaluation of various ML techniques for Software Fault Prediction using NASA dataset,"In order to improve software dependability, Software Fault Prediction (SFP) has become an important research topic in the area of software engineering. To improve program dependability, program defect predictions are being utilized to aid developers in anticipating prospective issues and optimizing testing resources. As a result of this method, the amount of software defects may be forecast, and software testing resources are directed toward the software modules that have the greatest issues, enabling the defects to be fixed as soon as possible. As a result, this paper handles the issue related for SFP based on using a dataset known as JM1 provided by NASA, with 21 features. In this study, several Machine Learning (ML) techniques will be studied, which include Logistic Regression (LR), Random Forest (RF), Naive Bias (NB), Support Vector Machine (SVM), K-Nearest Neighbor (KNN) with three distance metric, Decision Tree (DT). Three cases of normalization will be involved with investigation which are the without sampling, Random over Sample and the SMOTE. Performance evaluation will be based on various parameters such as the ACC, Recall, Precision, and F1-Score. Results obtained indicate that RF achieve the higher ACC with values of 0.81%, 0.92%, and 0.88% respectively. The comprehensive findings of this study may be utilized as a baseline for subsequent studies, allowing any claim of improved prediction using any new approach, model, or framework to be compared and confirmed. In future, the variation of feature number will be involved with performance evaluation in handling SFP."
pub.1138102862,A Novel Feature Selection Approach based on Binary Particle Swarm Optimization and Ensemble Learning for Heterogeneous Defect Prediction,"Software defect prediction is an integral part of the software development process. Defect prediction helps focus on the grey areas beforehand, thus saving the considerable amount of money that is otherwise wasted in finding and fixing the faults once the software is already in production. One of the popular areas of defect prediction in recent years is Heterogeneous Defect Prediction, which predicts defects in a target project using a source project with different metrics. Through our paper, we provide a novel feature selection based approach, En-BPSO, based on binary particle swarm optimization, coupled with majority voting ensemble classifier based fitness function for heterogeneous defect prediction. The datasets we are using are MORPH and SOFTLAB. The results show that the En-BPSO method provides the highest Friedman mean rank amongst all the feature selection methods used for comparison. En-BPSO technique also helps us dynamically determine the optimal number of features to build an accurate heterogeneous defect prediction model."
pub.1119063777,ConPredictor: Concurrency Defect Prediction in Real-World Applications,"Concurrent programs are difficult to test due to their inherent
non-determinism. To address this problem, testing often requires the
exploration of thread schedules of a program; this can be time-consuming when
applied to real-world programs. Software defect prediction has been used to
help developers find faults and prioritize their testing efforts. Prior studies
have used machine learning to build such predicting models based on designed
features that encode the characteristics of programs. However, research has
focused on sequential programs; to date, no work has considered defect
prediction for concurrent programs, with program characteristics distinguished
from sequential programs. In this paper, we present ConPredictor, an approach
to predict defects specific to concurrent programs by combining both static and
dynamic program metrics. Specifically, we propose a set of novel static code
metrics based on the unique properties of concurrent programs. We also leverage
additional guidance from dynamic metrics constructed based on mutation
analysis. Our evaluation on four large open source projects shows that
ConPredictor improved both within-project defect prediction and cross-project
defect prediction compared to traditional features."
pub.1093382833,Predicting fault-prone software modules in embedded systems with classification trees,"Embedded-computer systems have become essential elements of the modern world. For example, telecommunications systems are the backbone of society's information infrastructure. Embedded systems must have highly reliable software. The consequences of failures may be severe; down-time may not be tolerable; and repairs in remote locations are often expensive. Moreover, today's fast-moving technology marketplace mandates that embedded systems evolve, resulting in multiple software releases embedded in multiple products. Software quality models can be valuable tools for software engineering of embedded systems, because some software-enhancement techniques are so expensive or time-consuming that it is not practical to apply them to all modules. Targeting such enhancement techniques is an effective way to reduce the likelihood of faults discovered in the field. Research has shown software metrics to be useful predictors of software faults. A software quality model is developed using measurements and fault data from a past release. The calibrated model is then applied to modules currently under development. Such models yield predictions on a module-by-module basis. This paper examines the Classification And Regression Trees (CART) algorithm for predicting which software modules have high risk of faults to be discovered during operations. CART is attractive because it emphasizes pruning to achieve robust models. This paper presents details on the CART algorithm in the context of software engineering of embedded systems. We illustrate this approach with a case study of four consecutive releases of software embedded in a large telecommunications system. The level of accuracy achieved in the case study would be useful to developers of an embedded system. The case study indicated that this model would continue to be useful over several releases as the system evolves."
pub.1124681303,Heterogeneous Defect Prediction Using Ensemble Learning Technique,"One of the quite frequently used approaches that programmers adhere to during the testing phase is the software defect prediction of the life cycle of the software development, this testing becomes utmost important as it identifies potential error before the product is delivered to the clients or released in the market. Our primary concern is to forecast the errors by using an advanced heterogeneous defect prediction model based on ensemble learning technique which incorporates precisely eleven classifiers. Our approach focuses on the inculcation of supervised machine learning algorithms which paves the way in predicting the defect proneness of the software modules. This approach has been applied on historical metrics dataset of various projects of NASA, AEEEM and ReLink. The dataset has been taken from the PROMISE repository. The assessment of the models is done by using the area under the curve, recall, precision and F-measure. The results obtained are then compared to the methods that exist for predicting the faults."
pub.1100278401,ConPredictor: Concurrency Defect Prediction in Real-World Applications,"Concurrent programs are difficult to test due to their inherent non-determinism. To address this problem, testing often requires the exploration of thread schedules of a program; this can be time-consuming when applied to real-world programs. Software defect prediction has been used to help developers find faults and prioritize their testing efforts. Prior studies have used machine learning to build such predicting models based on designed features that encode the characteristics of programs. However, research has focused on sequential programs; to date, no work has considered defect prediction for concurrent programs, with program characteristics distinguished from sequential programs. In this paper, we present ConPredictor, an approach to predict defects specific to concurrent programs by combining both static and dynamic program metrics. Specifically, we propose a set of novel static code metrics based on the unique properties of concurrent programs. We also leverage additional guidance from dynamic metrics constructed based on mutation analysis. Our evaluation on four large open source projects shows that ConPredictor improved both within-project defect prediction and cross-project defect prediction compared to traditional features."
pub.1093595153,Classification tree models of software quality over multiple releases,"Software quality models are tools for focusing software enhancement efforts. Such efforts are essential for mission-critical embedded software, such as telecommunications systems, because customer-discovered faults have very serious consequences and are very expensive to repair. We present an empirical study that evaluated software quality models over several releases to address the question, ""How long will a model yield useful predictions?"" We also introduce the Classification And Regression Trees (CART) algorithm to software reliability engineering practitioners. We present our method for exploiting CART features to achieve a preferred balance between the two types of misclassification rates. This is desirable because misclassifications of fault-prone modules often have much more severe consequences than misclassifications of those that are not fault-prone. We developed two classification-tree models based on four consecutive releases of a very large legacy telecommunications system. Forty-two software product, process, and execution metrics were candidate predictors. The first software quality model used measurements of the first release as the training data set and measurements of the subsequent three releases as evaluation data sets. The second model used measurements of the second release as the training data set and measurements of the subsequent two releases as evaluation data sets. Both models had accuracy that would be useful to developers."
pub.1158153824,Service-oriented model-based fault prediction and localization for service compositions testing using deep learning techniques,"As service-oriented computing systems become more buoyant and complex, the occurrence of faults dramatically increases. Fault prediction plays a crucial role in the service-oriented computing paradigm, aiming to reduce testing cost while maximizing testing quality to utilize testing resources effectively and increase the reliability of service compositions. Although various fault prediction techniques were considered in software testing, service-oriented systems were less fortunate, in which most of the studies have focused on single web services testing rather than service compositions. Moreover, mainly the detection of faulty/non-faulty services was addressed, ignoring the estimate of faults count, their severity, as well as predicting when and where such faults would occur. In this paper, a multilateral model-based fault prediction and localization approach is proposed using deep learning techniques for web service compositions testing rather than single web service testing, which uniquely predicts not only faulty services, but also their count and severity level, location of faults, and time at which faults would occur. Three deep learning models are investigated: Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs) and a proposed hybrid model based on both CNN and RNN. The proposed approach is language-independent, as it adopts process metrics rather than code metrics to overcome the code unavailability concern of services. The experimental analysis adopted main performance metrics on multiple public datasets to evaluate its efficiency and effectiveness. The results indicated that the hybrid CNN_RNN model achieves an average accuracy range of 84%–95.7%, where the RNN and CNN models individually achieve 75%–90% and 70%-79.3% respectively. Thus, the hybrid model increases the accuracy level by 5%–10% and 15%–20%, while achieving the least mean square error of 30% and 60% compared to the RNN and CNN models respectively. In terms of time, the RNN model consumes less average time as of 30–50 ms for the different datasets of variant sizes compared to the CNN and hybrid CNN_RNN models that consume 79–102 and 177–224 ms respectively. Thus, RNN model consumes around 50%–80% less time than those of the CNN and hybrid models respectively."
pub.1095497936,An innovative tool for designing fault tolerant cockpit display symbology,"This research focuses on the design and development of a software package to aid display designers in creating fault tolerant fonts and symbology for monochrome dot-matrix displays. Since dot-matrix displays are subject to non-catastrophic failures [rows, columns, and individual picture elements], display designers find it necessary to address hardware reliability as a key design element when avoidance of operator reading errors is mission critical. This paper addresses row and column failure modes. Building redundancy into the design of font characters and symbology can provide additional protection from reading errors. The software package developed for the design of fault tolerant fonts, referred to herein as FontTool, operates on an IBM PC or compatible hardware platform within a Microsoft DOS environment. FontTool can simulate row or column dot-matrix display failures and ""predict"" likely human reading errors. Based on limited testing, FontTool reading error ""predictions"" were found to be consistent with actual human performance reading error data about 86% of the time. FontTool uses Euclidean distance between 2-D Fourier transformed representations of dot-matrix characters as a metric for predicting character ""similarity"". Although this metric has been applied previously, FontTool is a major advance in aiding display designers to build more fault tolerant cockpit display symbology.<>"
pub.1062978476,PREDICTING FAULT-PRONE SOFTWARE MODULES IN EMBEDDED SYSTEMS WITH CLASSIFICATION TREES,"Embedded-computer systems have become essential to life in modern society. For example, the backbone of society's information infrastructure is telecommunications. Embedded systems must have highly reliable software, so that we avoid the severe consequences of failures, intolerable down-time, and expensive repairs in remote locations. Moreover, today's fast-moving technology marketplace mandates that embedded systems evolve, resulting in multiple software releases embedded in multiple products.
                  Software quality models can be valuable tools for software engineering of embedded systems, because some software-enhancement techniques are so expensive or time-consuming that it is not practical to apply them to all modules. Targeting such enhancement techniques is an effective way to reduce the likelihood of faults discovered in the field. Research has shown software metrics to be useful predictors of software faults. A software quality model is developed using measurements and fault data from a past release. The calibrated model is then applied to modules currently under development. Such models yield predictions on a module-by-module basis.
                  This paper examines the Classification And Regression Trees (CART) algorithm for building tree-based models that predict which software modules have high risk of faults to be discovered during operations. CART is attractive because it emphasizes pruning to achieve robust models. This paper presents details on the CART algorithm in the context of software engineering of embedded systems. We illustrate this approach with a case study of four consecutive releases of software embedded in a large telecommunications system. The level of accuracy achieved in the case study would be useful to developers of an embedded system. The case study indicated that this model would continue to be useful over several releases as the system evolves."
pub.1094841907,"We're finding most of the bugs, but what are we missing?","We compare two types of model that have been used to predict software fault-proneness in the next release of a software system. Classification models make a binary prediction that a software entity such as a file or module is likely to be either faulty or not faulty in the next release. Ranking models order the entities according to their predicted number of faults. They are generally used to establish a priority for more intensive testing of the entities that occur early in the ranking. We investigate ways of assessing both classification models and ranking models, and the extent to which metrics appropriate for one type of model are also appropriate for the other. Previous work has shown that ranking models are capable of identifying relatively small sets of files that contain 75–95% of the faults detected in the next release of large legacy systems. In our studies of the rankings produced by these models, the faults not contained in the predicted most fault-prone files are nearly always distributed across many of the remaining files; i.e., a single file that is in the lower portion of the ranking virtually never contains a large number of faults."
pub.1152620209,Cross-Project Defect Prediction: A Literature Review,"Background: Software defect prediction models aim at identifying the potential faulty modules of a software project based on historical data collected from previous versions of the same project. Due to the lack of availability of software engineering data from the same project, the researchers proposed cross-project defect prediction (CPDP) models where the data collected from one or more projects are used to predict faults in other project. There are a number of approaches proposed with different levels of success and very limited repeatability. Goals: The purpose of this paper is to investigate the existing studies of cross-project models for defect prediction. It synthesizes the literature focusing on characteristics such as project type, software metrics, data preprocessing techniques, features selection approaches, classifiers, and performance measures used. Method: This paper follows the well-known Systematic Literature Review (SLR) approach proposed by Barbara Kitchenham in 2007. Results: Our finding shows that most of the article was published between 2015 and 2021. Moreover, the studies are mostly based on open-source datasets and the software metrics used to create the models are mainly product metrics. We also found out that most studies attempted to improve their models improving data preprocessing and feature selection approaches. Furthermore, logistic regression followed by naive bayes and random forest are the most adopted classifier techniques in such models. Finally, the f-measure followed by recall and AUC are the most preferred evaluation measure used to evaluate the performance of the models. Conclusions: This study provides an overview of the different approaches used to improve the CPDP models analyzing the different techniques used for data preprocessing, feature selection, and the selection of the classifiers. Moreover, we identified some aspects that need further investigation."
pub.1106840498,A New Framework Consisted of Data Preprocessing and Classifier Modelling for Software Defect Prediction,"
                    Different data preprocessing methods and classifiers have been established and evaluated earlier for the software defect prediction (SDP) across projects. These novel approaches have provided relatively acceptable prediction results for different software projects. However, to the best of our knowledge, few researchers have combined data preprocessing and building robust classifier simultaneously to improve prediction performances in SDP. Therefore, this paper presents a new whole framework for predicting fault-prone software modules. The proposed framework consists of instance filtering, feature selection, instance reduction, and establishing a new classifier. Additionally, we find that the 21 main software metrics commonly do follow nonnormal distribution after performing a Kolmogorov-Smirnov test. Therefore, the newly proposed classifier is built on the maximum correntropy criterion (MCC). The MCC is well-known for its effectiveness in handling non-Gaussian noise. To evaluate the new framework, the experimental study is designed with due care using nine open-source software projects with their 32 releases, obtained from the PROMISE data repository. The prediction accuracy is evaluated using
                    F-measure
                    . The state-of-the-art methods for Cross-Project Defect Prediction are also included for comparison. All of the evidences derived from the experimentation verify the effectiveness and robustness of our new framework.
                  "
pub.1062978959,Comparing Feature Selection Techniques for Software Quality Estimation Using Data-Sampling-Based Boosting Algorithms,"Software defect prediction is a classification technique that utilizes software metrics and fault data collected during the software development process to identify fault-prone modules before the testing phase. It aims to optimize project resource allocation and eventually improve the quality of software products. However, two factors, high dimensionality and class imbalance, may cause low quality training data and subsequently degrade classification models. Feature (software metric) selection and data sampling are frequently used to overcome these problems. Feature selection (FS) is a process of choosing a subset of relevant features so that the quality of prediction models can be maintained or improved. Data sampling alters the dataset to change its balance level, therefore alleviating the problem of traditional classification models that are biased toward the overrepresented (majority) class. A recent study shows that another method, called boosting (building multiple models, with each model tuned to work better on instances misclassified by previous models), is also effective for addressing the class imbalance problem. In this paper, we present a technique that uses FS followed by a boosting algorithm in the context of software quality estimation. We investigate four FS approaches: individual FS, repetitive sampled FS, sampled ensemble FS, and repetitive sampled ensemble FS, and study the impact of the four approaches on the quality of the prediction models. Ten base feature ranking techniques are examined in the case study. We also employ the boosting algorithm to construct classification models with no FS and use the results as the baseline for further comparison. The empirical results demonstrate that (1) FS is important and necessary prior to the learning process; (2) the repetitive sampled FS method generally has similar performance to the individual FS technique; and (3) the ensemble filter (including sampled ensemble filter and repetitive sampled ensemble filter) performs better than or similarly to the average of the corresponding individual base rankers."
pub.1164963960,Leveraging Time Series Autocorrelation Through Numerical Differentiation for Improving Failure Prediction,"Given the complexity of modern software systems, it is no longer possible to detect every fault before deployment. Such faults can eventually lead to failures at runtime, compromising the business process and causing significant risk or losses. Online Failure Prediction (OFP) is a complementary fault-tolerance technique that tries to predict failures in the near future, by using past data and the current state of the system. However, modern systems are comprised of many components and thus a proper characterization of its state requires hundreds of system metrics. As the system evolves through time, these data can be seen as multivariate time series, where the value of a system metric at a given time is related to its previous value. Although various techniques exist for leveraging this autocorrelation, they are often either simplistic (e.g., sliding-window), or too complex (e.g., Long-Short Term Memory (LSTM)). In this paper we propose the use of numerical differentiation, computing the first and second derivative, as a means to extract information concerning the underlying function of each system metric to support the development of predictive models for OFP. We conduct a comprehensive case using a Linux failure dataset that was generated through fault injection. Results suggest that numerical differentiation can be a promising approach to improve the performance of Machine Learning (ML) models for dependability-related problems with similar sequential characteristics (e.g., intrusion detection)."
pub.1093246157,New Conceptual Coupling and Cohesion Metrics for Object-Oriented Systems,"The paper presents two novel conceptual metrics for measuring coupling and cohesion in software systems. Our first metric, Conceptual Coupling between Object classes (CCBO), is based on the well-known CBO coupling metric, while the other metric, Conceptual Lack of Cohesion on Methods (CLCOM5), is based on the LCOM5 cohesion metric. One advantage of the proposed conceptual metrics is that they can be computed in a simpler (and in many cases, programming language independent) way as compared to some of the structural metrics. We empirically studied CCBO and CLCOM5 for predicting fault-proneness of classes in a large open-source system and compared these metrics with a host of existing structural and conceptual metrics for the same task. As the result, we found that the proposed conceptual metrics, when used in conjunction, can predict bugs nearly as precisely as the 58 structural metrics available in the Columbus source code quality framework and can be effectively combined with these metrics to improve bug prediction."
pub.1093526640,Semi-Supervised Learning for Software Quality Estimation,"A software quality estimation model is often built using known software metrics and fault data obtained from program modules of previously developed releases or similar projects. Such a supervised learning approach to software quality estimation assumes that fault data is available for all the previously developed modules. Considering the various practical issues in software project development, fault data may not be available for all the software modules in the training data. More specifically, the available labeled training data is such that a supervised learning approach may not yield good software quality prediction. In contrast, a supervised classification scheme aided by unlabeled data, i.e.) semi-supervised learning, may yield better results. This paper investigates semi-supervised learning with the Expectation Maximization (EM) algorithm for the software quality classification problem. Case studies of software measurement data obtained from two NASA software projects, JM1 and KC2, are used at our empirical investigation. A small portion of the JM1 dataset is randomly extracted and used as the labeled data, while the remaining JM1 instances are used as unlabeled data. The performance of the semi-supervised classification models built using the EM algorithm is evaluated by using the KC2 project as a test dataset. It is shown that the EM-based semi-supervised learning scheme improves the predictive accuracy of the software quality classification models."
pub.1163849050,Automatic software bug prediction using adaptive golden eagle optimizer with deep learning,"In the software maintenance and development process, the software bug detection is an essential problem because it related with the complete software successes. So, the earlier software bug detection is essential to enhance the software efficiency, reliability, software quality and software cost. Moreover, the efficient software bug prediction is a critical as well as challenging operation. Hence, the efficient software bug prediction model is developed in this article. To achieve this objective, optimized long short-term memory is developed. The important stages of the proposed model is preprocessing, feature selection and bug detection. At first the input bug dataset is preprocessed. In preprocessing, the duplicate data instances are removed from the dataset. After the preprocessing, the feature selection is done by Adaptive Golden Eagle Optimizer (AGEO). Here the traditional GEO algorithm is altered by means of opposition-based learning (OBL). Finally, the proposed approach utilizes a long short-term memory (LSTM) based recurrent neural network (RNN) for bug prediction. Long Short-Term Memory (LSTM) network is a type of recurrent neural network. The promise and NASA dataset are considered as the input for bug prediction. the performance of proposed approach is analysed based on various metrics namely, accuracy, F- measure, G-measure and Matthews Correlation Coefficient (MCC)."
pub.1093382346,Exploiting Tree Structures for Classifying Programs by Functionalities,"Analyzing source code to solve software engineering problems such as fault prediction, cost, and effort estimation always receives attention of researchers as well as companies. The traditional approaches are based on machine learning, and software metrics obtained by computing standard measures of software projects. However, these methods have faced many challenges due to limitations of using software metrics which were not enough to capture the complexity of programs. The aim of this paper is to apply several natural language processing techniques, which deal with software engineering problems by exploring information of programs' abstract syntax trees (ASTs) instead of software metrics. To speed up computational time, we propose a pruning tree technique to eliminate redundant branches of ASTs. In addition, the k-Nearest Neighbor (kNN) algorithm was adopted to compare with other methods whereby the distance between programs is measured by using the tree edit distance (TED) and the Levenshtein distance. These algorithms are evaluated based on the performance of solving 104-label program classification problem. The experiments show that due to the use of appropriate data structures although kNN is a simple machine learning algorithm, the classifiers achieve the promising results."
pub.1146733474,Comparative Analysis of Software Reliability Prediction Using Machine Learning and Deep Learning,"Software Reliability is an integral part to determine Software Quality. Software is considered to be of high quality if its reliability is high. There exist many statistical models that can help in predicting Software Reliability, but it is very difficult to consider all the real-world factors and hence it makes the task of reliability prediction very difficult. Therefore, it becomes more challenging for the IT industry to predict if a software is dependable or not. Machine Learning and Deep Learning can be used for the prediction of Software Reliability by programming a model that assesses reliability by fault prediction in a more meticulous manner. Therefore, in this study the use of predefined Artificial Intelligence algorithms, mainly Artificial Neural Network (ANN), Recurrent Neural Network (RNN), Gated Recurrent Unit (GRU) and Long Short-Term Memory (LSTM) are intended for predicting software reliability on a time series software failure dataset and are compared on the basis of selected performance metrics. Each of the algorithm trained on software failure dataset will be used to predict the software failure time after a certain number of corrective modifications are performed on the software. Based on the result of the studies, it is discovered that LSTM produces superior outcomes in predicting the software failure trend as it can capture long and short-term trends in the software failure dataset."
pub.1095189826,"PISRAT: Proportional Intensity-based Software Reliability Assessment Tool**The present research was partially supported by the Ministry of Education, Culture, Sport, Science and Technology, Grant-in-Aid for Young Scientists (B); Grant No. 18710145 (2006-2007) and Scientific Research (C); Grant No. 19510148 (2007-2008).","In this paper we develop a software reliability assessment tool, called PISRAT: Proportional Intensity-based Software Reliability Assessment Tool, by using several testing metrics data as well as software fault data observed in the testing phase. The fundamental idea is to use the proportional intensity-based software reliability models proposed by the same authors. PISRAT is written in Java language with 54 classes and 8.0 KLOC, where JDK1.5.0_9 and JFreeChart are used as the development kit and the chart library, respectively. This tool can support (i) the parameter estimation of software reliability models via the method of maximum likelihood, (ii) the goodness-of-fit test under several optimization criteria, (iii) the assessment of quantitative software reliability and prediction performance. To our best knowledge, PISRAT is the first freeware for dynamic software reliability modeling and measurement with time-dependent testing metrics."
pub.1018340604,11.4.1 Generating Predictive Models Using Decision Trees and Neural Networks for Large‐Scale Systems Engineering,"ABSTRACT Systems engineering must tackle the challenges of computational systems that are increasingly large‐scale and software‐intensive in terms of system size, component breadth and maturity, and development heterogeneity. This research describes and empirically evaluates techniques for generating predictive models for enabling large‐scale system development and management. We describe two types of metric‐driven decision models, decision trees and neural networks, which classify software components in large systems according to their likelihood of having user‐specified properties such as high fault‐proneness or high development effort. The metric‐driven decision models enable coarse‐grain analysis of large‐scale multi‐component heterogeneous systems, and they identify high‐payoff areas for directing the application of fine‐grain analysis techniques for fault detection or redesign. The decision models serve as metric integration mechanisms that enable the synergistic use of numerous metrics simultaneously and integrate measurements collected by development tools or infrastructure. Model generation techniques automatically generate the decision models to calibrate them to new projects and organizations. We evaluate the predictive effectiveness of the decision models in terms of correctness, consistency, and completeness using fault and effort data from large NASA systems. Correctness is defined as the percent of components correctly identified, consistency is defined as 100% minus the percent of false positives, and completeness is defined as 100% minus the percent of false negatives. On average, the decision models had 83.44% correctness, 71.96% consistency, and 65.25% completeness in predictions of high fault and high effort software components. The network models had 89.63% correctness, 79.49% consistency, and 69.09% completeness, while the tree models had 77.25% correctness, 64.42% consistency, and 61.40% completeness. Non‐parametric ANOVA comparisons showed that the network models were statistically more accurate than the tree models (α < 0.0001)."
pub.1143047182,Sine-Cosine Algorithm for Software Fault Prediction,"For developing an efficient and quality Software Fault Prediction (SFP) model, redundant and irrelevant features need to be removed. This task can be achieved, to a significant extent, with Feature Selection (FS) methods. Many empirical studies have been proposed on FS methods (Filter and Wrapper-based) and have shown effective results in reducing the problem of high dimensionality in metrics-based SFP models. This study evaluates the performance of novel wrapper-based Sine Cosine Algorithm (SCA) on five datasets of the AEEEM repository and compares the results with two metaheuristic techniques Genetic Algorithm (GA) and Cuckoo Search algorithm (CSA) on four different Machine Learning (ML) classifiers - Random Forest (RF), Support Vector Machine (SVM), Naïve Bayes (NB), and K-Nearest Neighbor (KNN). We found that the application of FS methods (SCA, GA & CSA) has improved the classifier performance. SCA has proved to be more efficient than GA and CSA in terms of lesser convergence time with the smallest subset of selected features and equivalent performance."
pub.1123198319,Software Defect Prediction using Hybrid Approach,"Defective software modules have significant impact over software quality leading to system crashes and software running error. Thus, Software Defect Prediction (SDP) mechanisms become essential part to enhance quality assurance activities, to allocate effort and resources more efficiently. Various machine learning approaches have been proposed to remove fault and unnecessary data. However, the imbalance distribution of software defects still remains as challenging task and leads to loss accuracy for most SDP methods. To overcome it, this paper proposed a hybrid method, which combine Support Vector Machine (SVM)-Radial Basis Function (RBF) as base learner for Adaptive Boost, with the use of Minimum-Redundancy-Maximum-Relevance (MRMR) feature selection. Then, the comparative analysis applied based on 5 datasets from NASA Metrics Data Program. The experimental results showed that hybrid approach with MRMR give better accuracy compared to SVM single learner, which is effective to deal with the imbalance datasets because the proposed method have good generalization and better performance measures."
pub.1157135172,Optimized Decision Tree-based Early Phase Software Dependability Analysis in Uncertain Environment,"Because of rapid development of software-based technology, early phase software dependability analysis has become very essential. The main purpose of this paper is to develop a novel classification model based on software dependability attributes for classification of software fault-prone modules during early phase of development. To carry out dependability analysis, early phase dependability attribute prediction is very essential. During early phase software metric value collection, metric values become uncertain due to difficulty of collection. Fuzzy Inference System (FIS) has been designed here to predict dependability attributes. A new algorithm for rule base generation has been proposed initially based on expert opinions for fuzzy inference system. These predicted software dependability attributes are applied to carry out dependability analysis. To classify software modules in early phase of development, an optimized Decision tree-based classification algorithm has been proposed to meet the main goal. Finally, Mahalanobis distance-based ranking technique has been developed based on different dependability attributes for ranking most non-dependable software modules. The proposed model has been validated based on software data sets. Software engineers will find the proposed model useful in allocating testing resources for most non-dependable software modules."
pub.1095676266,Fault-Prone Module Prediction using a Prediction Model and Manual Inspection,"This paper proposes a fault-prone prediction approach that combines a fault-prone prediction model and manual inspection. Manual inspection is conducted by a predefined checklist that consists of questions and scoring procedures. The questions capture the fault signs or indications that are difficult to be captured by source code metrics used as input by prediction models. Our approach consists of two steps. In the first, the modules are prioritized by a fault-prone prediction model. In the second step, an inspector inspects and scores $\alpha$ percent of the prioritized modules. We conducted a case study of source code modules in commercial software that had been maintained and evolved over ten years and compared AUC (Area Under the Curve) values of Alberg Diagram among three prediction models: (A) support vector machines, (B) lines of code, and (C) random predictor with four prioritization orders. Our results indicated that the maximum AUC values under appropriate $\alpha$ and the coefficient of the inspection score were larger than the AUC values of the prediction models without manual inspection in each of the four combinations and the three models in our context. In two combinations, our approach increased the AUC values to 0.860 from 0.774 and 0.724. Our results also indicated that one of the combinations monotonically increased the AUC values with the numbers of manually inspected modules. This might lead to flexible inspection; the number of manually inspected modules has not been preliminary determined, and the inspectors can inspect as many modules as possible, depending on the available effort."
pub.1061154555,A critique of software defect prediction models,"Many organizations want to predict the number of defects (faults) in software systems, before they are deployed, to gauge the likely delivered quality and maintenance effort. To help in this numerous software metrics and statistical models have been developed, with a correspondingly large literature. We provide a critical review of this literature and the state-of-the-art. Most of the wide range of prediction models use size and complexity metrics to predict defects. Others are based on testing data, the ""quality"" of the development process, or take a multivariate approach. The authors of the models have often made heroic contributions to a subject otherwise bereft of empirical studies. However, there are a number of serious theoretical and practical problems in many studies. The models are weak because of their inability to cope with the, as yet, unknown relationship between defects and failures. There are fundamental statistical and data quality problems that undermine model validity. More significantly many prediction models tend to model only part of the underlying problem and seriously misspecify it. To illustrate these points the Goldilock's Conjecture, that there is an optimum module size, is used to show the considerable problems inherent in current defect prediction approaches. Careful and considered analysis of past and new results shows that the conjecture lacks support and that some models are misleading. We recommend holistic models for software defect prediction, using Bayesian belief networks, as alternative approaches to the single-issue models used at present. We also argue for research into a theory of ""software decomposition"" in order to test hypotheses about defect introduction and help construct a better science of software engineering."
pub.1143531022,Use of Deep Learning Model with Attention Mechanism for Software Fault Prediction,"Software defect prediction is a skill in software engineering that can increase program reliability. In the past, most defect prediction studies have been based on size and complexity metrics. In recent years, machine learning based predictive studies have been conducted. To build an accurate prediction model, choosing effective features remains critical. In this paper, we constructed a deep learning model called Defect Prediction via Self-Attention mechanism (DPSAM) to extract semantic features and predict defects automatically. We transferred programs into abstract syntax trees (ASTs) and encoded them into token vectors. With input features, we trained a self-attention mechanism to extract semantic features of programs and predict defects. We evaluated performance on 7 open source projects. In Within-Project Defect Prediction (WPDP), DPSAM achieved 16.8% and 14.4% performance improvement compared to state-of-the-art deep belief network (DBN)-based method and defect prediction via convolutional neural network (DP-CNN)-based method in F1 score, respectively. Besides, in Cross-Project Defect Prediction (CPDP), DPSAM achieve 23% and 60% performance improvement in F1 score compared to DBN-based method and DP-CNN-based method."
pub.1094491729,Experience Report: Mining Test Results for Reasons other than Functional Correctness,"Regression testing is an important part of software development projects, and it is used to ensure software quality. Traditionally, a regression test focuses primarily on functional correctness of a modified program and is examined only when it fails, meaning it found a fault that would have otherwise been undetected. For certain application domains, regression tests for non-functional quality aspects such as performance, security, and usability could be just as important. However, those regression tests are much more costly and difficult to create, and thus many applications lack adequate non-functional regression test coverage. This adds risk of regressions in these areas as changes are made over time. In this research, we propose using metrics from passing test cases to predict quality aspects of the software beyond the traditional focus of regression tests. Our industrial case study shows that metrics such as test response time from functional regression tests are good predictors of which product areas are likely to contain certain types of non-functional performance faults. Furthermore, we show that this prediction can be improved through environmental perturbation such as the use of synthetic volume datasets or data size variation."
pub.1093522822,Exploring defect data from development and customer usage on software modules over multiple releases,"Traditional defect analyses of software modules have focused on either identifying error prone modules or predicting the number of faults in a module, based on a set of module attributes such as complexity, lines of code, etc. In contrast to these metrics based modeling studies, the paper explores the relationship of the number of faults per module to the prior history of the module. Specifically, we examine the relationship between: (a) the faults discovered during development of a product release and those escaped to the field; and (b) faults in the current release and faults in previous releases. Based on the actual data from four releases of a commercial application product consisting of several thousand modules, we show that: modules with more defects in development have a higher probability of failure in the field; there is a way to assess the relative quality of software releases without detailed information on the exact release content or code size; and it is sufficient to consider just the previous release for predicting the number of defects during development or field. These results can be used to improve the prediction of quality at the module level of future releases based on the past history."
pub.1014773038,Improving Fault Detection in Modified Code — A Study from the Telecommunication Industry,"Many software systems are developed in a number of consecutive releases. In each release not only new code is added but also existing code is often modified. In this study we show that the modified code can be an important source of faults. Faults are widely recognized as one of the major cost drivers in software projects. Therefore, we look for methods that improve the fault detection in the modified code. We propose and evaluate a number of prediction models that increase the efficiency of fault detection. To build and evaluate our models we use data collected from two large telecommunication systems produced by Ericsson. We evaluate the performance of our models by applying them both to a different release of the system than the one they are built on and to a different system. The performance of our models is compared to the performance of the theoretical best model, a simple model based on size, as well as to analyzing the code in a random order (not using any model). We find that the use of our models provides a significant improvement over not using any model at all and over using a simple model based on the class size. The gain offered by our models corresponds to 38–57% of the theoretical maximum gain."
pub.1138148278,Generative Adversarial Network-based Cross-Project Fault Prediction,"Background: The early stage of defect prediction in the software development
life cycle can reduce testing effort and ensure the quality of software. Due to
the lack of historical data within the same project, Cross-Project Defect
Prediction (CPDP) has become a popular research topic among researchers. CPDP
trained classifiers based on labeled data sets of one project to predict fault
in another project. Goals: Software Defect Prediction (SDP) data sets consist
of manually designed static features, which are software metrics. In CPDP,
source and target project data divergence is the major challenge in achieving
high performance. In this paper, we propose a Generative Adversarial Network
(GAN)-based data transformation to reduce data divergence between source and
target projects. Method: We apply the Generative Adversarial Method where label
data sets are choosing as real data, while target data sets are choosing as
fake data. The Discriminator tries to measure the perfection of domain
adaptation through loss function. Through the generator, target data sets try
to adapt the source project domain and, finally, apply machine learning
classifier (i.e., Naive Bayes) to classify faulty modules. Results: Our result
shows that it is possible to predict defects based on the Generative
Adversarial Method. Our model performs quite well in a cross-project
environment when we choose JDT as a target data sets. However, all chosen data
sets are facing a large class imbalance problem which affects the performance
of our model."
pub.1021856692,Towards a software failure cost impact model for the customer,"While the financial consequences of software errors on the developer's side have been explored extensively, the cost arising for the end user has been largely neglected. One reason is the difficulty of linking errors in the code with emerging failure behavior of the software. The problem becomes even more difficult when trying to predict failure probabilities based on models or code metrics. In this paper we take a first step towards a cost prediction model by exploring the possibilities of modeling the financial consequences of already identified software failures. Firefox, a well-known open source software, is used as a test subject. Historically identified failures are modeled using fault trees. To identify expenses, usage profiles are employed to depict the interaction with the system. The presented approach demonstrates the possibility to model failure cost for an organization using a specific software by establishing a relationship between user behavior, software failures, and cost. As future work, an extension with software error prediction techniques as well as an empirical validation of the model is aspired."
pub.1061788213,Assessing the applicability of fault-proneness models across object-oriented software projects,"A number of papers have investigated the relationships between design metrics and the detection of faults in object-oriented software. Several of these studies have shown that such models can be accurate in predicting faulty classes within one particular software product. In practice, however, prediction models are built on certain products to be used on subsequent software development projects. How accurate can these models be, considering the inevitable differences that may exist across projects and systems? Organizations typically learn and change. From a more general standpoint, can we obtain any evidence that such models are economically viable tools to focus validation and verification effort? This paper attempts to answer these questions by devising a general but tailorable cost-benefit model and by using fault and design data collected on two mid-size Java systems developed in the same environment. Another contribution of the paper is the use of a novel exploratory analysis technique - MARS (multivariate adaptive regression splines) to build such fault-proneness models, whose functional form is a-priori unknown. The results indicate that a model built on one system can be accurately used to rank classes within another system according to their fault proneness. The downside, however, is that, because of system differences, the predicted fault probabilities are not representative of the system predicted. However, our cost-benefit model demonstrates that the MARS fault-proneness model is potentially viable, from an economical standpoint. The linear model is not nearly as good, thus suggesting a more complex model is required."
pub.1171796038,IT2F-SEDNN: an interval type-2 fuzzy logic-based stacked ensemble deep learning approach for early phase software dependability analysis,"The growing size, complexity of software systems, and complex development process pose a difficult challenge in predicting dependability attributes during the early stages of development. Key attributes such as reliability, security, maintainability, availability, and aging play a critical role in defining the dependability of software modules. Therefore, accurate prediction of dependability attributes is of utmost importance. Existing prediction methodologies often rely on machine learning models. Software metrics are used in these studies as input for predicting dependability attributes. However, metric values can become uncertain, and machine learning models cannot address uncertainty issues of metric values. Due to the presence of uncertainty, the vulnerability or different types of defects may get overlooked during the early phase of development. Addressing this issue, this study proposes a type-2 fuzzy logic (T2FL)-based model to estimate dependability attributes effectively during an early phase. The proposed approach has leveraged human expertise in developing a rule base for the proposed T2FL model. A neural network-based approach called stacked deep neural network (SDNN) has also been proposed to analyze the impact of dependability attributes on software modules. SDNN uses the estimated dependability attributes as input, trains various architecture-based deep neural networks to classify software modules, and ensemble them to achieve better and more robust solutions. Two simulation studies have been carried out to validate the proposed methodology. The performance of the proposed approach achieves better accuracy than other baseline models. This proposed approach aims to assist software developers in developing dependable software in scheduled time with optimized costs."
pub.1162963894,Prediction of Bug Inducing Commits Using Metrics Trend Analysis,"Continuous software engineering advocates a release-small, release-often process model, where new functionality is added to a system very frequently and in small increments. In such a process model, it is important to be able to identify as early as possible, and every time a change is introduced, whether the system has entered a state where faults are more likely to occur. In this paper, we present a method that is based on process, quality, and source code metrics to evaluate the likelihood that an imminent bug inducing commit is highly probable. More specifically, the method analyzes the correlations, and the rate of change of selected structural and quality metrics. The findings from the SonarQube Technical Debt open-source dataset indicate that before bug inducing commits, metrics which otherwise are not corelated, suddenly exhibit a high correlation or high rate of metric value change. This metric behavior can then be used as a predictor for a imminent bug inducing commit. The technique is programing language agnostic, as it is based on metrics which are extracted without the use of specialized parsers, and can be applied to forewarn developers that a file, or a collection of files, has entered a state where faults are highly probable."
pub.1001616234,Software Quality Classification using Bayesian Classifier,"Many metric-based classification models have been proposed to predict fault-proneness of software module. This paper presents two prediction models using Bayesian classifier which is one of the most popular modern classification algorithms. Bayesian model based on Bayesian probability theory can be a promising technique for software quality prediction. This is due to the ability to represent uncertainty using probabilities and the ability to partly incorporate expert's knowledge into training data. The two models, NaveBayes(NB) and Bayesian Belief Network(BBN), are constructed and dimensionality reduction of training data and test data are performed before model evaluation. Prediction accuracy of the model is evaluated using two prediction error measures, Type I error and Type II error, and compared with well-known prediction models, backpropagation neural network model and support vector machine model. The results show that the prediction performance of BBN model is slightly better than that of NB. For the data set with ambiguity, although the BBN model's prediction accuracy is not as good as the compared models, it achieves better performance than the compared models for the data set without ambiguity."
pub.1122598055,BPDET: An effective software bug prediction model using deep representation and ensemble learning techniques,"In software fault prediction systems, there are many hindrances for detecting faulty modules, such as missing values or samples, data redundancy, irrelevance features, and correlation. Many researchers have built a software bug prediction (SBP) model, which classify faulty and non-faulty module which are associated with software metrics. Till now very few works has been done which addresses the class imbalance problem in SBP. The main objective of this paper is to reveal the favorable result by feature selection and machine learning methods to detect defective and non-defective software modules. We propose a rudimentary classification based framework Bug Prediction using Deep representation and Ensemble learning (BPDET) techniques for SBP. It combinedly applies by ensemble learning (EL) and deep representation(DR). The software metrics which are used for SBP are mostly conventional. Staked denoising auto-encoder (SDA) is used for the deep representation of software metrics, which is a robust feature learning method. Propose model is mainly divided into two stages: deep learning stage and two layers of EL stage (TEL). The extraction of the feature from SDA in the very first step of the model then applied TEL in the second stage. TEL is also dealing with the class imbalance problem. The experiment mainly performed NASA (12) datasets, to reveal the efficiency of DR, SDA, and TEL. The performance is analyzed in terms of Mathew co-relation coefficient (MCC), the area under the curve (AUC), precision-recall area (PRC), F-measure and Time. Out of 12 dataset MCC values over 11 datasets, ROC values over 6 datasets, PRC values overall 12 datasets and F-measure over 8 datasets surpass the existing state of the art bug prediction methods. We have tested BPDET using Wilcoxon rank sum test which rejects the null hypothesis at α = 0.025. We have also tested the stability of the model over 5, 8, 10, 12, and 15 fold cross-validation and got similar results. Finally, we conclude that BPDET is a stable and outperformed on most of the datasets compared with EL and another state of the art techniques."
pub.1085995118,An investigation of the fault-proneness of clone evolutionary patterns,"Two identical or similar code fragments form a clone pair. Previous studies have identified cloning as a risky practice. Therefore, a developer needs to be aware of any clone pairs in order to properly propagate any changes between clones. A clone pair may experience many changes during the creation and maintenance of a software system. A change can either maintain or remove the similarity between clones in a clone pair. If a change maintains the similarity between clones, the clone pair is left in a consistent state. When a change makes the clones no longer similar, the clone pair is left in an inconsistent state. The set of states and changes experienced by clone pairs over time form an evolution history known as a clone genealogy. In this paper, we examine clone genealogies to identify fault-prone “patterns” of states and changes. We explore the use of clone genealogy information in fault prediction. We conduct a quasi-experiment with four long-lived software systems (i.e., Apache Ant, ArgoUML, JEdit, Maven) and identify clones using the NiCad and iClones clone detection tools. Overall, we find that the size of the clone can impact the fault-proneness of a clone pair. However, there is no clear impact of the time interval between changes to a clone pair on the fault-proneness of the clone pair. We also discover that adding clone genealogy information can increase the explanatory power of fault prediction models."
pub.1150586965,A Comparative Analysis of SVM and ELM Classification on Software Reliability Prediction Model,"By creating an effective prediction model, software defect prediction seeks to predict potential flaws in new software modules in advance. However, unnecessary and duplicated features can degrade the model’s performance. Furthermore, past research has primarily used standard machine learning techniques for fault prediction, and the accuracy of the predictions has not been satisfactory. Extreme learning machines (ELM) and support vector machines (SVM) have been demonstrated to be viable in a variety of fields, although their usage in software dependability prediction is still uncommon. We present an SVM and ELM-based algorithm for software reliability prediction in this research, and we investigate factors that influence prediction accuracy. These worries incorporate, first, whether all previous disappointment information ought to be utilized and second, which type of disappointment information is more fitting for expectation precision. In this article, we also examine the accuracy and time of SVM and ELM-based software dependability prediction models. Then, after the comparison, we receive experimental results that demonstrate that the ELM-based reliability prediction model may achieve higher prediction accuracy with other parameters, such as specificity, recall, precision, and F1-measure. In this article, we also propose a model for how feature selection utilization with ELM and SVM. For testing, we used NASA Metrics datasets. Further, in both technologies, we are implementing feature selection techniques to get the best result in our experiment. Due to the imbalance in our dataset, we initially applied the resampling method before implementing feature selection techniques to obtain the highest accuracy."
pub.1090910001,Automatically classifying source code using tree-based approaches," Analyzing source code to solve software engineering problems such as fault prediction, cost, and effort estimation always receives attention of researchers as well as companies. The traditional approaches are based on machine learning, and software metrics obtained by computing standard measures of software projects. However, these methods have faced many challenges due to limitations of using software metrics which were not enough to capture the complexity of programs. To overcome the limitations, this paper aims to solve software engineering problems by exploring information of programs' abstract syntax trees (ASTs) instead of software metrics. We propose two combination models between a tree-based convolutional neural network (TBCNN) and k-Nearest Neighbors (kNN), support vector machines (SVMs) to exploit both structural and semantic ASTs' information. In addition, to deal with high-dimensional data of ASTs, we present several pruning tree techniques which not only reduce the complexity of data but also enhance the performance of classifiers in terms of computational time and accuracy. We survey many machine learning algorithms on different types of program representations including software metrics, sequences, and tree structures. The approaches are evaluated based on classifying 52000 programs written in C language into 104 target labels. The experiments show that the tree-based classifiers dramatically achieve high performance in comparison with those of metrics-based or sequences-based; and two proposed models TBCNN + SVM and TBCNN + kNN rank as the top and the second classifiers. Pruning redundant AST branches leads to not only a substantial reduction in execution time but also an increase in accuracy."
pub.1045366101,Empirical investigation of fault predictors in context of class membership probability estimation,"In the domain of software fault prediction, class membership probability of a selected classifier and the factors related to its estimation can be considered as necessary information for tester to take informed decisions about software quality issues. The objective of this study is to empirically investigate the class membership probability estimation capability of 15 classifiers/fault predictors on 12 datasets of open source projects retrieved from PROMISE repository. We empirically validate the effect of dataset characteristics and set of metrics on the performance of classifiers in estimating the class membership probability. We used Receiver Operating Characteristics-Area under Curve (ROC-AUC) value and overall accuracy as benchmarks to evaluate and compare the performance of classifiers. We apply Friedman's, post-hoc Nemenyi and Analysis of Means (ANOM) test to compare the significant performance of classifiers. We conclude that ADTree and RandomForest outperform, while ZeroR classifier cannot show significant performance for estimation of class membership probability."
pub.1166941589,On the adoption and effects of source code reuse on defect proneness and maintenance effort,"Software reusability mechanisms, like inheritance and delegation in Object-Oriented programming, are widely recognized as key instruments of software design that reduce the risks of source code being affected by defects, other than to reduce the effort required to maintain and evolve source code. Previous work has traditionally employed source code reuse metrics for prediction purposes, e.g., in the context of defect prediction. However, our research identifies two noticeable limitations of the current literature. First, still little is known about the extent to which developers actually employ code reuse mechanisms over time. Second, it is still unclear how these mechanisms may contribute to explaining defect-proneness and mainten0ance effort during software evolution. We aim at bridging this gap of knowledge, as an improved understanding of these aspects might provide insights into the actual support provided by these mechanisms, e.g., by suggesting whether and how to use them for prediction purposes. We propose an exploratory study, conducted on 12 Java projects–over 44,900 commits–of the Defects4J dataset, aiming at (1) assessing how developers use inheritance and delegation during software evolution; and (2) statistically analyzing the impact of inheritance and delegation on fault proneness and maintenance effort. Our results let emerge various usage patterns that describe the way inheritance and delegation vary over time. In addition, we find out that inheritance and delegation are statistically significant factors that influence both source code defect-proneness and maintenance effort."
pub.1134288507,Cross project defect prediction: a comprehensive survey with its SWOT analysis,"Software fault prediction (SFP) refers to the process of identifying (or predicting) faulty modules based on its characteristics/software metrics. SFP can be done either using the same project data in both the training and testing phase i.e. within project defect prediction or using a different one, as done in cross-project defect prediction (CPDP). Previous works show that contemporary research in this field is progressing towards CPDP. To present the current state of progress and the future prospects of CPDP, this article presents a comprehensive survey of CPDP considering the latest work along with its SWOT analysis. This survey is targeted to present the novice researchers, academicians, and practitioners with the alphas and omegas of this contemporary challenging field. We have also carried a qualitative and quantitative evaluation of CPDP w.r.t some of the targeted research questions. A total of 34 significant primary CPDP studies published from 2008 to 2019 were selected. Both qualitative and quantitative data are extracted from each study. The collected data is then consolidated and analyzed to present a comprehensive report showing the current state of the art, along with the answers to the targeted research questions and finally the CPDP SWOT analysis. We observed that there exists a big scope for performance improvement in CPDP. Integration of feature engineering, exploration with different process metrics, hyperparameter tuning, class imbalance handling in CPDP setting are some of the ways identified for bringing enhancement in CPDP performance. Apart from this, we would like to conclude that there is a strong need to investigate Precision over the Recall and model’s validity in terms of effort/cost-effectiveness."
pub.1181536765,Refining software defect prediction through attentive neural models for code understanding,"Identifying defects through manual software testing is a resource-intensive task in software development. To alleviate this, software defect prediction identifies code segments likely to contain faults using data-driven methods. Traditional techniques rely on static code metrics, which often fail to reflect the deeper syntactic and semantic features of the code. This paper introduces a novel framework that utilizes transformer-based networks with attention mechanisms to predict software defects. The framework encodes input vectors to develop meaningful representations of software modules. A bidirectional transformer encoder is employed to model programming languages, followed by fine-tuning with labeled data to detect defects. The performance of the framework is assessed through experiments across various software projects and compared against baseline techniques. Additionally, statistical hypothesis testing and an ablation study are performed to assess the impact of different parameter choices. The empirical findings indicate that the proposed approach can increase classification accuracy by an average of 15.93% and improve the F1 score by up to 44.26% compared to traditional methods."
pub.1093510127,Dynamic Coupling Measures for Object-Oriented Software,"The relationships between coupling and external quality factors of object-oriented software have been studied extensively for the past few years. For example, several studies have identified clear empirical relationships between class-level coupling and the fault-proneness of the classes. A common way to quantify the coupling is through static code analysis. However, the resulting static coupling measures only capture certain underlying dimensions of coupling. Other dependencies regarding the dynamic behavior of software can only be inferred from run-time information. For example, due to inheritance and polymorphism, it is not always possible to determine the actual receiver and sender classes (i.e., the objects) from static code analysis. This paper describes how several dimensions of dynamic coupling can be calculated by tracing the flow of messages between objects at run-time. As a first evaluation of the proposed dynamic coupling measures, fairly accurate prediction models of the change proneness of classes have been developed using change data from nine maintenance releases of a large SmallTalk system. Preliminary results suggest that dynamic coupling may also be useful for developing prediction models and tools supporting change impact analysis. At present, work on developing a dynamic coupling tracer and ripple-effect prediction models for Java programs is underway."
pub.1107321248,Software Fault Prediction in Object Oriented Software Systems Using Ensemble Classifiers,"The main aim of software projects is developing software programs to meet functional and non-functional requirements within the project budget and at a particular time. The greatest challenge in reaching this goal is the software errors that were found in the software projects. The most basic technique that is used to solve software errors is testing the software programs according to the methods in the literature. These methods are the software tests that are basically conducted by software developers, although they have different methods of verification and validation according to their size, experience, techniques or tools they use. When software is tested, it is very significant that software errors are found in the early phases. Software error estimation is a proven method of effectiveness and validity that increases the quality of software and reduces the cost of software development. In this study, by using machine learning algorithms and software metrics; software error estimation has been carried out with a developed software"
pub.1095576326,Locating Source Code to be Fixed based on Initial Bug Reports -A Case Study on the Eclipse Project-,"In most software development, a Bug Tracking System is used to improve software quality. Based on bug reports managed by the bug tracking system, triagers who assign a bug to fixers and fixers need to pinpoint buggy files that should be fixed. However if triagers do not know the details of the buggy file, it is difficult to select an appropriate fixer. If fixers can identify the buggy files, they can fix the bug in a short time. In this paper, we propose a method to quickly locate the buggy file in a source code repository using 3 approaches, text mining, code mining, and change history mining to rank files that may be causing bugs. (1) The text mining approach ranks files based on the textual similarity between a bug report and source code. (2) The code mining approach ranks files based on prediction of the fault-prone module using source code product metrics. (3) The change history mining approach ranks files based on prediction of the fault-prone module using change process metrics. Using Eclipse platform project data, our proposed model gains around 20% in TOP1 prediction. This result means that the buggy files are ranked first in 20 % of bug reports. Furthermore, bug reports that consist of a short description and many specific words easily identify and locate the buggy file."
pub.1132552182,Design and Development of Machine Learning Technique for Software Project Risk Assessment - A Review,"Accurate assessment of software project risk is amongst the key activities in a software project. It directly impacts the time and cost of software projects. This paper presents a literature review of designing & developing machine learning techniques for software project risk assessment. The results of the review have concluded prominent trends of machine learning approaches, size metrics, and study findings in the growth and advancement of machine learning in project management. Besides that, this research provides a deeper insight and an important framework for future work in the software project risk assessment. Furthermore, we demonstrated that the assessment of project risk using machine-learning is more efficient in reducing a project's fault. It also increases the probability for the software project's prediction and response, provides a further way to reduce the probability chances of failure effectively and to increase the software development performance ratio."
pub.1156538263,Predicted of Software Fault Based on Random Forest and K-Nearest Neighbor,"Software systems have gotten increasingly complicated and adaptable in today's computer world. As a result, it's critical to track down and fix software design flaws on a regular basis. Software fault prediction in early phase is useful for enhancing software quality and for reducing software testing time and expense; it's a technique for predicting problems using historical data. To anticipate software flaws from historical databases, several machine learning approaches are applied. This paper focuses on creating a predictor to predict software defects, Based on previous data. For this purpose, a supervised machine learning techniques was utilized to forecast future software failures, K-Nearest Neighbor (KNN) and Random Forest (RF) applied technique applied to the defective data set belonging to the NASA's PROMISE repository. Also, a set of performance measures such as accuracy, precision, recall and f1 measure were used to evaluate the performance of the models. This paper showed a good performance of the RF model compared to the KNN model resulting in a maximum and minimum accuracy are 99%,88% on the MC1 and KC1 responsibly. In general, the study's findings suggest that software defect metrics may be used to determine the problematic module, and that the RF model can be used to anticipate software errors."
pub.1153377281,A Study on Predicting Software Defects with Machine Learning Algorithms,"Software Defect Prediction (SDP), even in its early stages, is a crucial and significant activity. SDP has recently received a lot of attention as a quality assurance method. Massive amounts of reports and defect data may be generated by the component services. Although much emphasis has been placed on developing defect prediction models using machine learning (ML), some work has been done to determine how effective source code is. ML is a supervised algorithm that is used to produce better results. To appreciate defect prediction in SOS better, this paper suggests a fault diagnosis framework based on the web access to care.ML tools such as Random Forest (RF), Decision Tree (DT), and Support Vector Machine (SVM) are used to evaluate the model’s utility, and certain metrics are also constructed using feature extraction techniques. Finally, the performances of the ML algorithms are compared and the better one is analyzed."
pub.1146291385,Software Belief Reliability Growth Model Based on Uncertain Differential Equation,"Software reliability plays an important role in modern society. To evaluate software reliability, software reliability growth models (SRGMs) investigate the number of software faults in the testing phase. Obviously, testing progresses are inevitably influenced by dynamic indeterministic fluctuations such as the testing effort expenditure, testing efficiency and skill, testing method, and strategy. To model these dynamic fluctuations, several probability theory-based SRGMs are proposed. However, probability theory is suitable for dealing with aleatory uncertainty, but fails to deal with epistemic uncertainty widely existing in software faults. Therefore, this article considers software reliability from a new perspective under the framework of uncertainty theory, which is a new mathematical system different from probability theory, and proposes a software belief reliability growth model (SBRGM) based on uncertain differential equations for the first time. Based on this SBRGM, properties of essential software reliability metrics are investigated under belief reliability theory, which is a brand-new reliability theory. Parameter estimations for unknown parameters in SBRGM are presented. Furthermore, some numerical examples and real data analyses illustrate our methodology in detail, and show that it performs better than several famous probability-based SRGMs in terms of fitting ability and prediction ability. Finally, an optimal software release policy is discussed."
pub.1062978801,WRAPPER-BASED FEATURE RANKING TECHNIQUES FOR DETERMINING RELEVANCE OF SOFTWARE ENGINEERING METRICS,"Classification, an important data mining function that assigns class label to items in a collection, is of practical applications in various domains. In software engineering, for instance, a common classification problem is to determine the quality of a software item. In such a problem, software metrics represent the independent features while the fault proneness represents the class label. With many classification problems, one must often deal with the presence of irrelevant features in the feature space. That, coupled with class imbalance, renders the task of discriminating one class from another rather difficult. In this study, we empirically evaluate our proposed wrapper-based feature ranking where nine performance metrics aided by a particular learner and a methodology are considered. We examine five learners and take three different approaches, each in conjunction with one of three different methodologies: 3-fold Cross-Validation, 3-fold Cross-Validation Risk Impact, and a combination of the two. In this study, we consider two sets of software engineering datasets. To evaluate the classifier performance after feature selection has been applied, we use Area Under Receiver Operating Characteristic curve as the performance evaluator. We investigate the performance of feature selection as we vary the three factors that form the foundation of the wrapper-based feature ranking. We show that the performance is conditioned by not only the choice of methodology but also the learner. We also evaluate the effect of sampling on wrapper-based feature ranking. Finally, we provide guidance as to which software metrics are relevant in software defect prediction problems and how the number of software metrics can be selected when using wrapper-based feature ranking."
pub.1106939104,Software Reliability Growth Modeling: Comparison between Non-Linear- Regression Estimation and Maximum-Likelihood-Estimator Procedures,"Automotive software complexity has been growing rapidly with time. The demand for automation in automotive segment including autonomous automobiles and software based products has caught the attention of researchers. Hence, it is necessary to check the complexity of automotive software and their reliability growth. Testing in the field of software artifact is resource intensive exercise. If project managers are able to put forward testing activities well then the testing resource consumptions may be much more resource/cost efficient. Reliability can be estimated during testing phase of software using software reliability growth models (SRGMs). A software package Computer Aided Software Reliability Estimation (CASRE) has many important SRGMs. These SRGMs are based on Non-Homogeneous Poisson Process (NHPP), Markov process or Bayesian models. Computer Aided Software Reliability Estimation-CASRE is an open source software that has been used to compare the reliability estimates using different models for a automotive software failure dataset along-with, comparison of different methods to parameter estimation (MLE and NLR). Reliability estimation can also be performed after testing phase to predict latent faults and also assess maturity of automotive software. For parameter estimation of SRGMs, two techniques are widely used, namely maximum likelihood and method of least squares. The two techniques under comparative estimation include Maximum Likelihood Estimator (MLE) and Non-Linear Regression (NLR) estimators. Assessment of prediction accuracy using relative error metric, i.e. Balanced Prediction Relative Error (BPRE), is reported lower than 5%. Further in the paper we compare these two estimation procedures for their usability and applicability in correlation with SRGMs. The data used for this study is time-domain failure. In the data, software faults have been reported with their time-between-failures (TBF). Results obtained highlight the fact that NLR is a reasonable estimator for fitting the data to observed failure data, while MLE is a better estimator for making reliable predictions."
pub.1004777520,Predicting Software Fault Proneness Model Using Neural Network,"Importance of quality software is increasing leading to development of sophisticated techniques for exploring data sets, which can be used in constructing models for predicting quality attributes. There have been few empirical studies evaluating the impact of object-oriented metrics on software quality and constructing models that utilize them in predicting quality attributes of the system. Most of these predicted models are built using statistical techniques. Most of these prediction models are built using statistical techniques. ANN have seen an explosion of interest over the years, and are being successfully applied across a range of problem domains, in areas as diverse as finance, medicine, engineering, geology and physics. Indeed, anywhere that there are problems of prediction, classification or control, neural networks are being introduced. ANN can be used as a predictive model because it is very sophisticated modeling techniques capable of modeling complex functions."
pub.1143773171,Impact Analysis of Intelligent Agents in Automatic Fault-Prone Components Prediction and Testing,"Software quality is imperative for industrial strength software. This quality will be often determined by a few components present in the software which decides the entire functionality. If any of these components are not rigorously tested, the quality will be highly affected. Without knowing which of these components are really critical, it will not be possible to perform high level testing. Hence, to predict such fault-prone or critical components from the software prior to testing and prioritizing them during the testing process, an agent-based approach is proposed in this chapter. The framework developed as part of this work will certainly reduce the field failures and thus will improve the software quality. Further, this approach has also utilized important metrics to predict such components and also prioritized the components based on their critical value. Also, the work proposed in this research has also been compared with some of the existing approaches and the results reveal that, this work is a novel one and can both predict and test the components from the software."
pub.1062960193,AUTOMATICALLY EXPLORING HYPOTHESES ABOUT FAULT PREDICTION: A COMPARATIVE STUDY OF INDUCTIVE LOGIC PROGRAMMING METHODS,"We evaluate a class of learning algorithms known as inductive logic programming (ILP) methods on the task of predicting fault density in C++ classes. Using these methods, a large space of possible hypotheses is searched in an automated fashion; further, the hypotheses are based directly on an abstract logical representation of the software, eliminating the need to manually propose numerical metrics that predict fault density. We compare two ILP systems, FOIL and FLIPPER, and conclude that FLIPPER generally outperforms FOIL on this problem. We analyze the reasons for the differing performance of these two systems, and based on the analysis, propose two extensions to FLIPPER: a user-directed bias towards easy-to-evaluate clauses, and an extension that allows FLIPPER to learn ""counting clauses"". Counting clauses augment logic programs with a variation of the ""number restrictions"" used in description logics, and significantly improve performance on this problem when prior knowledge is used. We also evaluate the use of ILP techniques for automatic generation of Boolean indicators and numeric metrics from the calling tree representation."
pub.1174199932,Hybrid Classifier for Software Defect Prediction by Using Filter-Based Feature Selection Techniques,"Software’s capacity for error-free operation determines how reliable it is. Unfortunately, mistakes can happen at any stage of the software development process. Predicting software flaws early on in the development process is now of utmost importance in the field of software engineering. Using classification techniques, which are a popular strategy for predicting software faults, modules that are illustrated by a group of metrics or code properties are divided into defective or non-defective categories. However, there are low-quality, unreliable, redundant, and noisy data sources that have an adverse impact on the process of observing information and helpful patterns. Researchers must therefore use feature selection techniques to extract pertinent info from massive databases. In feature selection, the redundant and unnecessary features are eliminated in order to focus on the most significant ones. In this paper, we looked in to the impact of filter-based feature selection on classification techniques in software defect prediction. NASA and the Metric Data Program software repository both include publicly available datasets that were used in this study. Principal component analysis (PCA) and CFS was used to assess the dataset’s top discriminator features. The datasets were classified by using hybrid ensemble learning, for hybrid ensemble learning classifiers like DT, SVM, K-NN, NB, and LR were used. The experimental findings showed that it is preferable and should be encouraged to apply feature selection to datasets prior to classification in order to anticipate software defects."
pub.1114802942,整数計画法を用いた重点レビュー対象モジュールの選択,"There has been considerable research on Fault-Prone (FP) module prediction using software metrics, and their findings would be useful in the plan for reviewing and testing the modules. Toward a practical application of the FP module prediction methods, this paper focuses on the optimal selection of modules to be preferentially reviewed from a cost-effectiveness standpoint, since practitioners face some real constraints on the development time and cost. The paper considers a fault-proneness of a module to be the worth reviewing the module, and proposes to formulate the optimal selection of modules to be reviewed, as a 0-1 integer programming problem, i.e., knapsack problem. The empirical work using 500 sample modules from NASA IV & V shows the proposed method would be better than conventional one on the cost-effectiveness."
pub.1007935908,A prediction system for evolutionary testability applied to dynamic execution time analysis,"Evolutionary testing (ET) is a test case generation technique based on the application of an evolutionary algorithm. It can be applied to timing analysis of real-time systems. In this instance, timing analysis is equivalent to testing. The test objective is to uncover temporal errors. This corresponds to the violation of the system's timing specification. Testability is the ability of the test technique to uncover faults. Evolutionary testability is the ability of an evolutionary algorithm to successfully generate test cases with the goal to uncover faults, in this instance violation of the timing specification. This process attempts to find the best- and worst-case execution time of a real-time system.Some attributes of real-time systems were found to greatly inhibit the successful generation of the best- and worst-case execution times through ET. These are small path domains, high data dependence, large input vectors and nesting. This paper defines software metrics, which aim to express the effects of these attributes on ET. ET is applied to generate the best- and worst-case execution paths of test programs. Their extreme timing paths are determined analytically and the average success of ET to cover these paths is assessed. This empirical data is mapped against the software metrics to derive a prediction system for evolutionary testability.The measurement and prediction system developed from the experiments is able to forecast evolutionary testability with almost 90% accuracy. The prediction system will be used to assess whether the application of ET to a real-time system will be sufficient to successful dynamic timing analysis, or whether additional testing strategies are needed."
pub.1148183626,A novel multi‐view ordinal classification approach for software bug prediction,"Abstract  Software bug prediction aims to enhance software quality and testing efficiency by constructing predictive classification models using code properties. This enables the prompt detection of fault‐prone modules. There are several machine learning‐based software bug prediction studies, which mainly focus on single view data by disregarding the natural ordering relation among the class labels in the literature. Thus, these studies cause losing each view's own intrinsic structure and the inherent order of the labels that positively affect the prediction performance. To overcome this drawback, this study focuses on integrating ordering information and a multi‐view learning strategy. This paper proposes a novel approach multi‐view ordinal classification (MVOC), which learns from different views (complexity, coupling, cohesion, inheritance and scale) of the software dataset separately and predicts software bugs taking the inherent order of class labels (non‐buggy, less buggy and more buggy) into consideration. To demonstrate its prediction performance, the MVOC approach was executed on the 40 different real‐world software datasets using six different classification algorithms as base learners. In the experiments, the MVOC approach was compared with traditional classifiers and their multi‐view implementations in terms of precision, recall, f ‐measure and accuracy rate metrics. The results indicate that the MVOC approach presents better prediction performance on average than the multi‐view‐based and traditional classifiers. It is also observed from the results that the MVOC.RF model achieved the highest classification performance with an average accuracy rate of 85.65%. "
pub.1140917193,Class Imbalance Issue in Software Defect Prediction Models by various Machine Learning Techniques: An Empirical Study,"Software practitioners are continuing to build advanced software defect prediction (SDP) models to help the tester find fault-prone modules. However, the Class Imbalance (CI) problem consists of uncommonly few defective instances, and more non-defective instances cause inconsistency in the performance. We have conducted 880 experiments to analyze the variation in the performance of 10 SDP models by concerning the class imbalance problem. In our experiments, we have used 22 public datasets consists of 41 software metrics, 10 baseline SDP methods, and 4 sampling techniques. We used Mathews Correlation Coefficient (MCC), which is more useful when a dataset is highly imbalanced. We have also compared the predictive performance of various ML models by applying 4 sampling techniques. To examine the performance of different SDP models, we have used the F-measure. We found the performance of the learning models is unsatisfactory, which needs to mitigate. We have also found a few surprising results, some logical patterns between classifier and sampling technique. It provides a connection between sampling technique, software matrices, and a classifier."
pub.1029996552,A systematic and comprehensive investigation of methods to build and evaluate fault prediction models,"This paper describes a study performed in an industrial setting that attempts to build predictive models to identify parts of a Java system with a high fault probability. The system under consideration is constantly evolving as several releases a year are shipped to customers. Developers usually have limited resources for their testing and would like to devote extra resources to faulty system parts. The main research focus of this paper is to systematically assess three aspects on how to build and evaluate fault-proneness models in the context of this large Java legacy system development project: (1) compare many data mining and machine learning techniques to build fault-proneness models, (2) assess the impact of using different metric sets such as source code structural measures and change/fault history (process measures), and (3) compare several alternative ways of assessing the performance of the models, in terms of (i) confusion matrix criteria such as accuracy and precision/recall, (ii) ranking ability, using the receiver operating characteristic area (ROC), and (iii) our proposed cost-effectiveness measure (CE).The results of the study indicate that the choice of fault-proneness modeling technique has limited impact on the resulting classification accuracy or cost-effectiveness. There is however large differences between the individual metric sets in terms of cost-effectiveness, and although the process measures are among the most expensive ones to collect, including them as candidate measures significantly improves the prediction models compared with models that only include structural measures and/or their deltas between releases – both in terms of ROC area and in terms of CE. Further, we observe that what is considered the best model is highly dependent on the criteria that are used to evaluate and compare the models. And the regular confusion matrix criteria, although popular, are not clearly related to the problem at hand, namely the cost-effectiveness of using fault-proneness prediction models to focus verification efforts to deliver software with less faults at less cost."
pub.1121972590,An Empirical Framework for Code Smell Prediction using Extreme Learning Machine*,"The software containing code smells indicates the violation of standard design and coding practices by developer during the development of the software system. Recent empirical studies observed that classes having code smells have higher probability of change proneness or fault proneness with respect to classes having no code smells [1]. The effort of removing bugs due to code smells increases exponentially if the smells are not identified during the earlier phases of software development. The code smell prediction using source code metrics can be used in starting phases of software development life cycle to reduce the maintenance and testing effort of software and also help in improving the quality of the software. The work in this paper empirically investigates and evaluates different classification techniques, feature selection techniques, and data sampling techniques to handle imbalance data in predicting 7 different types of code smell. The conclusion of this research is assessed over 629 application packages. The experimental finding confirms the estimating capability of different classifiers, feature selection, and data imbalance techniques for developing code smell prediction models. Our analysis also reveals that the models developed using one technique are superior than the models developed using other techniques."
pub.1093960658,Return on investment of software quality predictions,"Software quality classification models can be used to target reliability enhancement efforts toward high risk modules. We summarize a generalized classification rule which we have proposed. Cost aspects of a software quality classification model are discussed. The contribution of this paper is a demonstration of how to assess the return on investment of model accuracy, in the context of a software quality classification model. An industrial case study of a very large telecommunications system illustrates the method. The dependent variable of the model was the probability that a module will have faults discovered by customers. The independent variables were software product and process metrics. The model is compared to random selection of modules for reliability enhancement. Calculation of return on investment can guide selection of the generalized classification rule's parameter so that the model is well-suited to the project."
pub.1092384433,Automatic calculation of process metrics and their bug prediction capabilities,"Identifying fault-prone code parts is useful for the developers to help reduce the time required for locating bugs. It is usually done by characterizing the already known bugs with certain kinds of metrics and building a predictive model from the data. For the characterization of bugs, software product and process metrics are the most popular ones. The calculation of product metrics is supported by many free and commercial software products. However, tools that are capable of computing process metrics are quite rare. In this study, we present a method of computing software process metrics in a graph database. We describe the schema of the database created and we present a way to readily get the process metrics from it. With this technique, process metrics can be calculated at the file, class and method levels. We used GitHub as the source of the change history and we selected 5 open-source Java projects for processing. To retrieve positional information about the classes and methods, we used SourceMeter, a static source code analyzer tool. We used Neo4j as the graph database engine, and its query language - cypher - to get the process metrics. We published the tools we created as open-source projects on GitHub. To demonstrate the utility of our tools, we selected 25 release versions of the 5 Java projects and calculated the process metrics for all of the source code elements (files, classes and methods) in these versions. Using our previous published bug database, we built bug databases for the selected projects that contain the computed process metrics and the corresponding bug numbers for files and classes. (We published these databases as an online appendix.) Then we applied 13 machine learning algorithms on the database we created to find out if it is feasible for bug prediction purposes. We achieved F-measure values on average of around 0.7 at the class level, and slightly better values of between 0.7 and 0.75 at the file level. The best performing algorithm was the RandomForest method for both cases."
pub.1121079987,Software Matrices Selection for a SDLC Based Software Reliability Prediction Model,"Software reliability is one of the essential factors of quality in software engineering like other quality attributes as functionality, usability, maintainability, performance, serviceability, documentation etc. From last few years, several software reliability models have been developed. There is lack of relevant literature which focuses on processes related to SDLC. A SDLC based structure for measurement of reliability has been proposed. Identified software reliability measures which are majorly take place in all levels of early software development phase of SDLC. Considering all measures for reliability estimation will be costly and time taking. So measures are identified which are taking place at each development phase and have high synthetic weight according to selecting criteria based on expert judgment and multi criteria decision making technique. Based on the grading, top ranked measures like completeness, error distribution, fault density etc are identified. Use of recommended metrics will make software reliability estimation more effective and reliable"
pub.1141076749,Evaluating the impact of feature selection consistency in software prediction,"Many empirical software engineering studies have employed feature selection algorithms to exclude the irrelevant and redundant features from the datasets with the aim to improve prediction accuracy achieved with machine learning-based estimation models as well as their generalizability. However, little has been done to investigate how consistently these feature selection algorithms produce features/metrics across different training samples, which is an important point for the interpretation of the trained models. The interpretation of the models largely depends on the features of the analyzed datasets, so it is recommended to evaluate the potential of various feature selection algorithms in terms of how consistently they extract features from the employed datasets. In this study, we consider eight different feature selection algorithms to evaluate how consistently they select features across different folds of k-fold cross-validation as well as when small changes are made in the training data. To provide a stable and generalized conclusion, we investigate data from two different domains, i.e., six datasets from the domain of Software Development Effort Estimation (SDEE) and six datasets from the Software Fault Prediction (SFP) domain. Our results reveal that a feature selection algorithm could produce 20-100% inconsistent features with an SDEE dataset and 18.8-95.3% inconsistent features in the case of an SFP dataset. The analysis also reveals that it is not necessarily true that the most consistent feature selection algorithm results to be the most accurate one (i.e., leads to better prediction accuracy) in the case of SDEE datasets, while with SFP datasets, the analysis highlights that the most consistent feature selection algorithm also results to be the most accurate in predicting faults."
pub.1175925472,SpecNLP: A Pre-trained Model Enhanced with Spectrum Profile for Bug Localization,"Spectrum-based fault localization approaches utilize the statistical information about the execution of test cases to rank statements denoting the most specious ones leading to the failure of test cases. We propose a new approach for software fault localization called SpecNLP, which combines natural language processing (NLP) techniques with spectrum-based fault localization (SBFL). SpecNLP uses a pre-trained NLP model called CodeBERT to extract semantic features. These features together with spectrum information from test executions are fed into a multi-layer perceptron (MLP) to predict the start and end locations of bugs. The key innovation is the integration of SBFL execution test cases with CodeBERT code embeddings, enabling more accurate bug localization. SpecNLP outperforms previous ML and NLP methods on the Codeflaws benchmark. On the key Top-N metric, SpecNLP achieves 31.9% accuracy on Top-1 predictions versus 5.4% for SBFL techniques. The results demonstrate that SpecNLP outperforms previous methods on a benchmark and achieves higher accuracy in predicting fault locations."
pub.1094941562,Controlling Overfitting in Software Quality Models: Experiments with Regression Trees and Classification,"In this day of “faster, cheaper, better” release cycles, software developers must focus enhancement efforts on those modules that need improvement the most. Predictions of which modules are likely to have faults during operations is an important tool to guide such improvement efforts durinG maintenance. Tree-based models are attractive because they readily model nonmonotonic relationships between a response variable and predictors. However, tree-based models are vulnerable to overfitting, where the model reflects the structure of the training data set too closely. Even though a model appears to be accurate on training data, if ouerfitted, it may be much less accurate when applied to a current data set. To account for the severe consequences of misclassifying fault-prone modules, our measure of overfitting is based on expected costs of mis-classification, rather than the total number of misclas-sifications. In this paper, We apply a regression-tree algorithm in the S-Plus system to classification of software modules by application of our classification rule that accounts for the preferred balance between misclassification rates. We conducted a case study of a very large legacy telecommunications system, and investigated two parameters of the regression-tree algorithm. We found here that minimum deviance was strongly related to overfitting, and can be used to control it, but the effect of minimum node size on overfitting is ambiguous."
pub.1165889015,A methodology for model clone detection using statistics of design metrics,"Model clone detection has predominantly gained momentum in the field of software development process and model driven engineering. Reuse and mutations of the existing models will increase the complexity of managing the software’s organisation’s internal repositories. Detecting semantic and structural similarities among the models finds various uses like fault prediction, estimation of maintenance and refactoring. Literature in the domain witnesses very few works focussing on model clone detection. This work proposes a model clone detection technique by leveraging the statistical and lexical properties of the UML diagrams. The primary contribution of the work is the construction of Similarity Measure (SM) by analysing the design metrics from different perspectives namelyi)measuring the statistical variability between the models and ii) estimating the lexical similarity among design metrics. The results of the model indicates that the proposed method was able to detect the semantically similar model clones of the banking use case. Also, the method is very robust and computationally inexpensive, so that it could find its applicability in all fields where model driven engineering is used."
pub.1107307598,Using code quality features to predict bugs in procedural software systems,"A wide range of metrics have been used as features to build bug (or fault) predictors. However, most of the existing predictors focus mostly on object-oriented (OO) systems, either because they rely on OO metrics or were evaluated mainly with OO systems. Procedural software systems (PSS), less addressed in bug prediction research, often suffer from maintainability problems because they typically consist of low-level applications, using for example preprocessors to cope with variability. Previous work evaluated sets of features (composed of static code metrics) proposed in existing approaches in the PSS context. However, explored metrics are limited to those that are part of traditional metric suites, being often associated with structural code properties. A type of information explored to a smaller extent in this context is the output of code quality tools that statically analyse source code, providing hints of code problems. In this paper, we investigate the use of information collected from quality tools to build bug predictors dedicated to PSS. We specify four features derived from code quality tools or associated with poor programming practices and evaluate the effectiveness of these features. Our evaluation shows that our proposed features improve bug predictors in our investigated context."
pub.1158090278,Software Complexity Prediction Model: A Combined Machine Learning Approach,"The need for computers increased quickly. As a result, the program is utilized in a significant and intricate manner. More complex systems are being developed by software businesses. Additionally, customers expect great quality, but the market requires them to finish their assignment faster. Different measuring methods are employed by software firms. Some of these include customer feedback after it has been given to customers, software testing, and stakeholder input. The objective of this project is to use a combination of machine learning techniques to predict software bug states using the NASA MDP dataset. The research process considered data preprocessing methods and applied singular and combination machine learning algorithms. To create the model, the single classifiers were combined using the voting method. Accuracy, precision, and recall were used to evaluate the model's effectiveness, along with tenfold cross-validation. The promising result was recorded by a combination of J48 and SMO classifiers. Before attempting to test the software product, the researcher retrieved attribute data from the source code; the complexity of the software product will then be ascertained using the constructed model. The main contribution of this study is to improve software quality by incorporating a machine learning framework into the present software development life cycle between implementation and testing."
pub.1110965363,Software reusability metrics prediction by using evolutionary algorithms: The interactive mobile learning application RozGaar,"Considering object oriented program based software metrics (cohesion, coupling and complexity) and their significance to characterize software quality, particularly software component reusability, we have considered six important CK matrices. The predominant reason behind using the measurement technique is the individual relationship with the design aspect and fault-proneness or aging-proneness. The key objective of this paper is to generate employment opening to thousands of people who have different skillsets and furthermore to provide hassle-free services by RozGaar service providers to customers with the help of machine learning techniques. In the current century’s rapid growth of modernization and automation, manual labor is reduced which gives rise to unemployment at mass. If we need technicians, workers, plumbers or drivers who work on daily wages, it is quite difficult to find one in our locality without having any contact references and knowing the quality of the work they provide. This paper helps in filling the gap between the various customers and the service providers. We aim to introduce this paper as an ocean of opportunities for all where people can get jobs on a daily basis and can earn money for their skills. The used application is a dual-platform application that runs on Android devices and on Internet as a website, promising you to provide unmatched services of daily work. To achieve the goal, we used the novel software prediction model, evolutionary algorithms such as decision tree, Rough Set, and Logistic Regression algorithms, to predict software reusability."
pub.1149171979,A cognitive and neural network approach for software defect prediction,"Software defect prediction is used to assist developers in finding potential defects and allocating their testing efforts as the scale of software grows. Traditional software defect prediction methods primarily concentrate on creating static code metrics that are fed into machine learning classifiers to predict defects in the code. To achieve the desired classifier performance, appropriate design decisions are required for deep neural network (DNN) and convolutional neural network (CNN) models. This is especially important when predicting software module fault proneness. When correctly identified, this could help to reduce testing costs by concentrating efforts on the modules that have been identified as fault prone. This paper proposes a CONVSDP and DNNSDP (cognitive and neural network) approach for predicting software defects. Python Programming Language with Keras and TensorFlow was used as the framework. From three NASA system datasets (CM1, KC3, and PC1) selected from PROMISE repository, a comparative analysis with machine learning algorithms (such as Random Forest (RF), Decision Trees (DT), Nave Bayes (NF), and Support Vector Machine (SVM) in terms of F-Measure (known as F1-score), Recall, Precision, Accuracy, Receiver Operating Characteristics (ROC) and Area Under Curve (AUC) has been presented. We extract four dataset attributes from the original datasets and use them to estimate the development effort, development time, and number of errors. The number of operands, operators, branch count, and executable LOCs are among these attributes. Furthermore, a new parameter called cognitive weight (Wc) of Basic Control Structure (BCS) is proposed to make the proposed cognitive technique more effective, and a cognitive data set of 8 features for NASA system datasets (CM1, KC3, and PC1) selected from the PROMISE repository to predict software defects is created. The experimental results showed that the CONVSDP and DNNSDP models was comparable to existing classifiers in both original datasets and cognitive data sets, and that it outperformed them in most of the experiments."
pub.1145093822,A Novel Convolutional Neural Network Model to Predict Software Defects,"Machine learning (ML) is becoming increasingly important as a research tool due to its various frameworks and learning approaches. With the ever‐increasing scale of software, reliability has become a crucial issue and software defect prediction is utilized to assist developers in finding potential defect and allocating their testing efforts. Traditional methods of software defect prediction mainly focus on designing static code metrics which are fed into ML classifiers to predict defects in the code. Even with the same ML techniques, many researchers apply statistical approaches to classify software modules and decide whether each module is defect prone or not and, accordingly, train their model. Deep neural network (DNN) and convolutional neural network (CNN) models built by the appropriate design decisions are crucial to obtain the desired classifier performance. This is especially significant when predicting fault proneness of software modules. When correctly identified, this could help in reducing the testing cost by directing the efforts more toward the modules identified to be fault prone. This paper proposed a N ovel CNN (NCNN) model to predict software defects. The framework used is Python Programming Language with Keras and TensorFlow. A comparative analysis with ML algorithms [such as Random Forest (RF), Decision Trees (DT), and Naïve Bayes (NB)] and DNN model in terms of F‐measure (known as F1‐score), recall, precision, and accuracy has been presented from four NASA system data sets (KC1, PC1, PC2, and KC3) selected from PROMISE repository. The experimental results indicated that NCNN model was comparable to the existing classifiers and outperformed them in most of the experiments."
pub.1061134054,Classification-tree models of software-quality over multiple releases,"This paper presents an empirical study that evaluates software-quality models over several releases, to address the question, ""How long will a model yield useful predictions?"" The classification and regression trees (CART) algorithm is introduced, CART can achieve a preferred balance between the two types of misclassification rates. This is desirable because misclassification of fault-prone modules often has much more severe consequences than misclassification of those that are not fault-prone. The case-study developed 2 classification-tree models based on 4 consecutive releases of a very large legacy telecommunication system. Forty-two software product, process and execution metrics were candidate predictors. Model 1 used measurements of the first release as the training data set; this model had 11 important predictors. Model 2 used measurements of the second release as the training data set; this model had 15 important predictors. Measurements of subsequent releases were evaluation data sets. Analysis of the models' predictors yielded insights into various software development practices. Both models had accuracy that would be useful to developers. One might suppose that software-quality models lose their value very quickly over successive releases due to evolution of the product and the underlying development processes. The authors found the models remained useful over all the releases studied."
pub.1029935438,Toward Non-security Failures as a Predictor of Security Faults and Failures,"In the search for metrics that can predict the presence of vulnerabilities early in the software life cycle, there may be some benefit to choosing metrics from the non-security realm. We analyzed non-security and security failure data reported for the year 2007 of a Cisco software system. We used non-security failure reports as input variables into a classification and regression tree (CART) model to determine the probability that a component will have at least one vulnerability. Using CART, we ranked all of the system components in descending order of their probabilities and found that 57% of the vulnerable components were in the top nine percent of the total component ranking, but with a 48% false positive rate. The results indicate that non-security failures can be used as one of the input variables for security-related prediction models."
pub.1031505738,Enhancing RBF-DDA Algorithm’s Robustness: Neural Networks Applied to Prediction of Fault-Prone Software Modules,"Many researchers and organizations are interested in creating a mechanism capable of automatically predicting software defects. In the last years, machine learning techniques have been used in several researches with this goal. Many recent researches use data originated from NASA (National Aeronautics and Space Administration) IV&V (Independent Verification & Validation) Facility Metrics Data Program (MDP). We have recently applied a constructive neural network (RBF-DDA) for this task, yet MLP neural networks were not investigated using these data. We have observed that these data sets contain inconsistent patterns, that is, patterns with the same input vector belonging to different classes. This paper has two main objectives, (i) to propose a modified version of RBF-DDA, named RBF-eDDA (RBF trained with enhanced Dynamic Decay Adjustment algorithm), which tackles inconsistent patterns, and (ii) to compare RBF-eDDA and MLP neural networks in software defects prediction. The simulations reported in this paper show that RBF-eDDA is able to correctly handle inconsistent patterns and that it obtains results comparable to those of MLP in the NASA data sets."
pub.1150295095,On the Adoption and Effects of Source Code Reuse on Defect Proneness and Maintenance Effort,"Context. Software reusability mechanisms, like inheritance and delegation in
Object-Oriented programming, are widely recognized as key instruments of
software design. These are used to reduce the risks of source code being
affected by defects, other than to reduce the effort required to maintain and
evolve source code. Previous work has traditionally employed source code reuse
metrics for prediction purposes, e.g., in the context of defect prediction.
Objective. However, our research identifies two noticeable limitations of
current literature. First, still little is known on the extent to which
developers actually employ code reuse mechanisms over time. Second, it is still
unclear how these mechanisms may contribute to explain defect-proneness and
maintenance effort during software evolution. We aim at bridging this gap of
knowledge, as an improved understanding of these aspects might provide insights
into the actual support provided by these mechanisms, e.g., by suggesting
whether and how to use them for prediction purposes. Method. We propose an
exploratory study aiming at (1) assessing how developers use inheritance and
delegation during software evolution; and (2) statistically analyze the impact
of inheritance and delegation on fault proneness and maintenance effort. The
study will be conducted on the commits of 17 Java projects of the DEFECTS4J
dataset."
pub.1154788723,Cross-Project Defect Prediction with Metrics Selection and Balancing Approach,"Abstract In software development, defects influence the quality and cost in an undesirable way. Software defect prediction (SDP) is one of the techniques which improves the software quality and testing efficiency by early identification of defects(bug/fault/error). Thus, several experiments have been suggested for defect prediction (DP) techniques. Mainly DP method utilises historical project data for constructing prediction models. SDP performs well within projects until there is an adequate amount of data accessible to train the models. However, if the data are inadequate or limited for the same project, the researchers mainly use Cross-Project Defect Prediction (CPDP). CPDP is a possible alternative option that refers to anticipating defects using prediction models built on historical data from other projects. CPDP is challenging due to its data distribution and domain difference problem. The proposed framework is an effective two-stage approach for CPDP, i.e., model generation and prediction process. In model generation phase, the conglomeration of different pre-processing, including feature selection and class reweights technique, is used to improve the initial data quality. Finally, a fine-tuned efficient bagging and boosting based hybrid ensemble model is developed, which avoids model over -fitting/under-fitting and helps enhance the prediction performance. In the prediction process phase, the generated model predicts the historical data from other projects, which has defects or clean. The framework is evaluated using25 software projects obtained from public repositories. The result analysis shows that the proposed model has achieved a 0.71±0.03 f1-score, which significantly improves the state-of-the-art approaches by 23 % to 60 %."
pub.1020225691,Searching for rules to detect defective modules: A subgroup discovery approach,"Data mining methods in software engineering are becoming increasingly important as they can support several aspects of the software development life-cycle such as quality. In this work, we present a data mining approach to induce rules extracted from static software metrics characterising fault-prone modules. Due to the special characteristics of the defect prediction data (imbalanced, inconsistency, redundancy) not all classification algorithms are capable of dealing with this task conveniently. To deal with these problems, Subgroup Discovery (SD) algorithms can be used to find groups of statistically different data given a property of interest. We propose EDER-SD (Evolutionary Decision Rules for Subgroup Discovery), a SD algorithm based on evolutionary computation that induces rules describing only fault-prone modules. The rules are a well-known model representation that can be easily understood and applied by project managers and quality engineers. Thus, rules can help them to develop software systems that can be justifiably trusted. Contrary to other approaches in SD, our algorithm has the advantage of working with continuous variables as the conditions of the rules are defined using intervals. We describe the rules obtained by applying our algorithm to seven publicly available datasets from the PROMISE repository showing that they are capable of characterising subgroups of fault-prone modules. We also compare our results with three other well known SD algorithms and the EDER-SD algorithm performs well in most cases."
pub.1046190341,Lack of Conceptual Cohesion of Methods,"While often defined in informal ways, class cohesion reflects important properties of modules in a software system. High cohesion for classes is one of the desirable properties in Object Oriented (OO) analysis as it supports program comprehension, testing, reusability, maintainability. Cohesion metrics have been used for quality assessment, fault prediction, software modularization etc. Existing approaches of class cohesion metrics are largely based on the structural information of the source code, such as attribute references in class methods. These cohesion metrics reflect particular interpretations of cohesion. However, only looking at structural aspect of cohesion is not sufficient for completely and accurately specifying class cohesion. So there is a need to pay attention on other aspects of cohesion like conceptual aspect. But only few conceptual metrics have been proposed till now. In our work, we have proposed a new set of cohesion metrics named LCCM (Lack of Conceptual Cohesion of Methods) metrics. These cohesion metrics are conceptual version of widely used LCOM (Lack of Cohesion of methods) metrics. LCOM metrics measure cohesion on structural information extracted entirely from the source code (e.g., attribute references in methods and method calls) that captures the degree to which the elements of a class belong together from a structural point of view. Proposed LCCM metrics use conceptual concerns embedded in source code entities for measuring class cohesion. These metrics are based on the analysis of latent topics embedded in comments and identifiers in source code. Latent Drichlet Allocation (LDA), a topic modeling tool is used for this purpose. These topics are used by proposed LCCM metrics to define similarity between methods of a class and on the basis of this similarity; proposed LCCM metrics define cohesion of the class. For the verification of proposed metrics, a case study on an open source java software system, called Rhino, is performed. The case study indicates that the novel cohesion metrics capture different aspects of class cohesion compared to the exiting cohesion metrics."
pub.1093759601,Reducing Overfitting in Genetic Programming Models for Software Quality Classification,"A high-assurance system is largely dependent on the quality of its underlying software. Software quality models can provide timely estimations of software quality, allowing the detection and correction of faults prior to operations. A software metrics-based quality prediction model may depict overfitting, which occurs when a prediction model has good accuracy on the training data but relatively poor accuracy on the test data. We present an approach to address the overfitting problem in the context of software quality classification models based on genetic programming (GP). The problem has not been addressed in depth for GP-based models. The presence of overfitting in a software quality classification model affects its practical usefulness, because management is interested in good performance of the model when applied to unseen software modules, i.e., generalization performance. In the process of building GP-basedsoftware quality classification models for a high-assurance telecommunications system, we observed that the GP models were prone to overfitting. We utilize a random sampling technique to reduce overfitting in our GP models. The approach has been found by many researchers as an effective method for reducing the time of a GP run. However, in our study we utilize random sampling to reduce overfitting with the aim of improving the generalization capability of our GP models."
pub.1111602033,Efficient Fault Prediction Using Exploratory and Causal Techniques,"Software is basically a series or cluster of operational directions or instructions. The operations or functions performed by the system are regulated by a set of orderly arranged instructions. An error in the code of the developed software is called as software fault. This field attracted many researchers to work in this domain not only due to its advantages but also due to availability of open source dataset and existence of a lot of research publications in the domain. The study performs exploratory and causal relation technique between metrics and bugs. Exploratory Factor analysis is used to identify the important variables of bugs. The identified variables are used to develop a robust model. This study is the extension of our previous experiment in which some variables were analyzed to determine the important predictors. And these distinct predictors were identified and a robust regression model was developed. In this study, we used the same model but development and identification mechanism of variables is different. The results prove the capability of the technique used. The comparison of results presented in the study. On the basis of results obtained researchers are provided with future guidelines in this research work."
pub.1062960194,DATA MINING FOR PREDICTORS OF SOFTWARE QUALITY,"""Knowledge discovery in data bases"" (KDD) for software engineering is a process for finding useful information in the large volumes of data that are a byproduct of software development, such as data bases for configuration management and for problem reporting. This paper presents guidelines for extracting innovative process metrics from these commonly available data bases. This paper also adapts the Classification And Regression Trees algorithm, CART, to the KDD process for software engineering data. To our knowledge, this algorithm has not been used previously for empirical software quality modeling. In particular, we present an innovative way to control the balance between misclassification rates. A KDD case study of a very large legacy telecommunications software system found that variables derived from source code, configuration management transactions, and problem reporting transactions can be useful predictors of software quality. The KDD process discovered that for this software development environment, out of forty software attributes, only a few of the predictor variables were significant. This resulted in a model that predicts whether modules are likely to have faults discovered by customers. Software developers need such predictions early in development to target software enhancement techniques to the modules that need improvement the most."
pub.1137203786,A STUDY ON SOFTWARE DEFECT PREDICTION SYSTEM USING DATA MINING TECHNIQUES,"Defects in software modules are a source of significant concern. Software reliability and software quality assurance ensure the high quality of applications. A software defect triggers software malfunction in an executable product. A number of methods for forecasting machine faults have been suggested, but none have proven to be sufficiently accurate. In the design of software error prediction models, the aim is to use metrics that can be obtained comparatively early in the life cycle of software production to provide fair initial quality estimates of an evolving software framework.Here are various data mining classification and forecasting techniques. Artificial Neural Network (ANN), K-Nearest Neighbor (KNN) have been analyzed and compared for software defect prediction model development. For this paper, the DATATRIEVETM project developed by Digital Engineering, Italy was used to validate the algorithm. The findings revealed that the model was an exceptional statistical model using the NN classification methodology. The main challenges faced in the secure software development process are quality and reliability. There are major software cost violations when a software product with errors in its various components is used on the customer’s side. The software warehouse is commonly used as a record keeping repository, which is often needed when adding new features or fixing bugs. Software errors can lead to erroneous and different results. As a result, software programs run late, are canceled, or become unreliable after use. Different social and technical issues are associated with software failure and software defects are the main reasons for deteriorating product quality. In software engineering, the most active research in software domain is defect prediction.This study discusses the bug-fix time forecast model, pre-release release, post-release error and different measurements to predict failures. Predicted results help developers identify and fix potential vulnerabilities, thereby improving software stability and reliability."
pub.1037663103,Using information retrieval based coupling measures for impact analysis,"Coupling is an important property of software systems, which directly impacts program comprehension. In addition, the strength of coupling measured between modules in software is often used as a predictor of external software quality attributes such as changeability, ripple effects of changes and fault-proneness. This paper presents a new set of coupling measures for Object-Oriented (OO) software systems measuring conceptual coupling of classes. Conceptual coupling is based on measuring the degree to which the identifiers and comments from different classes relate to each other. This type of relationship, called conceptual coupling, is measured through the use of Information Retrieval (IR) techniques. The proposed measures are different from existing coupling measures and they capture new dimensions of coupling, which are not captured by the existing coupling measures. The paper investigates the use of the conceptual coupling measures during change impact analysis. The paper reports the findings of a case study in the source code of the Mozilla web browser, where the conceptual coupling metrics were compared to nine existing structural coupling metrics and proved to be better predictors for classes impacted by changes."
pub.1120301222,Defect Prediction and Dimension Reduction Methods for Achieving Better Software Quality,"In quality of software, a fault discovery course is anticipated; intended to recover the taking up of various methods using cluster classifiers. Initially the classifiers are qualified on software record and then utilized to forecast if a forthcoming transformation originates a defect. Shortcomings of previous classifier based error prediction methods are inadequate presentation for realistic utilization and slow-moving forecast times due to a huge number of learned machine characteristics. Feature selection is a procedure in choosing a subset of pertinent characteristics so that the eminence of forecast replica can be enhanced. So that prediction recital of grouping techniques will be enhanced or sustained, whereas learning instance is considerably abridged. This effort commences by presenting a general idea of the datasets for error prediction, and then features a novel procedure for feature assortment by means of wrapper methods namely Fuzzy Neural Network (FNN) and Kernel Based Support Vector Machine (KSVM). The features chosen from FNN and KSVM are measured as significant characters. This effort examines numerous feature selection wrapper methods that are normally appropriate to grouping based error prediction. The system castoffs not as much of significant characters until optimal grouping recital are attained. The whole number of characters utilized for guidance is considerably reduced, frequently to lower than 15% of the unique. The general performance metrics is make used to estimate grouping systems such as accurateness, Recall, Precision, and F-Measure. It demonstrates that the anticipated Hybrid Hierarchical K-Centers (HHKC) grouping executes enhanced software quality compared to conventional grouping methods."
pub.1061788822,Evolutionary Optimization of Software Quality Modeling with Multiple Repositories,"A novel search-based approach to software quality modeling with multiple software project repositories is presented. Training a software quality model with only one software measurement and defect data set may not effectively encapsulate quality trends of the development organization. The inclusion of additional software projects during the training process can provide a cross-project perspective on software quality modeling and prediction. The genetic-programming-based approach includes three strategies for modeling with multiple software projects: Baseline Classifier, Validation Classifier, and Validation-and-Voting Classifier. The latter is shown to provide better generalization and more robust software quality models. This is based on a case study of software metrics and defect data from seven real-world systems. A second case study considers 17 different (nonevolutionary) machine learners for modeling with multiple software data sets. Both case studies use a similar majority-voting approach for predicting fault-proneness class of program modules. It is shown that the total cost of misclassification of the search-based software quality models is consistently lower than those of the non-search-based models. This study provides clear guidance to practitioners interested in exploiting their organization's software measurement data repositories for improved software quality modeling."
pub.1163421568,An efficient convergence-boosted salp swarm optimizer-based artificial neural network for the development of software fault prediction models,"Machine learning (ML) approaches were employed to tackle the software fault prediction (SFP) issue due to their consistent and rigorous performance. Multilayer perceptron (MLP) neural networks are one of the most effective ML models for prediction problems. Unfortunately, MLP suffers from chronic shortcomings related to the gradient-descent learning mechanism that can easily get stuck in local minima, leading to inappropriate control parameters. For SFP tackling, MLP boosted with an improved version of Salp Swarm Optimizer (SSA), a metaheuristic swarm intelligence technique, is presented in this research. The MLP learning approach is updated with SSA to remedy these flaws. The key benefit of such an algorithm is its ability to avoid local minima through convergence behavior. Two improvements were developed in the SSA optimization loop to link SSA functionality with MLP. The first improvement is elitism (SSA-elitism), while the second is MSSA, which stands for search improvement. The performance of proposed SSA versions is evaluated using 18 benchmark SFP datasets using ROC, sensitivity, specificity, and accuracy performance metrics. Several evaluations and validations were performed by contrasting the results of the developed versions with those of the conventional MLP, SSA, and 10 state-of-the-art approaches. The evaluations and validation findings prove that the proposed versions have superior capabilities to efficiently optimize MLP parameters, which raises the quality of their predictability."
pub.1123590488,Performance Evaluation of Pseudo Code with Weka for Accuracy Calculation,"Programming testing is a fundamental and essential advance of the existence cycle of programming improvement to recognize and defects in programming and afterward fix the deficiencies. The reliability of the data transmission or the quality of proper processing ,maintenance and retrieval of information to a server can be tested for some systems. Accuracy is also one factor that is usually used to the Joint Interoperability Test Command as a criterion for accessing interoperability. This is the main investigation of PC flaw forecast and exactness as per our examination, which spotlights on the utilization of PROMISE database dataset. Some PROMISE database dataset tests are compared between pseudo code (PYTHON) and actual software (WEKA),which in computer fault prediction and accuracy measurement are effective software metrics and machine learning methods."
pub.1127526557,Design Flaws Prediction for Impact on Software Maintainability using Extreme Learning Machine,"The software that contains flaws in its design is an indication that the design and coding standards have been violated by the developer during the software system’s development. It has been observed in recent empirical studies that classes with flaws in the design flaws have a higher probability of change proneness or fault proneness when compared to classes without flaws in the design. There is an exponential increase in terms of the effort required to remove bugs due to design flaws in cases where the flaws are not detected in the early stages of the development of the software. The use of source code metrics for the prediction of design flaws can be implemented in the initial stages of the life cycle of the software development for the reduction of the testing effort and the maintenance of the software as well as the improvement of its quality. This empirical research study examines and assesses a variety of techniques for classification, feature selection, and data sampling in order to deal with the imbalance data for prediction of several categories of design flaws. The assessment of more than 20 application packages is the basis of the conclusions of this study. The results of the experiments indicate that the estimating capability of various classifiers, feature selection, and data imbalance techniques for the development of prediction models for design flaws can be confirmed. In addition, it was also revealed that the models that were developed through the use of one particular technique were found to be superior to the models that were developed with the use of other techniques, according to our analysis."
pub.1140271487,Predicting the Defects using Stacked Ensemble Learner with Filtered Dataset,"Software defect prediction is a crucial software project management activity to enhance the software quality. It aids the development team to forecast about which modules need extra attention for testing; which part of software is more prone to errors and faults; before the commencement of testing phase. It helps to reduce the testing cost and hence the overall development cost of the software. Though, it ensures in-time delivery of good quality end-product, but there is one major hinderance in making this prediction. This is the class imbalance issue in the training data. Data imbalance in class distribution adversely affects the performance of classifiers. This paper proposes a K-nearest neighbour (KNN) filtering-based data pre-processing technique for stacked ensemble classifier to handle class imbalance issue. First, nearest neighbour-based filtering is applied to filter out the overlapped data-points to reduce Imbalanced Ratio, then, the processed data with static code metrics is supplied to stacked ensemble for prediction. The stacking is achieved with five base classifiers namely Artificial Neural Network, Decision Tree, Naïve Bayes, K-nearest neighbour (KNN) and Support Vector Machine. A comparative analysis among 30 classifiers (5 data pre-processing techniques * 6 prediction techniques) is made. In the experiments, five public datasets from NASA repository namely CM1, JM1, KC1, KC2 and PC1 are used. In total 150 prediction models (5 data pre-processing techniques * 6 classification techniques * 5 datasets) are proposed and their performances are assessed in terms of measures namely Receiver Operator Curve, Area under the Curve and accuracy. The statistical analysis shows that proposed stacked ensemble classifier with KNN filtering performs best among all the predictors independent of datasets."
pub.1100954164,Feature Selection Techniques to Counter Class Imbalance Problem for Aging Related Bug Prediction,"Aging-Related Bugs (ARBs) occur in long running systems due to error conditions caused because of accumulation of problems such as memory leakage or unreleased files and locks. Aging-Related Bugs are hard to discover during software testing and also challenging to replicate. Automatic identification and prediction of aging related fault-prone files and classes in an object oriented system can help the software quality assurance team to optimize their testing efforts. In this paper, we present a study on the application of static source code metrics and machine learning techniques to predict aging related bugs. We conduct a series of experiments on publicly available dataset from two large open-source software systems: Linux and MySQL. Class imbalance and high dimensionality are the two main technical challenges in building effective predictors for aging related bugs. We investigate the application of five different feature selection techniques (OneR, Information Gain, Gain Ratio, RELEIF and Symmetric Uncertainty) for dimensionality reduction and five different strategies (Random Under-sampling, Random Oversampling, SMOTE, SMOTEBoost and RUSBoost) to counter the effect of class imbalance in our proposed machine learning based solution approach. Experimental results reveal that the random under-sampling approach performs best followed by RUSBoost in-terms of the mean AUC metric. Statistical significance test demonstrates that there is a significant difference between the performance of the various feature selection techniques. Experimental results shows that Gain Ratio and RELEIF performs best in comparison to other strategies to address the class imbalance problem. We infer from the statistical significance test that there is no difference between the performances of the five different learning algorithms."
pub.1170374147,FPAFS: Feature Selection Using the Flower Pollination Algorithm for Software Fault Detection System,"This paper suggests a suitable feature selection (FS) approach FSFPA using flower pollination algorithm (FPA). It is based on the concept of flower pollination, to choose a set of important features or variables from a vast set of characteristics present in a dataset. The objective is to choose the best suitable features for defect prediction. In this study FSFPA strategy is compared with other optimization methods such as ant colony optimization (ACO), particle swarm optimization (PSO) and evolution based algorithms differential evolution (DE), and genetic algorithm (GA). The experiment has been conducted using these five optimization strategies on nine datasets. To determine the most effective metrics for identifying error proneness, it uses five classifiers (NB, KNN, DT, LDA, QDA). It is observed that FSFPA was better considering the parameters training times and prediction accuracies as compared to the traditional GA, ACO, DE, and PSO methods. In conclusion, FPA produces better prediction outcomes in imbalanced data sets than the GA, ACO, DE, and PSO. It is necessary to correct the parameters that are responsible for software errors by utilizing optimization algorithms and appropriate classifiers."
pub.1045437073,Online Black-Box Failure Prediction for Mission Critical Distributed Systems,"This paper introduces a novel approach to failure prediction for mission critical distributed systems that has the distinctive features to be black-box, non-intrusive and online. The approach combines Complex Event Processing (CEP) and Hidden Markov Models (HMM) so as to analyze symptoms of failures that might occur in the form of anomalous conditions of performance metrics identified for such purpose. The paper describes an architecture named CASPER, based on CEP and HMM, that relies on sniffed information from the communication network of a mission critical system, only, for predicting anomalies that can lead to software failures. An instance of CASPER has been implemented, trained and tuned to monitor a real Air Traffic Control (ATC) system. An extensive experimental evaluation of CASPER is presented. The obtained results show (i) a very low percentage of false positives over both normal and under stress conditions, and (ii) a sufficiently high failure prediction time that allows the system to apply appropriate recovery procedures."
pub.1095455354,Applying Radiation Hardening by Software to Fast Lossless Compression Prediction on FPGAs,"As scientists endeavor to learn more about the world's ecosystems, engineers are pushed to develop more sophisticated instruments. With these advancements comes an increase in the amount of data generated. For satellite based instruments the additional data requires sufficient bandwidth be available to transmit the data. Alternatively, compression algorithms can be employed to reduce the bandwidth requirements. This work is motivated by the proposed HyspIRI mission, which includes two imaging spectrometers measuring from visible to short wave infrared (VSWIR) and thermal infrared (TIR) that saturate the projected bandwidth allocations. We present a novel investigation into the capability of using FPGAs integrated with embedded PowerPC processors to adequately perform the predictor function of the Fast Lossless (FL) compression algorithm for multispectral and hyperspectral imagery. Furthermore, our design includes a multi-PowerPC implementation which incorporates recently developed Radiation Hardening by Software (RHBSW) techniques to provide software-based fault tolerance to commercial FPGA devices. Our results show low performance overhead (4–8%) while achieving a speedup of 1.97× when utilizing both PowerPCs. Finally, the evaluation of the proposed system includes resource utilization, performance metrics, and an analysis of the vulnerability to Single Event Upsets (SEU) through the use of a hardware based fault injector."
pub.1061784035,Online Prediction and Improvement of Reliability for Service Oriented Systems,"Reliability is an important metric for measuring the quality of software. Many methods have been proposed for online predicting and improving software reliability, but most of them have the following weakness: they are not able to predict software reliability on different time intervals and to locate the faulty components that cause the declining of the reliability either. This paper proposes a new method for online improvement of reliability of service composition. We use monitored failure data at ports of services to predict the reliabilities of service composition on different time intervals. If the predicted reliability is lower than the expected value, then we locate the faulty components that cause the declining of the reliability by using an improved spectrum-fault-localization (SFL) technique. The system can be automatically reconfigured to improve the system reliability by adding a component replica or replacing the faulty component. An Online Shop example is used to demonstrate the effectiveness of our method."
pub.1095122761,Correlation Between the Distribution of Software Bugs and Network Motifs,"With the increase of scale and complexity of software systems as well as the long existing threats of software accidents such as Therac-25 radiation exposure and the Toyota Prius braking system failure, improving the reliability and quality has become the major pressure in developing safety-or security-critical software systems. Since more and more large-scale software systems exhibit the properties of complex network, how can we employ the concepts and metrics of complex networks to the area of software engineering? What structural patterns can be used as indications for software quality and reliability? Though applying the concept of complex network to the field of software engineering has attracted attentions from both the academia and industry, these questions have not been researched thoroughly with satisfactory unanimity. In this study, we analyzed the bug distribution in 1,047 versions of four open source software projects downloaded from GitHub with complex network theory and focused on the correlation between software bugs and a specific type of software network structure-network motifs. Our results indicate that the functions containing bugs are more likely to be involved in feedforward loop motifs, one type of network motifs with highest degree of uniqueness. This paper could serve as a guide to further investigate the nature of software failures and a powerful tool for software fault prediction and quality evaluation."
pub.1172196476,The Effectiveness of Hidden Dependence Metrics in Bug Prediction,"Finding and fixing bugs in programs is perhaps one of the most difficult, yet most important, tasks in software maintenance. This is why in the last decades, a lot of work has been done on this topic, most of which is based on machine learning methods. Studies on bug prediction can be found for almost all programming languages. The solutions presented generally try to predict bugs based on information that can be easily extracted from the source code, rather than more expensive solutions that require a deeper understanding of the program. Another feature of these solutions is that they usually try to predict faults at a high level (module/file/class), which is useful, but locating the bug itself is still a difficult task. This work presents a solution that attempts to predict bugs at the method level, while also tracking the dependencies in the program using an efficient algorithm, resulting in an approach that can predict bugs more accurately. The practical measurements show that the defined approach really outperforms predictions based on traditional metrics in most cases, and with proper filtering, the best-performing RandomForest algorithm according to the F-measure can even achieve an improvement of up to 11%. Finally, it is proven that the introduced metrics are even suitable for predicting bugs that will appear later in a given project if sufficient learning data is available."
pub.1170022771,Benchmarking the Vehicle Integrated Prognostic Reasoner,"This paper outlines a benchmarking approach for evaluating the diagnostic and prognostic capabilities of the Vehicle Integrated Prognostic Reasoner (VIPR), a vehicle-level reasoner and an architecture which aims to detect, diagnose, and predict adverse events during the flight of an aircraft. A number of diagnostic and prognostic metrics exist, but these standards are defined for well-circumscribed algorithms that apply to small subsystems. For layered reasoners, such as VIPR, the overall performance cannot be evaluated by metrics solely directed toward timely detection and accuracy of estimation of the faults in individual components. Among other factors, the overall vehicle reasoner performance is governed by the effectiveness of the communication schemes between the different monitors and reasoners in the architecture, and the ability to propagate and fuse relevant information to make accurate, consistent, and timely predictions at different levels of the reasoner hierarchy. To address these issues, we outline an extended set of diagnostic and prognostics metrics that can be used to evaluate the performance of layered architecture, and we discuss a software architecture*as well as an evaluation plan for benchmarking VIPR."
pub.1062959810,Aggregating Data Sampling with Feature Subset Selection to Address Skewed Software Defect Data,"Defect prediction is an important process activity frequently used for improving the quality and reliability of software products. Defect prediction results provide a list of fault-prone modules which are necessary in helping project managers better utilize valuable project resources. In the software quality modeling process, high dimensionality and class imbalance are the two potential problems that may exist in data repositories. In this study, we investigate three data preprocessing approaches, in which feature selection is combined with data sampling, to overcome these problems in the context of software quality estimation. These three approaches are: Approach 1 — sampling performed prior to feature selection, but retaining the unsampled data instances; Approach 2 — sampling performed prior to feature selection, retaining the sampled data instances; and Approach 3 — sampling performed after feature selection. A comparative investigation is presented for evaluating the three approaches. In the experiments, we employed three sampling methods (random undersampling, random oversampling, and synthetic minority oversampling), each combined with a filter-based feature subset selection technique called correlation-based feature selection. We built the defect prediction models using five common classification algorithms. The case study was based on software metrics and defect data collected from multiple releases of a real-world software system. The results demonstrated that the type of sampling methods used in data preprocessing significantly affected the performance of the combination approaches. It was found that when the random undersampling technique was used, Approach 1 performed better than the other two approaches. However, when the feature selection technique was used in conjunction with an oversampling method (random oversampling or synthetic minority oversampling), we strongly recommended Approach 3."
pub.1023668734,Comparative Assessment of Software Quality Classification Techniques: An Empirical Case Study,"Software metrics-based quality classification models predict a software module as either fault-prone (fp) or not fault-prone (nfp). Timely application of such models can assist in directing quality improvement efforts to modules that are likely to be fp during operations, thereby cost-effectively utilizing the software quality testing and enhancement resources. Since several classification techniques are available, a relative comparative study of some commonly used classification techniques can be useful to practitioners. We present a comprehensive evaluation of the relative performances of seven classification techniques and/or tools. These include logistic regression, case-based reasoning, classification and regression trees (CART), tree-based classification with S-PLUS, and the Sprint-Sliq, C4.5, and Treedisc algorithms. The use of expected cost of misclassification (ECM), is introduced as a singular unified measure to compare the performances of different software quality classification models. A function of the costs of the Type I (a nfp module misclassified as fp) and Type II (a fp module misclassified as nfp) misclassifications, ECM is computed for different cost ratios. Evaluating software quality classification models in the presence of varying cost ratios is important, because the usefulness of a model is dependent on the system-specific costs of misclassifications. Moreover, models should be compared and preferred for cost ratios that fall within the range of interest for the given system and project domain. Software metrics were collected from four successive releases of a large legacy telecommunications system. A two-way ANOVA randomized-complete block design modeling approach is used, in which the system release is treated as a block, while the modeling method is treated as a factor. It is observed that predictive performances of the models is significantly different across the system releases, implying that in the software engineering domain prediction models are influenced by the characteristics of the data and the system being modeled. Multiple-pairwise comparisons are performed to evaluate the relative performances of the seven models for the cost ratios of interest to the case study. In addition, the performance of the seven classification techniques is also compared with a classification based on lines of code. The comparative approach presented in this paper can also be applied to other software systems."
pub.1093673304,A Multi-Factor Software Reliability Model Based on Logistic Regression,"This paper proposes a multi-factor software reliability model based on logistic regression and its effective statistical parameter estimation method. The proposed parameter estimation algorithm is composed of the algorithm used in the logistic regression and the EM (expectation-maximization) algorithm for discrete-time software reliability models. The multi-factor model deals with the metrics observed in testing phase (testing environmental factors), such as test coverage and the number of test workers, to predict the number of residual faults and other reliability measures. In general, the multi-factor model outperforms the traditional software reliability growth model like discrete-time non-homogeneous models in terms of data-fitting and prediction abilities. However, since it has a number of parameters, there is the problem in estimating model parameters. Our modeling framework and its estimation method are quite simpler than the existing methods, and are promising for expanding the applicability of multi-factor software reliability model. In numerical experiments, we examine data-fitting ability of the proposed model by comparing with the existing multi-factor models. The proposed method provides the similar fitting ability to existing multi-factor models, although the computation effort of parameter estimation is low."
pub.1101531373,Using artificial neural network-self-organising map for data clustering of marine engine condition monitoring applications,"Condition monitoring is the process of monitoring parameters expressing machinery condition, interpreting them for the identification of change which could indicate developing faults. Data processing is important in a ship condition monitoring software tool, as misinterpretation of data can significantly affect the accuracy and performance of the predictions made. Data for key performance parameters for a PANAMAX container ship main engine cylinder are clustered using a two-stage approach. Initially, the data is clustered using the artificial neural network (ANN)-self-organising map (SOM) and then the clusters are interclustered using the Euclidean distance metric into groups. The case study results demonstrate the capability of the SOM to monitor the main engine condition by identifying clusters containing data which are diverse compared to data representing normal engine operating conditions. The results obtained can be further expanded for application in diagnostic purposes, identifying faults, their causes and effects to the ship main engine."
pub.1093928789,Use of Relative Code Churn Measures to Predict System Defect Density,"Software systems evolve over time due to changes in requirements, optimization of code, fixes for security and reliability bugs etc. Codechurn, which measures the changes made to a component over a period of time, quantifies the extent of this change. We present a technique for early prediction of system defect density using a set of relative code churn measures that relate the amount of churn to other variables such as component size and the temporal extent of churn. Using statistical regression models, we show that while absolute measures of code churn are poor predictors of defect density, our set of relative measures of code churn is highly predictive of defect density. A case study performed on Windows Server 2003 indicates the validity of the relative code churn measures as early indicators of system defect density. Furthermore, our code churn metric suite is able to discriminate between fault and not fault-prone binaries with an accuracy of 89.0 percent."
pub.1005717752,Use of relative code churn measures to predict system defect density,"Software systems evolve over time due to changes in requirements, optimization of code, fixes for security and reliability bugs etc. Code churn, which measures the changes made to a component over a period of time, quantifies the extent of this change. We present a technique for early prediction of system defect density using a set of relative code churn measures that relate the amount of churn to other variables such as component size and the temporal extent of churn.Using statistical regression models, we show that while absolute measures of code churn are poor predictors of defect density, our set of relative measures of code churn is highly predictive of defect density. A case study performed on Windows Server 2003 indicates the validity of the relative code churn measures as early indicators of system defect density. Furthermore, our code churn metric suite is able to discriminate between fault and not fault-prone binaries with an accuracy of 89.0 percent."
pub.1149024123,An Empirical Study on Bug Severity Estimation using Source Code Metrics and Static Analysis,"In the past couple of decades, significant research efforts have been devoted
to the prediction of software bugs (i.e., defects). In general, these works
leverage a diverse set of metrics, tools, and techniques to predict which
classes, methods, lines, or commits are buggy. However, most existing work in
this domain treats all bugs the same, which is not the case in practice. The
more severe the bugs the higher their consequences. Therefore, it is important
for a defect prediction method to estimate the severity of the identified bugs,
so that the higher severity ones get immediate attention. In this paper, we
provide a quantitative and qualitative study on two popular datasets (Defects4J
and Bugs.jar), using 10 common source code metrics, and two popular static
analysis tools (SpotBugs and Infer) for analyzing their capability to predict
defects and their severity. We studied 3,358 buggy methods with different
severity labels from 19 Java open-source projects. Results show that although
code metrics are useful in predicting buggy code (Lines of the Code,
Maintainable Index, FanOut, and Effort metrics are the best), they cannot
estimate the severity level of the bugs. In addition, we observed that static
analysis tools have weak performance in both predicting bugs (F1 score range of
3.1%-7.1%) and their severity label (F1 score under 2%). We also manually
studied the characteristics of the severe bugs to identify possible reasons
behind the weak performance of code metrics and static analysis tools in
estimating their severity. Also, our categorization shows that Security bugs
have high severity in most cases while Edge/Boundary faults have low severity.
Finally, we discuss the practical implications of the results and propose new
directions for future research."
pub.1174517297,An empirical study on bug severity estimation using source code metrics and static analysis,"In the past couple of decades, significant research efforts have been devoted to the prediction of software bugs (i.e., defects). In general, these works leverage a diverse set of metrics, tools, and techniques to predict which classes, methods, lines, or commits are buggy. However, most existing work in this domain treats all bugs the same, which is not the case in practice. The more severe the bugs the higher their consequences. Therefore, it is important for a defect prediction method to estimate the severity of the identified bugs, so that the higher severity ones get immediate attention. In this paper, we provide a quantitative and qualitative study on two popular datasets (Defects4J and Bugs.jar), using 10 common source code metrics, and two popular static analysis tools (SpotBugs and Infer) for analyzing their capability to predict defects and their severity. We studied 3,358 buggy methods with different severity labels from 19 Java open-source projects. Results show that although code metrics are useful in predicting buggy code (Lines of the Code, Maintainable Index, FanOut, and Effort metrics are the best), they cannot estimate the severity level of the bugs. In addition, we observed that static analysis tools have weak performance in both predicting bugs (F1 score range of 3.1%–7.1%) and their severity label (F1 score under 2%). We also manually studied the characteristics of the severe bugs to identify possible reasons behind the weak performance of code metrics and static analysis tools in estimating their severity. Also, our categorization shows that Security bugs have high severity in most cases while Edge/Boundary faults have low severity. Finally, we discuss the practical implications of the results and propose new directions for future research."
pub.1107573374,Aging Related Bug Prediction using Extreme Learning Machines,"Aging-Related Bugs (ARBs) occur in long running systems due to error conditions caused because of accumulation of problems such as memory leakage or unreleased files and locks. Aging-Related Bugs are hard to discover during software testing and also challenging to replicate. Automatic identification and prediction of aging related fault-prone files and classes in an object oriented system can help the software quality assurance team to optimize their testing efforts. In this paper, we present a study on the application of static source code metrics and machine learning techniques to predict aging related bugs. We conduct a series of experiments on publicly available dataset from two large open-source software systems: Linux and MySQL. Class imbalance and high dimensionality are the two main technical challenges in building effective predictors for aging related bugs. We investigate the application of five different feature selection techniques (OneR, Information Gain, Gain Ratio, RELEIF and Symmetric Uncertainty) for dimensionality reduction and SMOTE method to counter the effect of class imbalance in our proposed machine learning based solution approach. We apply Extreme Learning Machines (ELM) with three different kernels (linear, polynomial and RBF) and present experimental results which demonstarte the effectiveness of our approach."
pub.1150218299,Design of software-oriented technician for vehicle’s fault system prediction using AdaBoost and random forest classifiers,"Detecting and isolating faults on heavy duty vehicles is very important because it helps maintain high vehicle performance, low emissions, fuel economy, high vehicle safety and ensures repair and service efficiency. These factors are important because they help reduce the overall life cycle cost of a vehicle. The aim of this paper is to deliver a Web application model which aids the professional technician or vehicle user with basic automobile knowledge to access the working condition of the vehicles and detect the fault subsystem in the vehicles. The scope of this system is to visualize the data acquired from vehicle, diagnosis the fault component using trained fault model obtained from improvised Machine Learning (ML) classifiers and generate a report. The visualization page is built with plotly python package and prepared with selected parameter from On-board Diagnosis (OBD) tool data. The Histogram data is pre-processed with techniques such as null value Imputation techniques, Standardization and Balancing methods in order to increase the quality of training and it is trained with Classifiers. Finally, Classifier is tested and the Performance Metrics such as Accuracy, Precision, Re-call and F1 measure which are calculated from the Confusion Matrix. The proposed methodology for fault model prediction uses supervised algorithms such as Random Forest (RF), Ensemble Algorithm like AdaBoost Algorithm which offer reasonable Accuracy and Recall. The Python package joblib is used to save the model weights and reduce the computational time. Google Colabs is used as the python environment as it offers versatile features and PyCharm is utilised for the development of Web application. Hence, the Web application, outcome of this proposed work can, not only serve as the perfect companion to minimize the cost of time and money involved in unnecessary checks done for fault system detection but also aids to quickly detect and isolate the faulty system to avoid the propagation of errors that can lead to more dangerous cases."
pub.1094382944,Integrating and Enhancing the Quality of Services in Cloud Computing with Software Testing,"Cloud computing involves to delivering the hosted services throughout the internet. Testing tools are used to test the desktop applications, web applications and the cloud based software systems that are used to address the quality of the cloud infrastructure such as tremendous extensibility and aggressive composition. In the existing paper it is not providing the quality of services in the effective manner. In this paper we focused on integrating the software metrics for getting the quality of services, in terms of speed, memory size, RAM, ROM size and we are also using the D-cloud and prefail testing tools to perform the fault tolerance and recovery testing. By using OVMP algorithm we are minimizing the cost spending for services and load prediction algorithm and it is also used to reduce the load. The aim is to extend the above framework with cross cloud testing scenario involving communications between heterogeneous cloud hosts. The results shows that the cloud environment ensures more flexible and quality of services."
pub.1172854546,Insights Into Test Code Quality Prediction: Managing Machine Learning Techniques,"Test cases represent the first line of defence against the introduction of software faults, especially when testing for regressions. They must be constantly maintained and updated as part of software components to keep them useful. With the help of testing frameworks, developers create test methods and run them periodically on their code. The entire team relies on the results from these tests to decide whether to merge a pull request or deploy the system. Unfortunately, tests are not immune to bugs or technical debts: indeed, they often suffer from issues that can preclude their effectiveness. Typical problems in test cases are called flaky tests and test smells. Over the last decades, the software engineering research community has been proposing a number of static and dynamic approaches to assist developers with the (semi-)automatic detection and removal of these problems. Despite this, most of these approaches rely on expensive dynamic steps and depend on tunable thresholds. These limitations have been partially targeted through machine learning solutions that could predict test quality issues using various features, like source code vocabulary or a mixture of static and dynamic metrics. In this tutorial, I will discuss our experience building prediction models to detect quality issues in test code. The tutorial will discuss the design choices to make in the context of test code quality prediction and the implications these choices have for the reliability of the resulting models."
pub.1062978956,Assessments of Feature Selection Techniques with Respect to Data Sampling for Highly Imbalanced Software Measurement Data,"In the process of software defect prediction, a classification model is first built using software metrics and fault data gathered from a past software development project, then that model is applied to data in a similar project or a new release of the same project to predict new program modules as either fault-prone (fp) or not-fault-prone (nfp). The benefit of such a model is to facilitate the optimal use of limited financial and human resources for software testing and inspection. The predictive power of a classification model constructed from a given data set is affected by many factors. In this paper, we are more interested in two problems that often arise in software measurement data: high dimensionality and unequal example set size of the two types of modules (e.g., many more nfp modules than fp modules found in a data set). These directly result in learning time extension and a decline in predictive performance of classification models. We consider using data sampling followed by feature selection (FS) to deal with these problems. Six data sampling strategies (which are made up of three sampling techniques, each consisting of two post-sampling proportion ratios) and six commonly used feature ranking approaches are employed in this study. We evaluate the FS techniques by means of: (1) a general method, i.e., assessing the classification performance after the training data is modified, and (2) studying the stability of a FS method, specifically with the goal of understanding the effect of data sampling techniques on the stability of FS when using the sampled data. The experiments were performed on nine data sets from a real-world software project. The results demonstrate that the FS techniques that most enhance the models' classification performance do not also show the best stability, and vice versa. In addition, the classification performance is more affected by the sampling techniques themselves rather than by the post-sampling proportions, whereas this is opposite for the stability."
pub.1095105852,Predicting testability of program modules using a neural network,"J.M. Voas (1992) defines testability as the probability that a test case will fail if the program has a fault. It is defined in the context of an oracle for the test, and a distribution of test cases, usually emulating operations. Because testability is a dynamic attribute of software, it is very computation-intensive to measure directly. The paper presents a case study of real time avionics software to predict the testability of each module from static measurements of source code. The static software metrics take much less computation than direct measurement of testability. Thus, a model based on inexpensive measurements could be an economical way to take advantage of testability attributes during software development. We found that neural networks are a promising technique for building such predictive models, because they are able to model nonlinearities in relationships. Our goal is to predict a quantity between zero and one whose distribution is highly skewed toward zero. This is very difficult for standard statistical techniques. In other words, high testability modules present a challenging prediction problem that is appropriate for neural networks."
pub.1152492838,A statistical estimation of the coupling between object metric for open-source apps developed in Java,"The coupling between objects along with other metrics, is used for evaluating the faults, vulnerabilities, and other quality indicators in software systems, including open-source ones. It is known, that a coupling between objectsvalue between oneand fouris good. However, there are apps in Java for whichthe coupling between objectsmetric value atan app level is greater than four. That is why, in our opinion, the above interval for coupling between objectsneeds to be clarified for the app level. To find the recommended values for the coupling between objects mean of an app we have proposed to apply the confidence and prediction intervals. A coupling between objectsmean value of an app from the confidence interval is good since this interval indicates how reliable the estimate is for all apps. A coupling between objectsmean value higher than an upper bound of the prediction interval may indicate that some classes are too tightly coupled with other ones in the app. We have estimated the confidence and prediction intervals of the coupling between objectsmean using normalizing transformations for the data sample from one hundredopen-source apps developed in Java hosted on GitHub. Comparisonwith the coupling between objectsmean values of three popular open-source apps developed in Java illustrate the applicability of the proposed quality indicators in the form of the confidence and prediction intervals of the coupling between objectsmean."
pub.1101340300,Impact of the Distribution Parameter of Data Sampling Approaches on Software Defect Prediction Models,"Sampling methods are known to impact defect prediction performance. These sampling methods have configurable parameters that can significantly affect the prediction performance. It is however, impractical to assess the effect of all the possible different settings in the parameter space for all the several existing sampling methods. A constant and easy to tweak parameter present in all sampling methods is the distribution of the defective and non-defective modules in the dataset known as Pfp (% of fault-prone modules). In this paper, we investigate and assess the performance of defect prediction models where the Pfp parameter of sampling methods are tweaked. An empirical experiment and assessment of seven sampling methods on five prediction models over 20 releases of 10 static metric projects indicate that (1) Area Under the Receiver Operating Characteristics Curve (AUC) performance is not improved after tweaking the Pfp parameter, (2) pf (false alarms) performance degrades as the Pfp is increased. (3) a stable predictor is difficult to achieve across different Pfp rates. Hence, we conclude that the Pfp parameter setting can have a large impact on the performance (except AUC) of defect prediction models. We thus recommend researchers experiment with the Pfp parameter of the sampling method since the distribution of trainina datasets varv."
pub.1165537054,Prevent: An Unsupervised Approach to Predict Software Failures in Production,"This paper presents Prevent, a fully unsupervised approach to predict and localize failures in distributed enterprise applications. Software failures in production are unavoidable. Predicting failures and locating failing components online are the first steps to proactively manage faults in production. Many techniques predict failures from anomalous combinations of system metrics with supervised, weakly supervised, and semi-supervised learning models. Supervised approaches require large sets of labelled data not commonly available in large enterprise applications, and address failure types that can be either captured with predefined rules or observed while training supervised models. Prevent integrates the core ingredients of unsupervised approaches into a novel fully unsupervised approach to predict failures and localize failing resources. The results of experimenting with Prevent on a commercially-compliant distributed cloud system indicate that Prevent provides more stable, reliable and timely predictions than supervised learning approaches, without requiring the often impractical training with labeled data."
pub.1128462492,A novel test case prioritization method based on problems of numerical software code statement defect prediction,"Test case prioritization (TCP) has been considerably utilized to arrange the implementation order of test cases, which contributes to improve the efficiency and resource allocation of software regression testing. Traditional coverage-based TCP techniques, such as statement-level, method/function-level and class-level, only leverages program code coverage to prioritize test cases without considering the probable distribution of defects. However, software defect data tends to be imbalanced following Pareto principle. Instinctively, the more vulnerable the code covered by the test case is, the higher the priority it is. Besides, statement-level coverage is a more fine-grained method than function-level coverage or class-level coverage, which can more accurately formulate test strategies. Therefore, we present a test case prioritization approach based on statement software defect prediction to tame the limitations of current coverage-based techniques in this paper. Statement metrics in the source code are extracted and data pre-processing is implemented to train the defect predictor. And then the defect detection rate of test cases is calculated by combining the prioritization strategy and prediction results. Finally, the prioritization performance is evaluated in terms of average percentage faults detected in four open source datasets. We comprehensively compare the performance of the proposed method under different prioritization strategies and predictors. The experimental results show it is a promising technique to improve the prevailing coverage-based TCP methods by incorporating statement-level defect-proneness. Moreover, it is also concluded that the performance of the additional strategy is better than that of max and total, and the choice of the defect predictor affects the efficiency of the strategy."
pub.1094992144,BioAIM: Bio-Inspired Autonomous Infrastructure Monitoring,"The Bio-inspired Autonomous Infrastructure Monitoring (BioAIM) system detects anomalous behavior during the deployment and maintenance of a wireless communication network formed autonomously by unmanned airborne nodes. A node may experience anomalous or unexpected behavior in the presence of hardware/software faults/failures, or external influence (e.g. natural weather phenomena, enemy threats). This system autonomously detects, reasons with (e.g. differentiates an anomaly from natural interference), and alerts a human operator of anomalies at runtime via a communication network formed by the Bio-inspired Artificial Intelligence Reconfiguration (BioAIR) system. In particular, BioAIM learns and builds a prediction model which describes how data from relevant sensors should change when a behavior executes under normal circumstances. Surprises occur when there are discrepancies between what is predicted and what is observed. BioAIM identifies a dynamic set of states from the prediction model and learns a structured model similar to a Markov Chain in order to quantify the magnitude of a surprise or divergence from the norm using a special similarity metric. While in operation BioAIM monitors the sensor data by testing the applicable models for each valid behavior at regular time intervals, and informs the operator when a similarity metric deviates from the acceptable threshold."
pub.1138307015,Fail-Safe Execution of Deep Learning based Systems through Uncertainty Monitoring,"Modern software systems rely on Deep Neural Networks (DNN) when processing complex, unstructured inputs, such as images, videos, natural language texts or audio signals. Provided the intractably large size of such input spaces, the intrinsic limitations of learning algorithms and the ambiguity about the expected predictions for some of the inputs, not only there is no guarantee that DNN’s predictions are always correct, but rather developers must safely assume a low, though not negligible, error probability. A fail-safe Deep Learning based System (DLS) is one equipped to handle DNN faults by means of a supervisor, capable of recognizing predictions that should not be trusted and that should activate a healing procedure bringing the DLS to a safe state. In this paper, we propose an approach to use DNN uncertainty estimators to implement such supervisor. We first discuss advantages and disadvantages of existing approaches to measure uncertainty for DNNs and propose novel metrics for the empirical assessment of the supervisor that rely on such approaches. We then describe our publicly available tool UNCERTAINTY-WIZARD, which allows transparent estimation of uncertainty for regular tf.keras DNNs. Lastly, we discuss a large-scale study conducted on four different subjects to empirically validate the approach, reporting the lessons-learned as guidance for software engineers who intend to monitor uncertainty for fail-safe execution of DLS."
pub.1135042535,Fail-Safe Execution of Deep Learning based Systems through Uncertainty Monitoring,"Modern software systems rely on Deep Neural Networks (DNN) when processing
complex, unstructured inputs, such as images, videos, natural language texts or
audio signals. Provided the intractably large size of such input spaces, the
intrinsic limitations of learning algorithms, and the ambiguity about the
expected predictions for some of the inputs, not only there is no guarantee
that DNN's predictions are always correct, but rather developers must safely
assume a low, though not negligible, error probability. A fail-safe Deep
Learning based System (DLS) is one equipped to handle DNN faults by means of a
supervisor, capable of recognizing predictions that should not be trusted and
that should activate a healing procedure bringing the DLS to a safe state. In
this paper, we propose an approach to use DNN uncertainty estimators to
implement such a supervisor. We first discuss the advantages and disadvantages
of existing approaches to measure uncertainty for DNNs and propose novel
metrics for the empirical assessment of the supervisor that rely on such
approaches. We then describe our publicly available tool UNCERTAINTY-WIZARD,
which allows transparent estimation of uncertainty for regular tf.keras DNNs.
Lastly, we discuss a large-scale study conducted on four different subjects to
empirically validate the approach, reporting the lessons-learned as guidance
for software engineers who intend to monitor uncertainty for fail-safe
execution of DLS."
pub.1006888201,Fault-Threshold Prediction with Linear Programming Methodologies,"This paper presents a new experimental methodology that operates on a series of programs structural parameters. We calculated some simple metrics on these parameters and then we applied linear programming techniques on them. It was therefore possible to define a model that can predict the risk level of a program, namely how prone it is to containing faults. The new system represents the software files as points on an n-dimensional space (every dimension is one of the structural attributes for each file). Starting from this model the problem to find out the more dangerous files is brought back to the problem to separate two sets in Rn. A solution to this linear programming problem was achieved by using the MSM-T method (multisurface method tree), a greedy algorithm, which iterative divides the space in polyhedral regions till it reaches an empty set. The classification procedure is divided in two steps: the learning phase, which is used to tune the model on the specified environment and the effective selection. It is, therefore, possible to divide the n-dimensional space and find out the risk-regions of the space, which represent the dangerous files All the process was tested in an industrial application, to validate the soundness of the methodology experimentally. A comparison between linear programming and other risk definition techniques was provided."
pub.1094115210,"SCOUT: A Multi-Objective Method to Select Components in Designing Unit Testing**This work is supported by Brazilian Funding Agencies: FAPEG (Process N° 201310267000283), CAPES (Process N° 99999.005341/2014-00), FAPESP (Process N° 2014/15514-2), and CNPq.","The creation of a suite of unit testing is preceded by the selection of which components (code units) should be tested. This selection is a significant challenge, usually made based on the team member's experience or guided by defect prediction or fault localization models. We modeled the selection of components for unit testing with limited resources as a multi-objective problem, addressing two different objectives: maximizing benefits and minimizing testing cost. To measure the benefit of a component, we made use of metrics from static analysis (cost of future maintenance), dynamic analysis (risk of fault, and frequency of calls), and business value. We tackled gaps and challenges in the literature to formulate an effective method, the Selector of Software Components for Unit Testing (SCOUT). SCOUT provides an automated extraction of all necessary data followed by a multi-objective optimization process. SCOUT is a method able to assist testers in different domains, and the Android platform was chosen to perform our experiments, taking nine leading open-source applications as our subjects. SCOUT was compared with two of the most frequently used strategies in terms of efficacy. We also compared the effectiveness and efficiency of seven algorithms in solving a multiobjective component selection problem. Our experiments were performed under different scenarios, and reveal the potential of SCOUT in reducing the market vulnerability, compared to others approaches. To the best of our knowledge, SCOUT is the first method to assist in an automated way software testing managers in selecting components for the development of unit testing, combining static and dynamic metrics and business value."
pub.1008033479,Programmer-based fault prediction,"Background: Previous research has provided evidence that a combination of static code metrics and software history metrics can be used to predict with surprising success which files in the next release of a large system will have the largest numbers of defects. In contrast, very little research exists to indicate whether information about individual developers can profitably be used to improve predictions. Aims: We investigate whether files in a large system that are modified by an individual developer consistently contain either more or fewer faults than the average of all files in the system. The goal of the investigation is to determine whether information about which particular developer modified a file is able to improve defect predictions. We also continue an earlier study to evaluate the use of counts of the number of developers who modified a file as predictors of the file's future faultiness. Method: We analyzed change reports filed by 107 programmers for 16 releases of a system with 1,400,000 LOC and 3100 files. A ""bug ratio"" was defined for programmers, measuring the proportion of faulty files in release R out of all files modified by the programmer in release R-1. The study compares the bug ratios of individual programmers to the average bug ratio, and also assesses the consistency of the bug ratio across releases for individual programmers. Results: Bug ratios varied widely among all the programmers, as well as for many individual programmers across all the releases that they participated in. We found a statistically significant correlation between the bug ratios for programmers for the first half of changed files versus the ratios for the second half, indicating a measurable degree of persistence in the bug ratio. However, when the computation was repeated with the bug ratio controlled not only by release, but also by file size, the correlation disappeared. In addition to the bug ratios, we confirmed that counts of the cumulative number of different developers changing a file over its lifetime can help to improve predictions, while other developer counts are not helpful. Conclusions: The results from this preliminary study indicate that adding information to a model about which particular developer modified a file is not likely to improve defect predictions. The study is limited to a single large system, and its results may not hold more widely. The bug ratio is only one way of measuring the ""fault-proneness"" of an individual programmer's coding, and we intend to investigate other ways of evaluating bug introduction by individuals."
pub.1172672640,Machine Learning-based Test Case Prioritization using Hyperparameter Optimization,"Continuous integration pipelines execute extensive automated test suites to validate new software builds. In this fast-paced development environment, delivering timely testing results to developers is critical to ensuring software quality. Test case prioritization (TCP) emerges as a pivotal solution, enabling the prioritization of fault-prone test cases for immediate attention. Recent advancements in machine learning have showcased promising results in TCP, offering the potential to revolutionize how we optimize testing workflows. Hyperparameter tuning plays a crucial role in enhancing the performance of ML models. However, there needs to be more work investigating the effects of hyperparameter tuning on TCP. Therefore, we explore how optimized hyperparameters influence the performance of various ML classifiers, focusing on the Average Percentage of Faults Detected (APFD) metric. Through empirical analysis of ten real-world, large-scale, diverse datasets, we conduct a grid search-based tuning with 885 hyperparameter combinations for four machine learning models. Our results provide model-specific insights and demonstrate an average 15% improvement in model performance with hyperparameter tuning compared to default settings. We further explain how hyperparameter tuning improves precision (max = 1), recall (max = 0.9633), F1-score (max = 0.9662), and influences APFD value (max = 0.9835), indicating a direct connection between tuning and prioritization performance. Hence, this study underscores the importance of hyperparameter tuning in optimizing failure prediction models and their direct impact on prioritization performance."
pub.1033993933,The impact of accounting for special methods in the measurement of object-oriented class cohesion on refactoring and fault prediction activities,"Class cohesion is a key attribute that is used to assess the design quality of a class, and it refers to the extent to which the attributes and methods of the class are related. Typically, classes contain special types of methods, such as constructors, destructors, and access methods. Each of these special methods has its own characteristics, which can artificially affect the class cohesion measurement. Several metrics have been proposed in the literature to indicate class cohesion during high- or low-level design phases. The impact of accounting for special methods in cohesion measurement has not been addressed for most of these metrics. This paper empirically explores the impact of including or excluding special methods on cohesion measurements that were performed using 20 existing class cohesion metrics. The empirical study applies the metrics that were considered to five open-source systems under four different scenarios, including (1) considering all special methods, (2) ignoring only constructors, (3) ignoring only access methods, and (4) ignoring all special methods. This study empirically explores the impact of including special methods in cohesion measurement for two applications of interest to software practitioners, including refactoring and predicting faulty classes. The results of the empirical studies show that the cohesion values for most of the metrics considered differ significantly across the four scenarios and that this difference significantly affects the refactoring decisions, but does not significantly affect the abilities of the metrics to predict faulty classes."
pub.1094387826,An Empirical Investigation of Filter Attribute Selection Techniques for Software Quality Classification,"Attribute selection is an important activity in data preprocessing for software quality modeling and other data mining problems. The software quality models have been used to improve the fault detection process. Finding faulty components in a software system during early stages of software development process can lead to a more reliable final product and can reduce development and maintenance costs. It has been shown in some studies that prediction accuracy of the models improves when irrelevant and redundant features are removed from the original data set. In this study, we investigated four filter attribute selection techniques, Automatic Hybrid Search (AHS), Rough Sets (RS), Kolmogorov-Smirnov (KS) and Probabilistic Search (PS) and conducted the experiments by using them on a very large telecommunications software system. In order to evaluate their classification performance on the smaller subsets of attributes selected using different approaches, we built several classification models using five different classifiers. The empirical results demonstrated that by applying an attribution selection approach we can build classification models with an accuracy comparable to that built with a complete set of attributes. Moreover, the smaller subset of attributes has less than 15 percent of the complete set of attributes. Therefore, the metrics collection, model calibration, model validation, and model evaluation times of future software development efforts of similar systems can be significantly reduced. In addition, we demonstrated that our recently proposed attribute selection technique, KS, outperformed the other three attribute selection techniques."
pub.1085795897,Dynamic Selection of Classifiers in Bug Prediction: An Adaptive Method,"In the last decades, the research community has devoted a lot of effort in the definition of approaches able to predict the defect proneness of source code files. Such approaches exploit several predictors (e.g., product or process metrics) and use machine learning classifiers to predict classes into buggy or not buggy, or provide the likelihood that a class will exhibit a fault in the near future. The empirical evaluation of all these approaches indicated that there is no machine learning classifier providing the best accuracy in any context, highlighting interesting complementarity among them. For these reasons ensemble methods have been proposed to estimate the bug-proneness of a class by combining the predictions of different classifiers. Following this line of research, in this paper we propose an adaptive method, named ASCI (Adaptive Selection of Classifiers in bug prediction), able to dynamically select among a set of machine learning classifiers the one which better predicts the bug-proneness of a class based on its characteristics. An empirical study conducted on 30 software systems indicates that ASCI exhibits higher performances than five different classifiers used independently and combined with the majority voting ensemble method."
pub.1140434319,Which Static Code Metrics Can Help to Predict Test Case Effectiveness? New Metrics and Their Empirical Evaluation on Projects Assessed for Industrial Relevance,"One of corner stones of software development are test cases, which help in assessment of created production code. As long as they are properly designed, they have a capacity to capture faults. In order to check whether tests are well made, different procedures have been established, like statement coverage or mutation testing, to evaluate their performance. This has an obvious downside of being computationally expensive and as such is not employed on a wide enough scale. Finding solutions to increase efficiency of assessing test cases, could lead to a more widespread adoption and for that reason we investigate one such approach. We tested possibility of predicting test case effectiveness, strictly on a basis of static code metrics of production and test classes. To solve this task we employed three different learning classifiers, to check feasibility of the process and compare their performance. We created our own set of metrics all of which were later assessed for their impact on prediction. Out of seven most impactful predictors, four of them were proposed by us: Number Of test Cases used in Test class (NOCT), Number Of Defined Variables in a class (NODV), Number of New Objects created in a class (NONO), Number Of Assertions used In Test class (NOAIT). Created models yield a promising result, with best of them achieving over 85% for both F-Measure and Precision along with 73% for Matthews Correlation Coefficient. With the fact of well balanced data used in creation of model, it is safe to assume, that they hold some merit. All steps taken to achieve this result are explained in detail."
pub.1111641494,Opinion Mining at Scale: A Case Study of the First Self-driving Car Fatality,"We present a comprehensive pipeline for large-scale opinion mining via a case study of the first self-driving car fatality, in an effort to qualitatively and quantitatively evaluate trending techniques in web searching as well as sentiment analysis. We first perform a scalable and fault-resilient web scraping with a partially-stateful data model. We then apply recent advances in deep learning comparing with a commercial software for sentiment detection. Not only do we measure the performances of the models by numerical metrics, we subsequently align the prediction results with amid economic indices and impactful social events. We further discuss trade-offs of above models from perspectives of both performance improvements of computer systems and accuracy enhancements of machine learning models, and provide deeper insights for stakeholders in the autonomous vehicle industry and the computational social science community."
pub.1156261118,Empirical evaluation of the performance of data sampling and feature selection techniques for software fault prediction,"Context: The application of Software Fault Prediction (SFP) in the software development life cycle to predict the faulty class at the early stage has piqued the interest of various scholars. In the SFP domain, during research analysis, it got realized that there has been very little work instigated on addressing both class imbalance and feature redundancy problems jointly to enhance the performance and prediction accuracy of SFP models. It has been perceived in the literature survey the study of droughts with the comprehensive comparative analysis of different sampling and feature selection strategies together. Objective: This research builds an extensive assessment of distinct combinations of different feature selection and sampling approaches, to effectively overcome the problems of class overlap, class imbalance, and feature redundancy. The objective is to determine the best combination that will produce results with a higher degree of accuracy and an effective SFP model. Method: Considering the above erudition, the study has applied 8 different sampling techniques along with 10 feature selection algorithms against 56 open-source projects. The comparative analysis is performed against 5346 variants of input datasets by applying 8 different classifiers to predict the faulty class. In addition, the research paper presents an intensive assessment and performance of these techniques individually against all the input projects. We have considered accuracy and Area Under the ROC (receiver operating characteristic curve) Curve (AUC) performance metrics to compare the performance of different models developed using the classification algorithm. Result: For each project in the proposed work, we evaluated a total of 792 combinations that were produced using 10 feature selection methods, 1 all metrics dataset, 8 sampling methods, 1 original, unsampled dataset, and 8 classifiers. The empirical result indicates that, against 21 projects out of 54 projects, Synthetic Minority Over Sampling Technique Edited (SMOTEE) with correlation-based feature selection (FS2) combination outperformed with the highest AUC value which is 38.89 % of projects. Additionally, according to experimental results, the highest AUC values were attained by 24.07 % of projects using the SMOTEE, FS2, and RF combination. Conclusion: The results of the statical analysis test reveal that 93.42 % of the combinational pairs of different sampling and feature selection approaches demonstrated a significant variance in the performance of the distinct combinations of sampling and feature selection techniques. The empirical result indicates the performance of the SFP Model is adversely impacted by class imbalance and irrelevance. The outcome indicates for more than 75% of projects, the performance of trained models improved with an AUC value between a range of 0.805 to 0.99 post-application of sampling and feature selection strategies, in comparison without the use of feature selection and sampli"
pub.1120286960,Neural network based multi-objective evolutionary algorithm for dynamic workflow scheduling in cloud computing,"Workflow scheduling is a largely studied research topic in cloud computing, which targets to utilize cloud resources for workflow tasks by considering the objectives specified in QoS. In this paper, we model dynamic workflow scheduling problem as a dynamic multi-objective optimization problem (DMOP) where the source of dynamism is based on both resource failures and the number of objectives which may change over time. Software faults and/or hardware faults may cause the first type of dynamism. On the other hand, confronting real-life scenarios in cloud computing may change number of objectives at runtime during the execution of a workflow. In this study, we propose a prediction-based dynamic multi-objective evolutionary algorithm, called NN-DNSGA-II algorithm, by incorporating artificial neural network with the NSGA-II algorithm. Additionally, five leading non-prediction based dynamic algorithms from the literature are adapted for the dynamic workflow scheduling problem. Scheduling solutions are found by the consideration of six objectives: minimization of makespan, cost, energy and degree of imbalance; and maximization of reliability and utilization. The empirical study based on real-world applications from Pegasus workflow management system reveals that our NN-DNSGA-II algorithm significantly outperforms the other alternatives in most cases with respect to metrics used for DMOPs with unknown true Pareto-optimal front, including the number of non-dominated solutions, Schott’s spacing and Hypervolume indicator."
pub.1110932570,Pinset: A DSL for Extracting Datasets from Models for Data Mining-Based Quality Analysis,"Data mining techniques have been successfully applied to software quality analysis and assurance, including quality of modeling artefacts. Before such techniques can be used, though, data under analysis commonly need to be formatted into two-dimensional tables. This constraint is imposed by data mining algorithms, which typically require a collection of records as input for their computations. The process of extracting data from the corresponding sources and formatting them properly can become error-prone and cumbersome. In the case of models, this process is mostly carried out through scripts written in a model management language, such as EOL or ATL. To improve this situation, we present Pinset, a domain-specific language devised for the extraction of tabular datasets from software models. Pinset offers a tailored syntax and built-in facilities for common activities in dataset extraction. For evaluation, Pinset has been used on UML class diagrams to calculate metrics that can be employed as input for several fault-prediction algorithms. The use of Pinset for this calculations led to more compact and high-level specifications when compared to equivalent scripts written in generic model management languages."
pub.1053505877,Integrating testing with reliability,"Abstract The activities of software testing and reliability are integrated for the purpose of demonstrating how the two activities interact in achieving testing efficiency and the reliability resulting from these tests. Integrating means modeling the execution of a variety of tests on a directed graph representation of an example program. A complexity metric is used to construct the nodes, edges, and paths of the example program. Models are developed to represent the efficiency and achieved reliability of black box and white box tests. Evaluations are made of path, independent path, node, program construct, and random tests to ascertain which, if any, is superior with respect to efficiency and reliability. Overall, path testing has the edge in test efficiency. The results depend on the nature of the directed graph in relation to the type of test. Although there is no dominant method, in most cases the tests that provide detailed coverage are better. For example, path testing discovers more faults than independent path testing. Predictions are made of the reliability and fault correction that results from implementing various test strategies. It is believed that these methods can be used by researchers and practitioners to evaluate the efficiency and reliability of other programs. Copyright © 2008 John Wiley & Sons, Ltd."
pub.1174640391,"Exploring Perspectives, Issues, and Practices in the Testing and Quality Validation of AI Software","Artificial intelligence and big data computing are developing at a fast pace, which has resulted in the creation of several software service systems that use different machine learning models. By processing multimedia data for functions including picture identification, recommendation, decision-making, and prediction, these systems seek to facilitate intelligent decision-making in enterprises. On the other hand, there is growing worry about the rising quality problems that are driving up testing expenses for businesses. This study focuses on the quality assessment of AI software functionality features and tackles the dearth of discussion around testing and quality validation for AI software. This study delves into the efficacy of supervised machine learning (ML) algorithms for addressing the test case prioritization problem. Four distinct ML algorithms, including Ranked Support Vector Machines (SVM Rank), K-Nearest Neighbor (KNN), logistic regression (Log Reg), and neural networks, are meticulously evaluated. Additionally, two ensemble learning strategies, historical ensemble learning and combinatorial ensemble learning, are introduced to further enhance prioritization quality. The evaluation methodology involves computing priority values for test cases and assessing effectiveness primarily through the Average Percentage of Faults Detected (APFD) metric. Results indicate that logistic regression excels among individual ML algorithms, while combining all four approaches yields superior performance. The inclusion of test case description features significantly impacts prioritization quality, with logistic regression consistently outperforming other algorithms across different subject systems."
pub.1162997421,A Systematic Literature Review on Test Case Prioritization and Regression Test Selection,"Regression testing is a crucial component of software testing and a crucial tool for ensuring the quality of software. An appropriate optimization method is essential for maximizing productivity and reducing expenses in regression testing. Test case prioritization (TCP) and regression test selection (RTS) are two popular methods in regression testing. This paper provides a qualitative analysis of 18 TCP and 17 RTS publications from the last five years. This paper presents four main issues. The first covers the most popular TCP techniques, the second covers the most popular RTS methods, the third covers the most popular metrics for measuring TCP and RTS, and the fourth covers data sources. Based on this study, we draw the following conclusions: (1) Defect prediction and machine learning-based TCP methods, machine learning, multi-objective, and model-based RTS methods will receive additional attention in future. (2) Defects4J is the most commonly used data set in TCP in the past five years. SIR and GitHub are the most commonly used datasets in RTS. (3) The most widely used measurement methods in TCP and RTS are APFD and cost, respectively. In future, researchers will use these two indicators to conduct a more comprehensive evaluation together with cost, fault detection capability, and test coverage."
pub.1154208324,Software Measurements from Machine Learning to Deep Learning,"Software measurement (SM) is an umbrella activity during the entire software development cycle. Measurements and metrics of the attributes are indispensable for successful completion of project and effective delivery of software product. This chapter discusses SMs using deep learning (DL) techniques from the perspective of an empirical study. It is evident that an inaccurate prediction or estimation during the software development processes leads to loss of money and loss of projects. Since the beginning of software engineering, a wide range of methods are being deployed for measuring the software attributes. At present, the conventional techniques are not so apt for SMs due to excessive complex attributes of very large software. Machine learning (ML) has been the answer to all market needs in the past 30 years. It is noticed that ML is quite good to perform measurements in software engineering processes, but it is not the best method and needs enhancements. DL is the extension to ML, which is now being extensively used for SMs. The chapter begins with an introduction to ML and DL techniques and their applications in SMs empirically. Then, it highlights the literature work carried out in the field of empirical SMs using DL techniques. One of the most important DL techniques is convolutional neural networks which is discussed as a case study. This study provides a practical orientation to the readers about the implementation of DL technique to SMs. This chapter describes the transitional shift of software measurements (SMs) from the usage of machine learning (ML) techniques to the usage of deep learning (DL) techniques. A wide range of ML methods and DL techniques is available to find the optimal approach to SMs. Techniques are categorized as supervised learning techniques and unsupervised learning techniques. The DL model is deployed in SMs basically in two situations: when there is need of automation for feature selection, and when there is necessity to assess the semantics of software coding to detect the faulty modules. With deep structures, the semantics of the code can be checked for fault proneness. It allows the both levels–syntactic level and semantic level aspects to be considered while judging the software module as defective or nondefective. The measurement of software quality is a highly complex task and equally essential one for the effective completion of software project."
pub.1167941235,CBReT: A Cluster-Based Resampling Technique for dealing with imbalanced data in code smell prediction,"Code smell refers to substandard design patterns in software’s source code that may lead to faults-prone implementation. Machine learning-based code smell prediction models suffer from data imbalance problems, i.e., one class contains significantly more instances than another. The existing oversampling approaches, such as SMOTE (Synthetic Minority Over-sampling Technique), have been used for balancing the code smell dataset by generating synthetic samples for the minority class. However, the distribution of classes of code smell datasets is overlapped; hence, randomly generated instances can damage the decision boundary between both classes. This paper addresses this issue and proposes a novel Cluster-Based Resampling Technique, CBReT, that generates synthetic instances by considering the distribution of the code smell data. The CBReT first formulates clusters (containing minority and majority instances) based on the data distribution using Gaussian Mixture Model (GMM). Next, each cluster is balanced separately by synthesizing minority instances. While balancing the clusters, the CBReT also checks the validity of the synthetic instances so that each synthetic instance holds similar properties as the other minority instances. To assess the performance of CBReT, extensive experiments have been conducted on the four publicly available benchmark code smell datasets. We have used various performance metrics to evaluate our model’s performance. The experimental results show that the CBReT technique significantly increased the performance of the code smell prediction model by 0.18% (min) and 9.08% (max) compared to the state-of-the-art imbalance learning approaches."
pub.1113194502,Complex Geological Modeling Using Unstructured Grids: Quality Assurance Approaches and Improved Prediction,"Abstract The vast majority of grids for reservoir modeling and simulation workflows are based on pillar gridding or stairstep grid technologies. The grids are part of a feature-rich and well-established modeling workflow provided by many commercial software packages. Undesirable and significant simplifications to the gridding often arise when employing such approaches in structurally complex areas, and this will clearly lead to poor predictions from the downstream modeling. In the classical gridding and modeling workflow, the grid is built in geological space from input horizon and fault interpretations, and the property modeling occurs in an approximated ‘depositional’ space generated from the geological space grid cells. The unstructured grids that we consider here are based on a very different workflow: a volume-based structural model is first constructed from the fault/horizon input data; a flattening (‘depositional’) mapping deforms the mesh of the structural model under mechanical and geometric constraints; the property modeling occurs in this depositional space on a regular cuboidal grid; after ‘cutting’ this grid by the geological discontinuities, the inverse depositional mapping recovers the final unstructured grid in geological space. A critical part of the depositional transformation is the improved preservation of geodetic distances and the layer-orthogonality of the grid cells. The final grid is an accurate representation of the input structural model, and therefore the quality checking of the modeling workflow must be focused on the input data and structural model creation. We describe a variety of basic quality checking and structurally-focused tools that should be applied at this stage; these tools aim to ensure the accuracy of the depositional transformation, and consequently ensure both the quality of the generated grid and the consistent representation of the property models. A variety of quality assurance metrics applied to the depositional/geological grid geometries provide spatial measures of the ‘quality’ of the gridding and modeling workflow, and the ultimate validation of the structural quality of the input data. Two case studies will be used to demonstrate this novel workflow for creating high-quality unstructured grids in structurally complex areas. The improved quality is validated by monitoring downstream impacts on property prediction and reservoir simulation; these improved prediction scenarios are a more accurate basis for history matching approaches."
pub.1094027667,System Failure Forewarning Based on Workload Density Cluster Analysis,"Each computer system contains design objectives for long-term usage, so the operator must conduct a continuous and accurate assessment of system performance in order to detect the potential factors that will degrade system performance. Condition indicators are the basic components of diagnosis. It is important to select feature vectors that meet the criteria in order to provide true accuracy and powerful diagnostic routines. Our goal is to indicate the actual system status according to the workload, and use clustering techniques to analyze the workload distribution density to build diagnostic templates. Such templates can be used for system failure forewarning. In the proposed system, we present an approach, based on workload density cluster analysis to automatically monitor the health of software systems and system failure forewarning. Our approach consists of tracking the workload density of metric clusters. We employ the statistical template model to automatically identify significant changes in cluster moving, therefore enabling robust fault detection. We observed two circumstances from the experiment results. First, under most normal status, the lowest accuracy value is approximate our theoretical minimum threshold of 84%. Such result implies a close correlation between our measured and real system status. Second, the command data used by the system could predict 90% of events announced, which reveals the prediction effectiveness of this proposed system. Although it is infeasible for the system to process the largest possible fault events in the deployment of resources, we could apply statistics to characterize the anomalous behaviors to understand the nature of emergencies and to test system service under such scenarios."
pub.1049827024,Fault diagnosis in DSL networks using support vector machines,"The adequate operation for a number of service distribution networks relies on the effective maintenance and fault management of their underlay DSL infrastructure. Thus, new tools are required in order to adequately monitor and further diagnose anomalies that other segments of the DSL network cannot identify due to the pragmatic issues raised by hardware or software misconfigurations. In this work we present a fundamentally new approach for classifying known DSL-level anomalies by exploiting the properties of novelty detection via the employment of one-class Support Vector Machines (SVMs). By virtue of the imbalance residing in the training samples that consequently lead to problematic prediction outcomes when used within two-class formulations, we adopt the properties of one-class classification and construct models for independently identifying and classifying a single type of a DSL-level anomaly. Given the fact that the greater number of the installed Digital Subscriber Line Access Multiplexers (DSLAMs) within the DSL network of a large European ISP were misconfigured, thus unable to accurately flag anomalous events, we utilize as inference solutions the models derived by the one-class SVM formulations built by the known labels as flagged by the much smaller number of correctly configured DSLAMs in the same network in order to aid the classification aspect against the monitored unlabeled events. By reaching an average over 95% on a number of classification accuracy metrics such as precision, recall and F-score we show that one-class SVM classifiers overcome the biased classification outcomes achieved by the traditional two-class formulations and that they may constitute as viable and promising components within the design of future network fault management strategies. In addition, we demonstrate their superiority over commonly used two-class machine learning approaches such as Decision Trees and Bayesian Networks that has been used in the same context within past solutions."
pub.1181450322,TEASMA: A Practical Methodology for Test Adequacy Assessment of Deep Neural Networks,"Successful deployment of Deep Neural Networks (DNNs), particularly in safety-critical systems, requires their validation with an adequate test set to ensure a sufficient degree of confidence in test outcomes. Although well-established test adequacy assessment techniques from traditional software, such as mutation analysis and coverage criteria, have been adapted to DNNs in recent years, we still need to investigate their application within a comprehensive methodology for accurately predicting the fault detection ability of test sets and thus assessing their adequacy. In this paper, we propose and evaluate TEASMA, a comprehensive and practical methodology designed to accurately assess the adequacy of test sets for DNNs. In practice, TEASMA allows engineers to decide whether they can trust high-accuracy test results and thus validate the DNN before its deployment. Based on a DNN model’s training set, TEASMA provides a procedure to build accurate DNN-specific prediction models of the Fault Detection Rate (FDR) of a test set using an existing adequacy metric, thus enabling its assessment. We evaluated TEASMA with four state-of-the-art test adequacy metrics: Distance-based Surprise Coverage (DSC), Likelihood-based Surprise Coverage (LSC), Input Distribution Coverage (IDC), and Mutation Score (MS). We calculated MS based on mutation operators that directly modify the trained DNN model (i.e., post-training operators) due to their significant computational advantage compared to the operators that modify the DNN's training set or program (i.e., pre-training operators). Our extensive empirical evaluation, conducted across multiple DNN models and input sets, including large input sets such as ImageNet, reveals a strong linear correlation between the predicted and actual FDR values derived from MS, DSC, and IDC, with minimum R2 values of 0.94 for MS and 0.90 for DSC and IDC. Furthermore, a low average Root Mean Square Error (RMSE) of 9% between actual and predicted FDR values across all subjects, when relying on regression analysis and MS, demonstrates the latter's superior accuracy when compared to DSC and IDC, with RMSE values of 0.17 and 0.18, respectively. Overall, these results suggest that TEASMA provides a reliable basis for confidently deciding whether to trust test results for DNN models."
pub.1132967323,Systems Performance Modeling,"Software security has been an area of immense research as most of the things surrounding us are technology based. Much has been talked about vulnerabilities, their categories and types. Some studies elaborated and extended the available discovery models but few have considered the correction process in the same work. In this study, an approach to deal with software vulnerability through the release of patch/updates has been presented. The methodical work presented here discusses a mathematical model for optimal allocation of resources to remove vulnerabilities through an update. Debugging activities in a testing phase of software development are important for eliminating software faults remained and for shipping highly reliable software system to the user. Therefore, reflecting the debugging situation in testing activities on software reliability assessment must be one of the useful approaches for managing the software development project with accurate information on software quality/reliability and conducting quality-oriented software management. We introduce two types of software fault debugging-oriented stochastic modeling approaches for conducting mathematical model-based quality/reliability assessment. These modeling approaches discussed in this chapter are expected to improve the accuracy of model-based software reliability assessment. Vehicular cloud computing is a new paradigm that makes use of cloud computing resources to overcome the restraints of vehicular computing. It allows the sharing of resources such as storage capacity, computational power, and Internet connectivity from those vehicles in which these resources remain idle for long hours (in parking or heavy traffic jams). This chapter presents an availability study of the vehicular cloud. Due to its multilayered architecture, composite modeling technique is desired for availability analysis of vehicular clouds. Distinct models are developed for each subsystem using reliability block diagrams and semi-Markov process, and the models are then combined to evaluate the availability of the complete system. Two different sensitivity analysis techniques (partial derivatives and percentage difference) to determine the parameters that cause the greatest impact on the availability of the vehicular cloud are also applied. The analysis reflects that the availability can be improved by aiming on reduced set of parameters that affect the availability most. A new software reliability model is proposed. The model is inspired in the Polya stochastic process, which is the asymptotic limit of the Polya urn model for contagion that is well described as a pure birth process. Modeling software reliability with this type of process introduces failure rate functions that depend not only on time but also on the number of failures previously detected. Since the failure rate function of the Polya stochastic process results in a linear-over-time mean number of failures, we propose a new pure birth process w"
pub.1121498489,"Failure prediction, detection & recovery algorithms using MCMC in tree-based network topology to improve coverage and connectivity in 3D-UW environment"," In an Underwater Wireless Sensor Networks (UW-WSN), one of the most challenging issue is the fault tolerance during data transmission. There are various constraints like lack of power, physical damage, hardware and software problem that leads to failure or blocked sensor node. Due to the faulty sensor node, it is quite difficult to communicate the information in a particular time period. This failure affects the overall network operation performance. In order to improve the coverage, connectivity and network performance, we propose a failure prediction, detection and recovery algorithm using Markov Chain Monte Carlo (MCMC) process. In the failure prediction algorithm, the failures of sensor node are identified by using error pattern of delayed messages and the threshold limit is based on time probability distribution function. In the failure detection algorithm, the faulty sensor node is detected using threshold limit and residual energy. In the recovery algorithm, the faulty sensor node is replaced by the nearest neighbouring sensor node with high energy capacity. Theoretical analysis and experimental simulation results are evaluated based on performance metrics such as Coverage Ratio, Failure Prediction, Network Lifetime and Recovery Policy. The results shows that the proposed 3-D UW-WSN system has a maximum coverage ratio of 23.07%, maximum increase of recovery sensor nodes 30%, maximum decrease of the predictive probability of failure node 11.11% and maximum increase of network lifetime 50%. The simulation results shows better performance and the proposed method is more efficient than the coverage of static and mobile sensor in 2-D UW-WSN algorithms. The proposed coverage of static and mobile sensor in 3-D UW-WSN mechanism performs to improve coverage and connectivity, reduces the predictive probability of failure nodes and increases network lifetime."
pub.1098889496,Empirical studies on software evolution,"In recent and past years, there have been hundreds of studies aimed at characterizing the evolution of a software system. Many of these studies analyze the behavior of a variable over a given period of observation. How does the size of a software system evolve? What about its complexity? Does the number of defects increase over time or does it remain stable? In some cases, studies also attempt to correlate variables, and, possibly, to build predictors upon them. This is to say, one could estimate the likelihood that a fault occurs in a class, based on some metrics the class exhibits, on the kinds of changes the class underwent. Similarly, change couplings can be inferred by observing how artifacts tend to co-change. Although in many cases we are able to obtain models ensuring good prediction performances, we are not able to claim any causal-effect relationship between our independent and dependent variables. We could easily correlate the presence of some design constructs with the change-proneness of a software component, however the same correlation could be found with the amount of good Belgian beer our developers drink. As a matter of fact, the component could undergo changes for other, external reasons. Recent software evolution studies rely on fine-grained information mined by integrating several kinds of repositories, such as versioning systems, bug tracking systems, or mailing lists. Nowadays, many other precious sources of information, ranging from code search repositories, vulnerability databases, informal communications, and legal documents are also being considered. This would possibly aid to capture the rationale of some events occurring in a software project, and link them to statistical relations we observed. The road towards shifting from solid empirical models towards ""principles of software evolution"" will likely be long and difficult, therefore we should prepare ourselves to traverse it and go as far as possible with limited damages. To do this, we need to carefully prepare our traveling equipment by paying attention at: (i) combining quantitative studies with qualitative studies, surveys, and informal interviews, (ii) relating social relations among developers with variables observed on the project, (iii) using proper statistical and machine learning techniques able to capture the temporal relation among different events, and (iv) making a massive use of natural language processing and text mining among the various sources of information available."
pub.1172310161,Availability analysis of imperfect repairable system subject to inspection," Purpose This work examines a repairable machining system’s reliability by considering multiple failure scenarios, including individual component failures, hardware and software malfunctions, failures resulting from shared causes and failures caused by human error. When a system is susceptible to several modes of failure, the primary goal is to forecast availability and other reliability metrics as well as to calculate the expected profit of the repairable machining system.   Design/methodology/approach The process of recovering after a system failure involves inspecting the system and fixing any malfunctions that may have occurred. The repair procedures for all kinds of faults are taken to follow a general distribution to represent real-time circumstances. We develop a non-Markovian stochastic model representing different system states that reveal working, failed, degraded, repair and delayed repair states. Laplace transformation and the supplementary variable technique are used to assess the transient states of the system.   Findings Analytical expressions for system performance indices such as availability, reliability and cost-benefit analysis are derived. The transient probabilities when the system experiences in different states such as failed, degraded and delayed states are computed. The results obtained are validated using Mathematica software by performing a numerical illustration on setting default values of unknown parameters. This ensures the accuracy and reliability indices of the analytical predictions.   Originality/value By methodically examining the system in its several states, we will be able to spot possible problems and offer efficient fixes for recovery. The system administrators would check to see if a minor or major repair is needed, or if a replacement is occasionally taken into consideration to prevent recurring repairs. "
pub.1141439667,Sustainability Analysis of a ZnO-NaCl-Based Capacitor Using Accelerated Life Testing and an Intelligent Modeling Approach,"From small toys to satellites, capacitors play a vital role as an energy storage element, filtering or controlling other critical tasks. This research paper focuses on estimating the remaining useful life of a nanocomposite-based fabricated capacitor using various experimental and artificial intelligence techniques. Accelerated life testing is used to explore the sustainability and remaining useful life of the fabricated capacitor. The acceleration factors affecting the health of capacitors are investigated, and experiments are designed using Taguchi’s approach. The remaining useful lifetime of the fabricated capacitor is calculated using a statistical technique, i.e., regression analysis using Minitab 18.1 software. An expert model is designed using artificial neural networks (ANN), which warns the user of any upcoming faults and failures. The average remaining useful life of the fabricated capacitor, using accelerated life testing, regression, and artificial neural network, is reported as 13,724.3 h, 14,515.9 h, and 14,247.1 h, respectively. A comparison analysis is conducted, and performance metrics are analyzed to opt for the most efficient technique for the prediction of the remaining useful life of the fabricated capacitor, which confirms 93.83% accuracy using the statistical method and 95.82% accuracy using artificial neural networks. The root mean square error (RMSE) of regression and artificial neural networks is found to be 0.102 and 0.167, respectively, which validates the consistency of the reliability methods."
pub.1124050898,Cost Evaluation Framework for Fault Prediction Technique in Testing,"In the current situation, service-oriented architecture is received by the greater part of the organization, which is a gathering of inexactly coupled administration. In this paper, we have proposed a versatile cost assessment structure that joins cost drivers for different blame expulsion stages and plays out a money-saving advantage examination for testing and blame forecast. Our cost assessment structure considers more sensible situation where the undetected shortcomings are followed in all the later testing stages and the relating flaw evacuation cost is assessed in view of the association with particular measurements. Here we have focused on two of the most pertinent research questions with respect to testing. To start with, regardless of whether blame forecast could financially help in decreasing programming improvement cost, for a specific task, we pick a blame forecast system for general enhanced execution. We have utilized the proposed structure to examine the convenience of different blame expectation methods in testing. The examination comprised execution assessment of two noteworthy blame expectation methods, that is, straight relapse and coordination relapse on two distinct adaptations of eBay web administrations. Here we have discovered blame expectation valuable for the ventures with the level of broken modules not as much as a specific edge."
pub.1164815184,Utilising Artificial Neural Networks for Assessing Seismic Demands of Buckling Restrained Braces Due to Pulse-like Motions,"Buckling restrained brace frames (BRBFs) exhibit exceptional lateral stiffness, load-bearing capacity, and energy dissipation properties, rendering them a highly promising choice for regions susceptible to seismic activity. The precise and expeditious prediction of seismic demands on BRBFs is a crucial and challenging task. In this paper, the potential of artificial neural networks (ANNs) to predict the seismic demands of BRBFs is explored. The study presents the characteristics and modelling of prototype BRBFs with different numbers of stories and material properties, utilising the OpenSees software (Version 2.5.0) for numerical simulations. The seismic performance of the BRBFs is evaluated using 91 near-fault pulse-like ground motions, and the maximum inter-storey drift ratio (MIDR) and global drift ratio (GDR) are recorded as a measure of seismic demand. ANNs are then trained to predict the MIDR and GDR of the selected prototypes. The model’s performance is assessed by analysing the residuals and error metrics and then comparing the trend of the results with the real dataset. Feature selection is utilised to decrease the complexity of the problem, with spectral acceleration at the fundamental period (T) of the structure (Sa), peak ground acceleration (PGA), peak ground velocity (PGV), and T being the primary factors impacting seismic demand estimation. The findings demonstrate the effectiveness of the proposed ANN approach in accurately predicting the seismic demands of BRBFs."
pub.1163954801,A Systematic Literature Review of Explainable Artificial Intelligence (XAI) in Software Engineering (SE),"<p>Artificial intelligence (AI) is the most advanced developing area for enhancing Machine Intelligence and replicating the intelligence of humans. In this regard, Machine Learning (ML) is used to develop algorithms and models that help machines learn from data and predict problems. Although ML models provide accurate predictions, they are frequently considered black boxes due to their lack of interpretability. This can undermine trust and acceptance of AI systems, particularly in critical domains requiring transparency and accountability, such as Healthcare. Explainable Artificial Intelligence (XAI) techniques, which have emerged to make ML models more transparent and interpretable, can address the lack of interpretability challenge. They shed light on how ML models make decisions and explain and justify the results. This builds trust and makes AI systems more accessible to implement in various industries. The proposed research study investigates how much XAI is used in Software Engineering (SE). It intends to present a comprehensive view of the most recent advancements and address challenges and future directions for further investigation.</p> <p>This Systematic Literature Review (SLR) investigates the application of XAI techniques in SE. It is based on empirical studies published between January 2020 and September 2022 to analyze the XAI&rsquo;s overall illustration. We developed a search string and six research questions, each answered briefly. According to our SLR findings, 14 of the 131 research studies extracted from various databases addressed XAI techniques. Additionally, 14 research studies using XAI techniques in the Healthcare and Finance domains were chosen to compare with the findings of this literature review. These studies were chosen because the researchers frequently cited them.</p> <p>Following our findings, XAI approaches were mainly employed in the Software Fault Predictions (SFP) subdomain of SE, and all studies used local explanations. Python programming libraries were used for implementation, with &ldquo;sci-kit&rdquo; being the most widely used, followed by &ldquo;caret&rdquo; of the R programming language. In addition, the &ldquo;LIME&rdquo; tool is the most commonly used in the SFP domain for local explanations, followed by the &ldquo;SHAP&rdquo; tool. The findings also show that local and global explanations were used in the Healthcare and Finance domains. The most widely used Python programming library is the &ldquo;sci-kit learn&rdquo; library, with the &ldquo;SHAP&rdquo; tool being the most commonly used explanation tool in the Finance and Healthcare domains. Finally, whereas XAI in SE is new, XAI methods have been used in conjunction with traditional machine learning models. However, there is a lack of benchmark evaluation metrics in the existing literature, leading to researcher confusion and unreliable comparison standards.</p> <p> </p>"
pub.1094360318,"Automated Generation and Assessment of Autonomous Systems Test Cases11-4244-1488-1/08/$25.00 © 2008 IEEE,2IEEEAC paper #1228, Version 2, Updated October 22, 2007","Verification and validation testing of autonomous spacecraft routinely culminates in the exploration of anomalous or faulted mission-like scenarios. Prioritizing which scenarios to develop usually comes down to focusing on the most vulnerable areas and ensuring the best return on investment of test time. Rules-of-thumbstrategies often come into play, such as injecting applicable anomalies prior to, during, and after system state changes; or, creating cases that ensure good safety-net algorithm coverage. Although experience and judgment in test selection can lead to high levels of confidence about the majority of a system's autonomy, it's likely that important test cases are overlooked. One method to fill in potential test coverage gaps is to automatically generate and execute test cases using algorithms that ensure desirable properties about the coverage. For example, generate cases for all possible fault monitors, and across all state change boundaries. Of course, the scope of coverage is determined by the test environment capabilities, where a faster-than-real-time, high-fidelity, software-only simulation would allow the broadest coverage. Even real-time systems that can be replicated and run in parallel, and that have reliable set-up and operations features provide an excellent resource for automated testing. Making detailed predictions for the outcome of such tests can be difficult, and when algorithmic means are employed to produce hundreds or even thousands of cases, generating predicts individually is impractical, and generating predicts with tools requires executable models of the design and environment that themselves require a complete test program. Therefore, evaluating the results of large number of mission scenario tests poses special challenges. A good approach to address this problem is to automatically score the results based on a range of metrics. Although the specific means of scoring depends highly on the application, the use of formal scoring metrics has high value in identifying and prioritizing anomalies, and in presenting an overall picture of the state of the test program. In this paper we present a case study based on automatic generation and assessment of faulted test runs for the Dawn mission, and discuss its role in optimizing the allocation of resources for completing the test program."
pub.1112924552,"iSTEP, an integrated Self-Tuning Engine for Predictive maintenance in Industry 4.0","The recent expansion of IoT-enabled (Internet of Things) devices in manufacturing contexts and their subsequent data-driven exploitation paved the way to the advent of the Industry 4.0, promoting a full integration of IT services, smart devices, and control systems with physical objects, their electronics and sensors. The real-time transmission and analysis of collected data from factories has the potential to create manufacturing intelligence, of which predictive maintenance is an expression. Hence the need to design new approaches able to manage not only the data volume, but also the variety and velocity, extracting actual value from the humongous amounts of collected data. To this aim, we present iSTEP, an integrated Self-Tuning Engine for Predictive maintenance, based on Big Data technologies and designed for Industry 4.0 applications. The proposed approach targets some of the most common needs of manufacturing enterprises: compatibility with both the on-premises and the in-the-cloud environments, exploitation of reliable and largely supported Big Data platforms, easy deployment through containerized software modules, virtually unlimited horizontal scalability, fault-tolerant self-reconfiguration, flexible yet friendly streaming-KPI computations, and above all, the integrated provisioning of self-tuning machine learning techniques for predictive maintenance. The current implementation of iSTEP exploits a distributed architecture based on Apache Kafka, Spark Streaming, MLlib, and Cassandra; iSTEP provides (i) a specific feature engineering block aimed at automatically extracting metrics from the production monitoring time series, which improves the predictive performance by 77% on average, and (ii) a self-tuning approach that dynamically selects the best prediction algorithm, which improves the predictive performance up to 60%. The iSTEP engine provides transparent predictive models, able to provide end users with insights into the knowledge learned, and it has been experimentally evaluated on a public unbalanced failure dataset, whose extensive results are discussed in the paper."
pub.1137790113,An Elasticity Framework for Distributed Message Queuing Telemetry Transport Brokers,"Internet of Things (IoT) applications are increasingly making impact in all areas of humanlife. Day by day, its chatty embedded devices have been generating tons of data requiring effectivenetwork infrastructure. To deliver millions of IoT messages back and fort with as few faults aspossible, participation of communication protocols like MQTT is a must. Lightweight blueprintand friendly battery are just two of many advantages of this protocol making it become a dominantin IoT world. In real application scenarios, distributed MQTT solutions are usually required sincecentralized MQTT approach is incapable of dealing with huge amount of data. Although distributedMQTT solutions are scalable, they do not adapt to fluctuations of traffic workload. This might costIoT service provider because of redundant computation resources. This leads to the need of a novelapproach that can adapt its size changes in workload. This article proposes such an elastic solutionby proposing a flexible MQTT framework. Our MQTT framework uses off-the-shelf componentsto obtain server’s elasticity while keeping IoT applications intact. Experiments are conducted tovalidate elasticity function provided by an implementation of our framework.
 Keywords
 MQTT broker, Elasticity, Internet of Things, Cloud computing
 References
  [1] Sharma, D. Panwar, Green IoT: Advancements and Sustainability with Environment by 2050. In: 8th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO), Noida, India, 2020, pp. 1127-1132.
 [2] Turner, D. Reinsel, J.F. Gantz, S. Minton, The Digital Universe of Opportunities: Rich Data and the Increasing Value of the Internet of Things, IDC Report Apr, 2014.
 [3] MQ Telemetry Transport. http://mqtt.org/, 2020 (30 October 2020).
 [4] Mell, T. Grance, The NIST definition of cloud computing (draft), NIST special publication 800-145 (2011) 1-3.
 [5] T. Eugster, P.A. Felber, R. Guerraoui, A. Kermarrec, The many faces of publish/subscribe, ACM Comput, Surv. 35(2) (2003) 114-131.
 [6] Kawaguchi, M. Bandai, Edge Based MQTT Broker Architecture for Geographical IoT Applications, 2020 International Conference on Information Networking (ICOIN), Barcelona, Spain, 2020, pp. 232-235.
 [7] Gupta, S. Khera, N. Turk, MQTT protocol employing IOT based home safety system with ABE encryption, Multimed Tools Appl, 2020.
 [8] Mukambikeshwari, Poojary, Smart Watering System Using MQTT Protocol in IoT, Advances in Artificial Intelligence and Data Engineering. Advances in Intelligent Systems and Computing, Springer, Singapore 1133 (2020) số trang đầu-cuối.
 [9] C. See, E.X. Ho, IoT-Based Fire Safety System Using MQTT Communication Protocol, International Journal of Integrated Engineering. 12(6) (2020) 207-215.
 [10] Nazir, M. Kaleem, Reliable Image Notifications for Smart Home Security with MQTT, International Conference on Information Science and Communication Technology (ICISCT), Karachi, Pakistan, 2019, pp. 1-5.
 [11]"
